<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="About Learning"><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/fonts.css><link rel=stylesheet href=/css/custom.css><title>Demystifying Item Response Theory (1/4) |
Yongfu's Blog</title></head><body><div class=header><div class=header_title><span class=logo><!doctype html><svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="346pt" height="346pt" viewBox="0 0 346 346"><g transform="translate(0.000000,346.000000) scale(0.100000,-0.100000)" fill="#000" stroke="none"><path d="M1484 3328c8-40 19-53 84-94 36-24 52-40 50-52-2-10-12-16-23-15-173 21-208 16-293-38-17-12-66-30-108-40-117-29-354-149-354-178 0-5 20-6 45-3 28 3 45 1 45-6 0-6-32-32-70-57-98-65-105-78-90-162 7-38 20-88 30-113 21-50 17-65-33-117-23-25-32-46-38-93-7-49-17-70-50-112-39-50-41-55-33-98 4-25 8-95 8-156 1-104 3-113 29-151 15-22 41-52 58-67 16-14 29-33 29-41 0-33 71-189 122-267 30-46 82-113 116-149 56-60 60-67 47-85-27-39-155-291-155-305 1-8 45-43 99-79l97-64-7-47c-4-25-22-73-40-104-33-59-38-93-31-205 2-43-13-179-23-202-4-10-10-16-14-14-16 10-39-21-34-47 5-23 9-26 32-20 41 12 94 9 98-4 7-21-131-17-152 3-12 13-19 14-30 4-8-7-15-19-15-26 0-12 68-14 405-14 263 0 405 3 405 10 0 6-83 10-230 10h-230l-11 27c-7 20-6 28 3 35 24 15 136 8 272-17 167-31 201-31 351 0 123 25 190 30 283 18 47-5 53-8 50-27-3-21-8-21-235-24-198-2-233-5-233-17 0-13 54-15 409-15 406 0 409 0 404 20-7 27-43 48-43 25 0-22-34-19-56 6-15 17-16 22-4 29 9 6 17 5 22-3 4-6 10-8 14-4s-1 16-11 27c-14 16-21 18-28 8-6-9-7-8-3 5 3 10 0 20-9 23-7 3-11 12-8 20s0 21-7 29c-20 24-30 87-17 103 6 8 11 44 11 82-1 53-8 82-32 136-28 60-58 163-50 168 2 1 41 19 88 40s89 42 94 46c17 17-80 244-135 314l-20 25-44-30c-48-32-188-1e2-245-118-19-6-83-27-142-46-116-39-236-53-303-37-39 10-38 10 27 11 37 1 102 7 145 13l78 13-140 6c-209 10-363 60-526 169-192 130-358 370-403 587l-7 31 78 7c43 3 90 8 104 11l26 5 17-148c11-91 23-157 33-172 15-24 16-24 147-18 203 9 528 54 544 75 11 13 13 54 10 179-4 165-3 173 33 173 5 0 9-30 9-67 0-87 18-240 30-263 16-29 99-34 392-23 222 8 270 12 292 26l26 17v160 160h28c16 0 63 3 104 6l75 7 7-42c6-40 3-47-49-122-31-43-51-79-45-79s37 13 69 30c64 32 73 47 87 140 9 63 36 112 84 152 45 39 49 52 20 68-11 6-38 35-61 66-39 51-42 60-50 144-5 49-15 106-24 126-14 35-14 39 4 58 27 29 35 69 21 110-8 26-24 42-63 64-58 33-81 55-95 93-15 37 17 103 63 130 19 12 35 25 35 30 0 17-68 9-147-16-42-13-79-22-81-20-12 11 33 56 80 82l52 28-34 3c-22 2-52-6-92-27-32-17-65-31-73-31-25 0-108 46-155 85-57 48-142 85-192 85-46 0-57 5-163 76-81 54-192 94-262 94-21 0-54 15-99 45-36 25-69 45-72 45-2 0-2-14 2-32zm-143-641c-13-16-43-98-38-104 2-2 20 11 40 29s56 44 79 56l43 24-48-48c-31-30-64-79-94-138l-45-91 59 61c45 48 84 75 178 124 66 34 130 70 143 79 32 23 183 11 261-21 50-20 72-23 204-23 143 0 149 1 166 23l17 24 19-44c23-51 167-203 279-295 48-39 81-73 82-86 2-12 12-62 22-112 11-49 18-91 17-93-4-4-199 50-208 58-4 4-9 45-11 91l-3 84-83-1c-82-1-83-1-112 32-42 48-124 84-191 84-49 0-66-7-186-76-90-52-130-81-127-90 4-10-2-14-19-14-24 0-24-2-27-92-3-87-4-93-25-96-20-3-22 2-28 75-3 43-8 83-10 90-3 9-79 10-307 6-167-3-334-8-373-12-80-7-75 2-61-121l7-66-93-38c-51-21-99-41-107-44-12-4-13 5-8 49 4 30 14 76 23 102 14 42 23 51 68 74 30 15 88 63 142 117 70 71 106 118 162 212 58 1e2 82 130 134 172 65 53 78 62 59 39zm897-336c20-10 48-30 61-44l23-25-43-7c-71-9-389-41-389-39 0 7 120 94 155 112 53 28 142 29 193 3zm216-399c4-152 4-285 1-294-4-9-14-19-23-23s-143-9-298-12c-248-5-281-4-287 10-7 18-24 241-31 413l-6 122 113 12c61 6 184 20 272 30 88 9 181 18 206 19l46 1 7-278zm-810 171c16-80 37-505 26-516-17-16-580-71-593-58-5 5-10 28-13 52-2 31-1 37 4 19 5-16 17-26 32-28 23-4 421 34 469 44 13 3 21 7 18 10-2 3-114-7-247-21-134-14-247-22-251-18-10 11-53 448-45 468 5 13 42 15 265 15 181 0 262 3 267 11s-65 10-260 7c-217-3-268-6-280-18-12-13-13-33-1-150 8-74 14-151 13-170-1-40-23 141-34 277l-7 93 169 3c93 1 235 4 316 5l146 2 6-27zm-587-455c-2-13-4-3-4 22s2 35 4 23c2-13 2-33 0-45zM975 191c3-5 1-12-5-16-5-3-10 1-10 9 0 18 6 21 15 7zm210-59c-9-9-25 19-24 43 0 16 2 15 15-8 9-16 13-32 9-35zm-55 9c0-11-4-9-14 4-8 11-12 24-9 28 7 11 23-12 23-32zm1108 17c-2-6-10-14-16-16-7-2-10 2-6 12 7 18 28 22 22 4zm44-10c-7-7-12-8-12-2 0 14 12 26 19 19 2-3-1-11-7-17zm83 2c4-6-5-10-20-10s-24 4-20 10c3 6 12 10 20 10s17-4 20-10z"/><path d="M1260 2374c-42-23-1e2-75-1e2-89 0-4 16 7 35 24 56 49 95 65 155 65 66 0 115-23 214-1e2 71-57 90-63 121-40 16 12 6 20-116 90-131 74-137 76-199 75-49 0-76-7-110-25z"/><path d="M2070 2158c-102-11-189-25-195-30-7-7 2-9 30-4 104 16 474 48 489 43 15-6 16-32 14-244l-3-238-247-3c-141-1-248-6-248-11 0-9 469-4 498 5 10 3 12 58 10 251l-3 248-80 2c-44 0-163-8-265-19z"/><path d="M1969 1961c-62-62-20-171 66-171 27 0 44 8 66 29 62 62 20 171-66 171-27 0-44-8-66-29z"/><path d="M1414 1940c-60-24-73-112-25-161 39-38 87-39 130-3 26 22 31 33 31 71 0 77-65 122-136 93z"/><path d="M1512 1343c2-10 32-33 67-52 91-48 176-54 255-18 52 24 77 49 62 64-3 3-29-6-57-21-76-42-149-39-243 8-81 41-89 43-84 19z"/><path d="M933 693c15-2 39-2 55 0 15 2 2 4-28 4s-43-2-27-4z"/><path d="M2388 673c6-2 18-2 25 0 6 3 1 5-13 5s-19-2-12-5z"/><path d="M870 155c-6-8-10-19-8-24 1-6 8 1 15 14 13 28 11 31-7 10z"/><path d="M2546 157c3-10 9-15 12-12s0 11-7 18c-10 9-11 8-5-6z"/></g></svg></span><span>Yongfu's Blog</span></div><div class=site_nav><span class=nav_link><a href=/>Home</a></span>
<span class=nav_link><a href=/post/>Posts</a></span>
<span class=nav_link><a href=/about/>About</a></span>
<span class=nav_link><a href=/feed.xml>Subscribe</a></span></div></div><div class=main><article class=post><div class=article_header><div class=titles><h1>Demystifying Item Response Theory (1/4)</h1><p class=subtitle>Playing God through simulations</p></div><div class=meta><div class=tags><a href="/post/?tag=r">r</a>
<a href="/post/?tag=statistics">statistics</a>
<a href="/post/?tag=psychology">psychology</a>
<a href="/post/?tag=reproducibility">reproducibility</a></div><div class=date><span class=inline-icon><svg aria-hidden="true" focusable="false" data-prefix="far" data-icon="calendar-alt" class="svg-inline--fa fa-calendar-alt fa-w-14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="rgb(95, 95, 95)" d="M148 288h-40c-6.6.0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h48c26.5.0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3.0 6-2.7 6-6z"/></svg></span><span class=str>Feb 25, 2023</span></div></div></div><div class=article_content><figure><img src=irt.jpg style=width:70% alt="Ok, so these are the item characteristic curves. What then?"><figcaption aria-hidden=true><em>Ok, so these are the <a href=https://www.researchgate.net/figure/Item-characteristic-curves-Item-Response-Theory-IRT-1PL-model_fig1_342560715>item
characteristic curves</a>. What then?</em></figcaption></figure><h2 id=mysterious-item-response-theory>Mysterious Item Response Theory</h2><p><strong>Item response theory is <em>mysterious</em> and intimidating to students.</strong>
It is mysterious in the way it is presented in textbooks, at least in
introductory ones. The text often starts with an ambitious conceptual
introduction to IRT, which most students would be able to follow, but
with some confusion. Curious students might bear with the confusion and
expect it to resolve in the following text, only to find themselves
disappointed. At the point where the underlying statistical model should
be further elaborated, the text abruptly stops and tries to convince
readers to trust the results from black-box IRT software packages.</p><p>It isn’t that I have trust issues with black-box software, and I also
agree that it is impractical to understand all the details of model
estimation in IRT. Doing so would be similar to coding an IRT program
from scratch. The issue is that there is a huge gap here, between where
textbooks stopped explaining and where the confusing details of
statistical models should be hidden. Hence, students would be tricked
into believing that they have a <em>sufficient degree of understanding</em>,
but in reality, it is just blind faith.</p><p>A sufficient degree of understanding should allow the student to deploy
the learned skill to new situations. Therefore, a sufficient degree of
understanding of IRT models, for instance, should allow students to
extend and apply the models to analyses of <a href=https://en.wikipedia.org/wiki/Differential_item_functioning>differential item
functioning
(DIF)</a> and
<strong>differential rater functioning (DRF)</strong>.</p><p>I’m arguing here that there is a basic granularity of understanding,
somewhat similar to the concept of <a href=https://en.wikipedia.org/wiki/Basic_category>basic-level
category</a>, that when
reached, allows a student to smoothly adapt the learned skill to a wide
variety of situations, modifying and extending the skill on demand. And
I believe that item response theory is <em><strong>too hard</strong></em> for a student to
learn and reach this basic level of understanding, due to its
conventional presentation and historical development<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>.</p><p>There is still hope however, thanks to the development of a very general
set of statistical models known as the <a href=https://en.wikipedia.org/wiki/Generalized_linear_model>Generalized Linear Models
(GLM)</a>. Item
response models could be understood in terms of the GLM and its
extensions
(<a href=https://en.wikipedia.org/wiki/Generalized_linear_mixed_model>GLMM</a>
and non-linear form of GLM/GLMM). To be too particular about the
details, the results from IRT software packages and GLMs/GLMMs would be
very close but not identical, since they utilize different estimation
methods. The strengths of GLM, however, lie in its conceptual simplicity
and extensibility. Through GLM, IRT and other models such as the T-test,
ANOVA, and linear regression, are all placed together into the same
conceptual framework. Furthermore, software packages implementing GLMs
are widely available. Users can thus experiment with them—simulate a set
of data based on known parameters, construct the model and feed it the
data, and see if the fitted model correctly recovers the parameters.
This technique of learning statistics is probably the only effective way
for students to understand <em><strong>a mysterious statistical model</strong></em>.</p><p>In this series of posts, I will walk the readers through the path of
understanding item response theory, with help from simulations and
generalized linear models. No need to worry if you don’t know GLMs yet.
We have another ally—<a href=https://www.r-project.org>R</a>, in which we will be
simulating artificial data and fitting statistical models along the way.
Although it might seem intimidating at first, coding simulations and
models in fact provides scaffolding for learning. When feeling unsure or
confused, you can always resort to these simulation-based experiments to
resolve the issues at hand. In this very first post, I will start by
teaching you <em><strong>simulations</strong></em>.</p><h2 id=just-enough-theory-to-get-started>Just Enough Theory to Get Started</h2><p>Jargons aside, the concept behind item response theory is fairly simple.
Consider the case where 80 testees are taking a 20-item English
proficiency test. Under this situation, what are the <em><strong>factors</strong></em> that
influence whether an item is correctly answered by a testee?
Straightforward right? If an item is easy and if a testee is proficient
in English, he/she would probably get the item correct. Here, <em><strong>two
factors jointly influence the result</strong></em>:</p><ol><li>how difficult (or easy) an item is</li><li>the English ability of a testee</li></ol><p>We can express these variables and the relations between them in the
graphs below. Let’s focus on the left one first. Here, $A$ represents
the <strong>ability</strong> of the testee, $D$ represents the <strong>difficulty</strong> of the
item, and $R$ represents the <strong>item response</strong>, or <strong>score</strong> on the
item. A response for an item is coded as <code>1</code> ($R=1$) if it is correctly
answered. Otherwise, it is coded as <code>0</code> ($R=0$). The arrows $A$ → $R$
and $D$ → $R$ indicate the direction of influence. The arrows enter $R$
since item difficulty and testee ability influence the score on the item
(not the other way around). $A$ and $D$ are drawn as a circled node to
indicate that they are <strong>unobserved</strong> (or <strong>latent</strong>, if you prefer a
fancier term), whereas uncircled nodes represent directly observable
variables (i.e., stuff that gets recorded during data collection). This
graphical representation of the variable and their relationships is
known as a <a href=https://en.wikipedia.org/wiki/Directed_acyclic_graph>Directed Acyclic Graph
(DAG)</a>.</p><div class="goat svg-container"><svg xmlns="http://www.w3.org/2000/svg" font-family="Menlo,Lucida Console,monospace" viewBox="0 0 352 137"><g transform="translate(8,16)"><path d="M272 16h32" fill="none" stroke="currentcolor"/><path d="M152 16V96" fill="none" stroke="currentcolor"/><path d="M24 80 40 48" fill="none" stroke="currentcolor"/><path d="M216 80l16-32" fill="none" stroke="currentcolor"/><path d="M72 48 88 80" fill="none" stroke="currentcolor"/><path d="M264 48l16 32" fill="none" stroke="currentcolor"/><polygon points="52.000000,48.000000 40.000000,42.400002 40.000000,53.599998" fill="currentcolor" transform="rotate(300.000000, 40.000000, 48.000000)"/><polygon points="84.000000,48.000000 72.000000,42.400002 72.000000,53.599998" fill="currentcolor" transform="rotate(240.000000, 72.000000, 48.000000)"/><path d="M232 48l8-16" fill="none" stroke="currentcolor"/><polygon points="250.000000,48.000000 238.000000,42.400002 238.000000,53.599998" fill="currentcolor" transform="rotate(300.000000, 232.000000, 48.000000)"/><path d="M256 32l8 16" fill="none" stroke="currentcolor"/><polygon points="282.000000,48.000000 270.000000,42.400002 270.000000,53.599998" fill="currentcolor" transform="rotate(240.000000, 264.000000, 48.000000)"/><polygon points="312.000000,16.000000 300.000000,10.400000 300.000000,21.600000" fill="currentcolor" transform="rotate(0.000000, 304.000000, 16.000000)"/><path d="M248 0A16 16 0 00232 16" fill="none" stroke="currentcolor"/><path d="M248 0a16 16 0 0116 16" fill="none" stroke="currentcolor"/><path d="M232 16a16 16 0 0016 16" fill="none" stroke="currentcolor"/><path d="M264 16A16 16 0 01248 32" fill="none" stroke="currentcolor"/><path d="M16 80A16 16 0 000 96" fill="none" stroke="currentcolor"/><path d="M16 80A16 16 0 0132 96" fill="none" stroke="currentcolor"/><path d="M96 80A16 16 0 0080 96" fill="none" stroke="currentcolor"/><path d="M96 80a16 16 0 0116 16" fill="none" stroke="currentcolor"/><path d="M208 80A16 16 0 00192 96" fill="none" stroke="currentcolor"/><path d="M208 80a16 16 0 0116 16" fill="none" stroke="currentcolor"/><path d="M288 80A16 16 0 00272 96" fill="none" stroke="currentcolor"/><path d="M288 80a16 16 0 0116 16" fill="none" stroke="currentcolor"/><path d="M0 96a16 16 0 0016 16" fill="none" stroke="currentcolor"/><path d="M32 96A16 16 0 0116 112" fill="none" stroke="currentcolor"/><path d="M80 96a16 16 0 0016 16" fill="none" stroke="currentcolor"/><path d="M112 96A16 16 0 0196 112" fill="none" stroke="currentcolor"/><path d="M192 96a16 16 0 0016 16" fill="none" stroke="currentcolor"/><path d="M224 96a16 16 0 01-16 16" fill="none" stroke="currentcolor"/><path d="M272 96a16 16 0 0016 16" fill="none" stroke="currentcolor"/><path d="M304 96a16 16 0 01-16 16" fill="none" stroke="currentcolor"/><text text-anchor="middle" x="16" y="100" fill="currentcolor" style="font-size:1em">A</text><text text-anchor="middle" x="56" y="20" fill="currentcolor" style="font-size:1em">R</text><text text-anchor="middle" x="96" y="100" fill="currentcolor" style="font-size:1em">D</text><text text-anchor="middle" x="208" y="100" fill="currentcolor" style="font-size:1em">A</text><text text-anchor="middle" x="248" y="20" fill="currentcolor" style="font-size:1em">P</text><text text-anchor="middle" x="288" y="100" fill="currentcolor" style="font-size:1em">D</text><text text-anchor="middle" x="328" y="20" fill="currentcolor" style="font-size:1em">R</text></g></svg></div><p>The DAGs laid out here represent the concept behind the simplest kinds
of item response models, known as the <strong>1-parameter logistic (1PL)
model</strong> (or Rasch Model). In more formal terms, this model posits that
the <strong>probability</strong> of correctly answering an item is determined by the
<strong>difference</strong> between testee ability and item difficulty. So a more
precise DAG representation for this model would be the one shown on the
right above. Here, $P$ is the probability of correctly answering the
item, which cannot be directly observed. However, $P$ directly
influences the item score $R$, hence the arrow $P$ → $R$.</p><p>Believe it or not, the things we have learned so far could get us
started. So let’s simulate some data, based on what we know about item
response theory!</p><h2 id=simulating-item-responses>Simulating Item Responses</h2><figure><img src=tenet2.gif style=width:85% alt="Simulation is playing god in a small world. Similar to model fitting, but in reverse direction."><figcaption aria-hidden=true>Simulation is <em>playing god</em> in a
small world. Similar to model fitting, but in <em>reverse</em>
direction.</figcaption></figure><p>Consider the scenario where 3 students (Rob, Tom, and Joe) took a math
test with 2 items (A and B). Since we play gods during simulations, we
know the math ability of the students and the difficulty of the items.
These ability/difficulty levels can range from positive to negative
numbers, unbounded. Larger numbers indicate higher levels of
difficulty/ability. In addition, the levels of difficulty and ability
sit on a common scale, and hence could be directly compared. Also, each
student answers every item, so we get responses from all 6 (3x2)
combinations of students and items. Let’s code this in R. The function
<code>expand.grid()</code> would pair up the 6 combinations for us.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>D <span style=color:#f92672>=</span> <span style=color:#a6e22e>c</span>( A<span style=color:#f92672>=</span><span style=color:#ae81ff>0.4</span>, B<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span> )  <span style=color:#75715e># Difficulty of item</span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span>A <span style=color:#f92672>=</span> <span style=color:#a6e22e>c</span>( R<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, T<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>, J<span style=color:#f92672>=</span><span style=color:#ae81ff>-0.4</span> )  <span style=color:#75715e># Ability of student (R:Rob, T:Tom, J:Joe)</span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3</span><span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4</span><span>dat <span style=color:#f92672>=</span> <span style=color:#a6e22e>expand.grid</span>( 
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5</span><span>   I <span style=color:#f92672>=</span> <span style=color:#a6e22e>c</span>( <span style=color:#e6db74>&#34;A&#34;</span>, <span style=color:#e6db74>&#34;B&#34;</span> ),      <span style=color:#75715e># Item index</span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6</span><span>   T <span style=color:#f92672>=</span> <span style=color:#a6e22e>c</span>( <span style=color:#e6db74>&#34;R&#34;</span>, <span style=color:#e6db74>&#34;T&#34;</span>, <span style=color:#e6db74>&#34;J&#34;</span> )  <span style=color:#75715e># Testee index</span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7</span><span>)
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">8</span><span>dat
</span></span></code></pre></div><pre><code># A tibble: 6 × 2
  I     T    
  &lt;fct&gt; &lt;fct&gt;
1 A     R    
2 B     R    
3 A     T    
4 B     T    
5 A     J    
6 B     J    
</code></pre><p>After having all possible combinations of the students and the items, we
could collect the values of student ability and item difficulty into the
data frame.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>dat<span style=color:#f92672>$</span>A <span style=color:#f92672>=</span> A[ dat<span style=color:#f92672>$</span>T ]  <span style=color:#75715e># map ability to df by testee index T</span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span>dat<span style=color:#f92672>$</span>D <span style=color:#f92672>=</span> D[ dat<span style=color:#f92672>$</span>I ]  <span style=color:#75715e># map difficulty to df by item index I</span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3</span><span>dat
</span></span></code></pre></div><pre><code># A tibble: 6 × 4
  I     T         A     D
  &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt;
1 A     R       0.5   0.4
2 B     R       0.5   0.1
3 A     T       0.1   0.4
4 B     T       0.1   0.1
5 A     J      -0.4   0.4
6 B     J      -0.4   0.1
</code></pre><p>Now, we’ve got all the data needed for simulation, the only thing left
is to precisely lay out the <strong>rules for generating the response data
$R$</strong>—the scores (zeros and ones) on the items answered by the students.
We are two steps away.</p><h3 id=generating-probabilities>Generating Probabilities</h3><p>When IRT is introduced in the previous section, I mention that the
probability of success on an item is determined by the <strong>difference
between testee ability and item difficulty</strong>. It is straightforward to
get this difference: simply subtract $D$ from $A$ in the data. This
would give us a new variable $\mu$. I save the values of $\mu$ to column
<code>Mu</code> in the data frame.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>dat<span style=color:#f92672>$</span>Mu <span style=color:#f92672>=</span> dat<span style=color:#f92672>$</span>A <span style=color:#f92672>-</span> dat<span style=color:#f92672>$</span>D
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span>dat
</span></span></code></pre></div><pre><code># A tibble: 6 × 5
  I     T         A     D    Mu
  &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 A     R       0.5   0.4   0.1
2 B     R       0.5   0.1   0.4
3 A     T       0.1   0.4  -0.3
4 B     T       0.1   0.1   0  
5 A     J      -0.4   0.4  -0.8
6 B     J      -0.4   0.1  -0.5
</code></pre><p>From the way $\mu$ is calculated ($A$ - $D$), we can infer that, for a
particular observation, if $\mu$ is positive and large, the testee’s
ability will be much greater than the item’s difficulty, and he would
probably succeed on this item. On the other hand, if $\mu$ is negative
and small, the item difficulty would be much greater in this case, and
the testee would likely fail on this item. Hence, $\mu$ is directly
related to probability, in that $\mu$ of large values result in high
probabilities of success on the items, whereas $\mu$ of small values
result in low probabilities of success. But how exactly is $\mu$ linked
to probability? How could we map $\mu$ to probability in a principled
manner? The solution is to take advantage of the <a href=https://en.wikipedia.org/wiki/Logistic_function>logistic
function</a>.</p><p>$$
logistic( x ) = \frac{ 1 }{ 1 + e^{-x} }
$$</p><p>The <em><strong>logistic</strong></em> is a function that maps a real number $x$ to a
probability $p$. In other words, the logistic function transforms the
input $x$ and constrains it to a value between zero and one. Note that
the transformation is <strong>monotonic increasing</strong>, meaning that a smaller
$x$ would be mapped onto a smaller $p$, and a larger $x$ would be mapped
onto a larger $p$. The ranks of the values before and after the
transformation stay the same. To have a feel of what the logistic
function does, let’s transform some values with the logistic.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span><span style=color:#75715e># Set plot margins  # (b, l, t, r)</span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span><span style=color:#a6e22e>par</span>(oma<span style=color:#f92672>=</span><span style=color:#a6e22e>c</span>(<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>0</span>))  <span style=color:#75715e># Outer margin</span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3</span><span><span style=color:#a6e22e>par</span>(mar<span style=color:#f92672>=</span><span style=color:#a6e22e>c</span>(<span style=color:#ae81ff>4.5</span>, <span style=color:#ae81ff>4.5</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>) )  <span style=color:#75715e># margin</span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4</span><span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5</span><span>logistic <span style=color:#f92672>=</span> <span style=color:#a6e22e>function</span>(x) <span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> ( <span style=color:#ae81ff>1</span> <span style=color:#f92672>+</span> <span style=color:#a6e22e>exp</span>(<span style=color:#f92672>-</span>x) )
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6</span><span>x <span style=color:#f92672>=</span> <span style=color:#a6e22e>seq</span>( <span style=color:#ae81ff>-5</span>, <span style=color:#ae81ff>5</span>, by<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span> )
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7</span><span>p <span style=color:#f92672>=</span> <span style=color:#a6e22e>logistic</span>( x )
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">8</span><span><span style=color:#a6e22e>plot</span>( x, p )
</span></span></code></pre></div><p><img src=part1_files/figure-commonmark/unnamed-chunk-4-1.svg style=width:100% data-fig-align=center></p><p>As the plot shows, the logistic transformation results in an S-shaped
curve. Since the transformed values (p) are bounded by 0 and 1, extreme
values on the poles of the x-axis would be “squeezed” after the
transformation. Real numbers with absolute values greater than 4, after
transformations, would have probabilities very close to the boundaries.</p><h4 id=less-math-less-confusion>Less Math, Less Confusion</h4><p>For many students, the mathematical form of the logistic function leads
to confusion. Staring at the math symbols hardly enables one to arrive
at any insightful interpretation of the logistic. A suggestion here is
to let go of the search for such an interpretation. The logistic
function is introduced not because it is loaded with some crucial
mathematical or statistical meaning. Instead, it is used here solely for
a practical reason: to monotonically map real numbers to probabilities.
You may well use another function here to achieve the same purpose
(e.g., the <strong>cumulative distribution function</strong> for the normal
distribution).</p><h3 id=generating-responses>Generating Responses</h3><p>We have gone all the way from ability/difficulty levels to the
probabilities of success on the items. Since we cannot directly observe
probabilities in the real world, the final step is to link these
probabilities to observable outcomes. In the case here, the outcomes are
simply item responses of zeros and ones. How do we map probabilities to
zeros and ones? Coin flips, or <a href=https://en.wikipedia.org/wiki/Bernoulli_distribution>Bernoulli
distributions</a>,
will get us there.</p><p>Every time a coin is flipped, either a tail or a head is observed. The
Bernoulli distribution is just a fancy way of describing this process.
Assume that we record tails as <code>0</code>s and heads as <code>1</code>s, and suppose that
the probability $p$ of observing a head equals 0.75 (since the coin is
imbalanced in some way that the head is more likely observed and we know
it somehow). Then the distribution of the outcomes (zero and one) is a
Bernoulli distribution with parameter $P=0.75$. In graphical terms, the
distribution is just two bars.</p><p><img src=part1_files/figure-commonmark/unnamed-chunk-5-1.svg style=width:100% data-fig-align=center></p><p>We’ve got all we need by now. Let’s construct the remaining columns to
complete this simulation. In the code below, I compute the probabilities
(<code>P</code>) from column <code>Mu</code>. Column <code>P</code> could then generate column <code>R</code>, the
item responses, through the Bernoulli distribution.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>rbern <span style=color:#f92672>=</span> <span style=color:#a6e22e>function</span>( p, n<span style=color:#f92672>=</span><span style=color:#a6e22e>length</span>(p) ) 
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span>   <span style=color:#a6e22e>rbinom</span>( n<span style=color:#f92672>=</span>n, size<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, prob<span style=color:#f92672>=</span>p )
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3</span><span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4</span><span><span style=color:#a6e22e>set.seed</span>(<span style=color:#ae81ff>13</span>)
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5</span><span>dat<span style=color:#f92672>$</span>P <span style=color:#f92672>=</span> <span style=color:#a6e22e>logistic</span>( dat<span style=color:#f92672>$</span>Mu )
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6</span><span>dat<span style=color:#f92672>$</span>R <span style=color:#f92672>=</span> <span style=color:#a6e22e>rbern</span>( dat<span style=color:#f92672>$</span>P ) <span style=color:#75715e># Generate 0/1 from Bernoulli distribution</span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7</span><span>dat
</span></span></code></pre></div><pre><code># A tibble: 6 × 7
  I     T         A     D    Mu     P     R
  &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;
1 A     R       0.5   0.4   0.1 0.525     0
2 B     R       0.5   0.1   0.4 0.599     1
3 A     T       0.1   0.4  -0.3 0.426     0
4 B     T       0.1   0.1   0   0.5       0
5 A     J      -0.4   0.4  -0.8 0.310     1
6 B     J      -0.4   0.1  -0.5 0.378     0
</code></pre><p>Now, we have a complete table of simulated item responses. A few things
to notice here. First, look at the fourth row of the data frame, where
the response of testee T (Tom) on item B is recorded. Column <code>Mu</code> has a
value of zero since Tom’s ability level is identical to the difficulty
of item B. What does it mean to be “identical”? “Identical” implies that
Tom is neither more likely to succeed nor to fail on item B. Hence, you
can see that Tom has a 50% of getting item B correct in the $P$ column.
This is how the ability/difficulty levels and $\mu$ are interpreted.
They are on an abstract scale of real numbers. We need to convert them
to probabilities to make sense of them.</p><p>The second thing to notice is column <code>R</code>. This is the only column that
has <em><strong>randomness</strong></em> introduced. Every run of the simulation would
likely give different values of $R$ (unless a random seed is set, or the
<code>P</code> column consists solely of zeros and ones). The outcomes are not
guaranteed, probability is at work.</p><p>The presence of such randomness is the gist of simulations and
statistical models. We add uncertainty to the simulation, mimicking the
real world, to know that in the presence of such uncertainty, would it
still be possible to discover targets of interest with a statistical
model. Randomness, however, poses some challenges for coding. We need to
equip ourselves for those challenges.</p><h2 id=coding-randomness>Coding Randomness</h2><p>Randomness is inherent in simulations and statistical models, so it is
impossible to run away from it. It is everywhere. The problem with
randomness is that it introduces uncertainty in the outcome produced.
Thus, it would be hard to spot any errors just by <strong>eyeballing the
results</strong>.</p><p>Take <code>rbern()</code> for instance. Given a parameter $P=0.5$, we can
repeatedly run <code>rbern(0.5)</code> a couple of times to produce zeros and ones.
But these zeros and ones cannot tell us whether <code>rbern(0.5)</code> is working
properly. <code>rbern(0.5)</code> might be broken somehow, and instead generates
the ones with, say, $P=0.53$.</p><p>The <a href=https://en.wikipedia.org/wiki/Law_of_large_numbers>law of large
numbers</a> can help us
here. Since <code>rbern()</code> generates one with probability $P$, if we run
<code>rbern()</code> many times, the proportion of one in the outcomes should
converge to $P$. To achieve this, take a look at the second argument <code>n</code>
in <code>rbern()</code>. You can increase <code>n</code> to see if the result comes even
closer to $0.5$.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>outcomes <span style=color:#f92672>=</span> <span style=color:#a6e22e>rbern</span>( p<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, n<span style=color:#f92672>=</span><span style=color:#ae81ff>1e4</span> )  <span style=color:#75715e># Run rbern with P=0.5 10,000 times</span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span><span style=color:#a6e22e>mean</span>(outcomes)
</span></span></code></pre></div><pre><code>[1] 0.4991
</code></pre><p>A more general way to rerun a chunk of code is through the for loop or
convenient wrappers such as the <code>replicate()</code> function.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>outcomes <span style=color:#f92672>=</span> <span style=color:#a6e22e>replicate</span>( n<span style=color:#f92672>=</span><span style=color:#ae81ff>1e4</span>, expr<span style=color:#f92672>=</span>{ <span style=color:#a6e22e>rbern</span>( p<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span> ) } )
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span><span style=color:#a6e22e>mean</span>(outcomes)
</span></span></code></pre></div><pre><code>[1] 0.5027
</code></pre><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-r data-lang=r><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1</span><span><span style=color:#75715e># See if several runs of rbern( p=0.5, n=1e4 ) give results around 0.5</span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2</span><span>Ps <span style=color:#f92672>=</span> <span style=color:#a6e22e>replicate</span>( n<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>, expr<span style=color:#f92672>=</span>{
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3</span><span>   outcomes <span style=color:#f92672>=</span> <span style=color:#a6e22e>rbern</span>( p<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, n<span style=color:#f92672>=</span><span style=color:#ae81ff>1e4</span> )
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4</span><span>   <span style=color:#a6e22e>mean</span>(outcomes)
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5</span><span>})
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6</span><span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7</span><span><span style=color:#75715e># Plot Ps to see if they scatter around 0.5</span>
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8</span><span><span style=color:#a6e22e>plot</span>( <span style=color:#ae81ff>1</span>, type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;n&#34;</span>, xlim<span style=color:#f92672>=</span><span style=color:#a6e22e>c</span>(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>100</span>), ylim<span style=color:#f92672>=</span><span style=color:#a6e22e>c</span>(<span style=color:#ae81ff>0.47</span>, <span style=color:#ae81ff>0.53</span>), ylab<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;P&#34;</span> )
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9</span><span><span style=color:#a6e22e>abline</span>( h<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, lty<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;dashed&#34;</span> )
</span></span><span style=display:flex><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10</span><span><span style=color:#a6e22e>points</span>( Ps, pch<span style=color:#f92672>=</span><span style=color:#ae81ff>19</span>, col<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span> )
</span></span></code></pre></div><p><img src=part1_files/figure-commonmark/unnamed-chunk-9-1.svg style=width:100% data-fig-align=center></p><h3 id=randomness-in-models>Randomness in Models</h3><p>The method described above works only for simple cases. What about
complex statistical models? How do we test that they are working as they
claim to? Guess what? <em><strong>Simulation</strong></em> is the key.</p><p>We simulate data based on the assumptions of the statistical model and
see if it indeed returns what it claims to estimate. The simulation can
be repeated several times, each set to different values of parameters.
If the parameters are always recovered by the statistical model, we can
then be confident that the model is properly constructed and correctly
coded. So <strong>simulation is really <em>not an option</em> when doing
statistics</strong>. It is the only safety that helps us guard against bugs in
our statistical models, both programmatical and theoretical ones.
Without first testing the statistical model on simulated data, any
inferences about the empirical data are in doubt.</p><h2 id=whats-next>What’s next?</h2><p>In a real-world scenario of the example presented here, we would only
observe the score ($R$) of an item ($I$) taken by a testee ($T$). The
targets of interest are the unobserved item difficulty ($D$) and testee
ability ($A$). In <a href=/irt2>Part 2</a>, we will work in reverse and fit
statistical models on simulated data. We will see how the models
discover the true $A$s and $D$s from the information of $R$, $I$, and
$T$. See you there!</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>I mean, what the hack is <em>Joint/Conditional Maximum Likelihood
Estimation</em>? These are methods developed in psychometrics and are
hardly seen in other fields. Unless obsessed with psychometrics, I
don’t think one would be able to understand these things.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><br><br><br><script src=https://utteranc.es/client.js repo=liao961120/comments issue-term=title theme=github-light crossorigin=anonymous async></script><div class=next-prev><div><span>PREV</span>
<a href=https://yongfu.name/2023/02/15/snakemake/>A Minimalist Structure for Snakemake</a></div><div><span>NEXT</span>
<a href=https://yongfu.name/2023/03/06/irt2/>Demystifying Item Response Theory (2/4)</a></div></div></article><aside class="toc toc-right js-toc relative z-1 transition--300 absolute pa4 pt5 is-position-fixed"></aside></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.11.1/tocbot.min.js></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.11.1/tocbot.css><script>tocbot.init({tocSelector:".js-toc",contentSelector:".article_content",headingSelector:"h2, h3, h4",scrollSmooth:!1,hasInnerContainers:!0,collapseDepth:3})</script><style>ol.toc-list{list-style-type:none}aside{position:fixed;top:15%!important;right:2%}.next-prev{margin-top:2.5em;border-top:2px solid rgba(173,173,173,.548);display:flex;flex-wrap:wrap;justify-content:space-between}.next-prev>div{min-width:150px;width:43%}.next-prev>div>span{display:block;width:100%;color:grey;font-weight:600;letter-spacing:1.5px;padding-bottom:.3rem;margin-top:.4rem}.next-prev>div:nth-child(2){text-align:right}.next-prev>div>a{text-decoration:none;color:#000;font-weight:600}</style><footer><div class=social><span class=icon title="Send me an email"><a href=mailto:liao961120@gmail.com target=_blank><span class="social email"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="envelope" class="svg-inline--fa fa-envelope fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="#fff" d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V4e2c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5.0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg></span></a></span><span class=icon title="Follow me on Twitter"><a href=https://twitter.com/liao_yongfu target=_blank><span class="social twitter"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="twitter" class="svg-inline--fa fa-twitter fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="#fff" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></a></span><span class=icon title="Follow me on Facebook"><a href=https://www.facebook.com/liao961120 target=_blank><span class="social facebook"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="facebook-f" class="svg-inline--fa fa-facebook-f fa-w-10" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="#fff" d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43.0 225.36.0c-73.22.0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z"/></svg></span></a></span><span class=icon title="Follow me on GitHub"><a href=https://github.com/liao961120 target=_blank><span class="social github"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" class="svg-inline--fa fa-github fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="#fff" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></span></div><p class=site_info><span class=copyright>© Yongfu's Blog 2017-2023</span></p><p class=theme_info>Powered by <a href=https://gohugo.io target=_blank>Hugo</a> & <a href=https://github.com/liao961120/TeXtLite target=_blank>TeXtLite Theme</a>.</p></footer><script src=//yihui.org/js/math-code.js defer></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1})})</script><div class=scrollBtn><span id=scrolltop onclick=window.scrollTo(0,0)>&#9650;</span>
<span id=scrollbottom onclick=window.scrollTo(0,document.body.scrollHeight)>&#9660;</span></div><style>div.scrollBtn{display:flex;flex-wrap:wrap;width:1em;position:fixed;bottom:1.1%;right:.8%}#scrolltop,#scrollbottom{line-height:1;font-size:1.4rem;color:var(--link-transitiion-light)}#scrolltop:hover,#scrollbottom:hover{cursor:pointer;color:green;font-size:1.6rem}</style><script src=https://unpkg.com/@popperjs/core@2></script>
<script src=https://unpkg.com/tippy.js@6></script>
<link rel=stylesheet href=https://unpkg.com/tippy.js@6/themes/light-border.css><script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll('a[href^="#fn"]:not(.footnote-backref)').forEach(e=>{const t=new URL(e.href).hash;console.log(t),tippy(e,{content:document.getElementById(t.substring(1)).innerHTML,allowHTML:!0,theme:"light-border"})})})</script></body></html>
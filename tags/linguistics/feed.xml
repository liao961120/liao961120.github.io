<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Linguistics on Yongfu's Blog</title><link>https://yongfu.name/tags/linguistics/</link><description>Recent content in Linguistics on Yongfu's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 03 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://yongfu.name/tags/linguistics/feed.xml" rel="self" type="application/rss+xml"/><item><title>我的 R 開放課程</title><link>https://yongfu.name/2021/06/03/my-r-course/</link><pubDate>Thu, 03 Jun 2021 00:00:00 +0000</pubDate><guid>https://yongfu.name/2021/06/03/my-r-course/</guid><description>&lt;p>這學期 (109-2) 第二次擔任課程助教，給大學部的同學們上 R 語言。第二次教學，在熱情上減了一半，在教材難度上增加了一半。大概是因為不喜歡重複做一樣的事，這次課程刻意補了上一次 (&lt;a href="https://rlads2019.github.io/lab/">108-1&lt;/a>) 懶得教&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>、沒時間教&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>、沒自信可以教&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>以及沒有能力教&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>的內容。有了這些新的內容，課程準備起來就比較提得起勁，畢竟知道在去年已經教過的內容上，現在的我實在很難超越當時的自己&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>。不過，在準備教材的同時，也可以看到自己這一陣子的轉變：對某些概念的認識更加地完整、思緒變得更複雜迅速有條理。能發現這些真的蠻開心的，至少腦袋還是有長一些。擴增教材的另一個目的，是為了補齊上一次未能 (學會然後) 教的缺憾，大概是一種想把圓畫完整的感覺，當然圓不可能畫得完美&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>，不過整體來說，完整的感覺還是大過缺憾許多，也蠻值得開心的。&lt;/p>
&lt;p>這次的課程全部採取事前錄製影片的方式授課，表面上的目的是擔心遠距教學的情形再度出現 (結果真的出現了&amp;hellip;)，實際上的目的則是跟剛剛一樣：我不想要做同樣的事情 (實體授課)，而且這次實體授課大概也不會講得比上次好，所以不如換一種方式授課&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>。結果無心插柳，最後幾堂課因為突來的疫情改成遠距教學，對我反倒沒造成什麼影響，又是件值得開心的事情。&lt;/p>
&lt;p>在經歷 12 個頗為漫長的週末，終於完成了這個算是完整的 R 語言課程。在這 12 堂課中，或許值得慶幸的一件事情是課程內容主題都不是 state-of-the-art。在能夠選擇時，選擇了去講比較穩定不變的東西、比較不會經過兩三年後就變成歷史名詞的技術或概念。這麼做或許可以讓課程的保鮮期變得比較長，也或許可以讓更多人從這個課程中受惠。這 12 堂課程的完整內容 (影片/簡報/講義/作業/程式碼) 可以在這個&lt;a href="https://rlads2021.github.io/archives/">頁面&lt;/a>取得，歡迎讀者自行使用、分享或是修改並應用於教學之中。&lt;/p>
&lt;p>
&lt;figure>
&lt;img src="https://img.yongfu.name/posts/rlads2021.png" alt="2021 課程影片">
&lt;figcaption>2021 課程影片&lt;/figcaption>
&lt;/figure>
&lt;/p>
&lt;p>整個學期下來，雖然過得平淡、沒有第一次授課時那種短時間內大量成長的感覺，不過反倒是有種&lt;strong>比較完整地完成了一件事情&lt;/strong>的感覺。這種感覺不會讓人大喜大悲、異常緊張或是過度興奮，但會讓心裡變得厚實舒坦，讓內心安穩一些，然後微微的喜悅就會從心底緩慢而持續地湧出。&lt;/p>
&lt;p>最後，還要特別感謝 Andrea、Yulin、Mao-Chang 以及 Amber 在各個方面的協助，這門課的學生能有你們的照顧真的很幸運。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>Lab01: &lt;a href="https://rlads2021.github.io/LabBook/ch01">路徑、終端機、R101&lt;/a> (絕對與相對路徑 &amp;amp; Terminal)&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>Lab12: &lt;a href="https://rlads2021.github.io/LabBook/ch12">專案成果展示&lt;/a> (Shiny)&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>Lab09: &lt;a href="https://rlads2021.github.io/LabBook/ch09">文本與詞彙的向量表徵&lt;/a> (document-term matrix &amp;amp; latent semantic analysis)&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4">
&lt;p>Lab06: &lt;a href="https://rlads2021.github.io/LabBook/ch06">Simulating Data with R&lt;/a> (Causal inference 101)&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5">
&lt;p>那時多有熱情和自信啊！反觀現在真的很難被激勵，不過往好處想或許這代表掌握情緒的能力有所提昇？&amp;#160;&lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6">
&lt;p>像是這次在教 Web API 時拿來示範用的 Public API 在我上傳教學影片之後就關閉服務了&amp;hellip;&amp;#160;&lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7">
&lt;p>這樣就不用和過去的自己硬碰硬比較，擔心自己退步了 (反正我有錄影片，觸及的人就是比較廣比較潮啦！108-1 的你輸了啦哈哈哈哈哈)。比較不見得會進步，但一定會帶來傷害，所以換個方式讓自己沒辦法去比較或許也不錯。&amp;#160;&lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description><category>R</category><category>Course</category><category>statistics</category><category>linguistics</category><category>中文</category></item><item><title>Searching Interlinear Glosses Written in Word Documents</title><link>https://yongfu.name/2020/04/23/gloss-search/</link><pubDate>Thu, 23 Apr 2020 00:00:00 +0000</pubDate><guid>https://yongfu.name/2020/04/23/gloss-search/</guid><description>&lt;p>I am taking the course &lt;a href="https://nol2.aca.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=142%20M0210&amp;amp;class=&amp;amp;dpt_code=1420&amp;amp;ser_no=10017&amp;amp;semester=108-2&amp;amp;lang=EN">Linguistic Fieldwork&lt;/a> this semester. Each week, we record and transcribe Budai Rukai, an Austronesian language spoken by &lt;a href="https://en.wikipedia.org/wiki/Rukai_people">Rukai people (魯凱族)&lt;/a>. The resulting data (interlinear glosses) are written in a Word document (&lt;code>.docx&lt;/code>) as required by the course instructor. Things get worse as the number of documents accumulates each week, since it becomes harder to locate specific linguistic patterns in the corpus of texts, as they are spread across multiple documents.&lt;/p>
&lt;p>Inspired by &lt;a href="https://github.com/puerdon/corpus_processor">the work&lt;/a> of my labmate, &lt;a href="https://github.com/puerdon">Don&lt;/a>, I created a web app for searching interlinear glosses, which can search for and locate specific patterns in a collection of Word documents. This post describe the web app&amp;rsquo;s basic design and improvements to &lt;a href="https://github.com/puerdon/corpus_processor">&lt;code>puerdon/corpus_processor&lt;/code>&lt;/a>, the project this web app got inspiration and succeeded from. For instructions about using the app, visit &lt;a href="https://github.com/liao961120/gloss-search">&lt;code>liao961120/gloss-search&lt;/code>&lt;/a> (&lt;a href="https://github.com/liao961120/gloss-search/blob/master/README-en.md">English&lt;/a>) for more details.&lt;/p>
&lt;img src="https://img.yongfu.name/gif/gloss-search.gif" style="width:100%">
&lt;h2 id="basic-design">Basic Design&lt;/h2>
&lt;p>The app&amp;rsquo;s frontend was built with &lt;a href="https://vuejs.org">Vue.js&lt;/a>, and the backend was written in &lt;a href="https://python.org">Python 3&lt;/a>. The frontend was designed to ease the search and locating of certain patterns in the Word documents and is the only interface the users need to interact with. The backend is used to (1) parse the glosses written in Word documents into Python objects (dictionaries) and (2) perform the search on these Python objects based on the requests sent from the frontend.&lt;/p>
&lt;h2 id="backend">Backend&lt;/h2>
&lt;p>The most challenging part of the backend program is that of (1) since Word is a &lt;a href="https://en.wikipedia.org/wiki/WYSIWYG">WYSIWYG&lt;/a> editing software, which means that two Word documents could have the exact same appearance while differ in their underlying structures. In other words, without considering the fact that different users differ in the way they use Word, the naive code used to parse Word documents are doomed to fail, even though the users SEEM to stick to a particular format. In order to deal with this problem, some kind of &lt;em>normalization&lt;/em> needs to be done to all the Word documents such that documents that look the same are INDEED the same. The format of the Word document provided by our course instructor is as below:&lt;/p>
&lt;pre tabindex="0">&lt;code>[Number].
[Original language (optional)]
[EMPTY LINE (optional)]
[Gloss line 1 (original language)]
[Gloss line 2 (English)]
[Gloss line 3 (Mandarin)]
[EMPTY LINE]
#e [English translation]
#c [Chinese translation]
#n [Notes]
[EMPTY LINE]
&lt;/code>&lt;/pre>&lt;p>Below is an illustration of what it &amp;rsquo;looks&amp;rsquo; like in a Word document of interlinear glosses:&lt;/p>
&lt;img src="https://img.yongfu.name/posts/gloss-example.png" style="width:75%">
&lt;p>When you press &lt;code>Enter&lt;/code> on the keyboard while editing a Word document, you SEEM to be creating a &lt;strong>line break&lt;/strong>, but, in fact, you are creating a &lt;strong>new paragraph&lt;/strong>. To create a line break without breaking the current paragraph, &lt;code>Shift + Enter&lt;/code> instead of &lt;code>Enter&lt;/code> should be pressed. This is an example of the user behaviors I needed to normalize before I can sucessfully parse the Word documents.&lt;/p>
&lt;p>To do this in Python, I extract all the paragraphs in a Word document using the module &lt;a href="https://python-docx.readthedocs.io/en/latest">&lt;code>python-docx&lt;/code>&lt;/a>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> and concatenate them with newline characters (&lt;code>\n&lt;/code>) into a large string. Then, I split the string by &lt;code>\n&lt;/code> into a list of lines, from which the starting and ending positions (the positions where &lt;code>[gloss num].&lt;/code> is found in the list) of each elicitation could be located by simple pattern matching:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1&lt;/span>&lt;span>&lt;span style="color:#f92672">from&lt;/span> docx &lt;span style="color:#f92672">import&lt;/span> Document
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4&lt;/span>&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">process_doc&lt;/span>(fp&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;corp/20200325.docx&amp;#34;&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6&lt;/span>&lt;span> &lt;span style="color:#75715e"># Normalize document into a list of lines&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7&lt;/span>&lt;span> d &lt;span style="color:#f92672">=&lt;/span> Document(fp)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8&lt;/span>&lt;span> a_doc &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#ae81ff">\n&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>join(p&lt;span style="color:#f92672">.&lt;/span>text &lt;span style="color:#66d9ef">for&lt;/span> p &lt;span style="color:#f92672">in&lt;/span> d&lt;span style="color:#f92672">.&lt;/span>paragraphs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9&lt;/span>&lt;span> a_doc &lt;span style="color:#f92672">=&lt;/span> a_doc&lt;span style="color:#f92672">.&lt;/span>split(&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#ae81ff">\n&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11&lt;/span>&lt;span> &lt;span style="color:#75715e"># Find the positions of each elicitation&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12&lt;/span>&lt;span> pat_start &lt;span style="color:#f92672">=&lt;/span> re&lt;span style="color:#f92672">.&lt;/span>compile(&lt;span style="color:#e6db74">&amp;#34;^(\d{1,2})\.\s*$&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13&lt;/span>&lt;span> glosses_on &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14&lt;/span>&lt;span> gloss_num_old &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15&lt;/span>&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> i, line &lt;span style="color:#f92672">in&lt;/span> enumerate(a_doc):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16&lt;/span>&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> pat_start&lt;span style="color:#f92672">.&lt;/span>match(line):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17&lt;/span>&lt;span> gloss_num_new &lt;span style="color:#f92672">=&lt;/span> i
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19&lt;/span>&lt;span> &lt;span style="color:#75715e"># Save each elicitation range&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20&lt;/span>&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> gloss_num_old &lt;span style="color:#f92672">is&lt;/span> &lt;span style="color:#f92672">not&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21&lt;/span>&lt;span> glosses_on&lt;span style="color:#f92672">.&lt;/span>append( (gloss_num_old, gloss_num_new &lt;span style="color:#f92672">-&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>) )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22&lt;/span>&lt;span> gloss_num_old &lt;span style="color:#f92672">=&lt;/span> gloss_num_new
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24&lt;/span>&lt;span> &lt;span style="color:#75715e"># Save last gloss&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25&lt;/span>&lt;span> i &lt;span style="color:#f92672">=&lt;/span> gloss_num_old
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26&lt;/span>&lt;span> &lt;span style="color:#66d9ef">while&lt;/span> &lt;span style="color:#66d9ef">True&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27&lt;/span>&lt;span> i &lt;span style="color:#f92672">+=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28&lt;/span>&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> a_doc[i]&lt;span style="color:#f92672">.&lt;/span>strip()&lt;span style="color:#f92672">.&lt;/span>startswith(&lt;span style="color:#e6db74">&amp;#39;#&amp;#39;&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29&lt;/span>&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> len(a_doc) &lt;span style="color:#f92672">==&lt;/span> i &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">or&lt;/span> (&lt;span style="color:#f92672">not&lt;/span> a_doc[i &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>strip()&lt;span style="color:#f92672">.&lt;/span>startswith(&lt;span style="color:#e6db74">&amp;#39;#&amp;#39;&lt;/span>)):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30&lt;/span>&lt;span> end_idx &lt;span style="color:#f92672">=&lt;/span> i &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31&lt;/span>&lt;span> &lt;span style="color:#66d9ef">break&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32&lt;/span>&lt;span> glosses_on&lt;span style="color:#f92672">.&lt;/span>append( (gloss_num_old, i) )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34&lt;/span>&lt;span> &lt;span style="color:#75715e"># Get all elicitations in the document&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35&lt;/span>&lt;span> glosses &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36&lt;/span>&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> start, end &lt;span style="color:#f92672">in&lt;/span> glosses_on:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37&lt;/span>&lt;span> gloss_num &lt;span style="color:#f92672">=&lt;/span> int(re&lt;span style="color:#f92672">.&lt;/span>match(&lt;span style="color:#e6db74">&amp;#34;(\d+)\.&amp;#34;&lt;/span>, a_doc[start])[&lt;span style="color:#ae81ff">1&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38&lt;/span>&lt;span> gloss_lines &lt;span style="color:#f92672">=&lt;/span> [ l&lt;span style="color:#f92672">.&lt;/span>strip() &lt;span style="color:#66d9ef">for&lt;/span> l &lt;span style="color:#f92672">in&lt;/span> a_doc[(start &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>):end] ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39&lt;/span>&lt;span> glosses&lt;span style="color:#f92672">.&lt;/span>append( (gloss_num, gloss_lines) )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41&lt;/span>&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> glosses
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>One major improvement to &lt;a href="https://github.com/puerdon/corpus_processor">&lt;code>puerdon/corpus_processor&lt;/code>&lt;/a> is dealing with gloss lines that span multiple lines, as exemplified in the code chunk below. This problem can be solved by removing all empty lines between the gloss lines and free lines (those starting with &lt;code>#e&lt;/code>, &lt;code>#c&lt;/code>, and &lt;code>#n&lt;/code>) such that, when the free lines are excluded, the number of gloss lines &lt;strong>must&lt;/strong> be multiples of three (the example below has 6 gloss lines in total). Normalizing each elicitation to this format allows me to concatenate multiple gloss lines into three for all elicitaion examples. The code that deal with this can be found in the function &lt;code>assign_gloss_free_lines()&lt;/code> in &lt;a href="https://github.com/liao961120/gloss-search/blob/master/GlossProcessor.py">&lt;code>GlossProcessor.py&lt;/code>&lt;/a>.&lt;/p>
&lt;pre tabindex="0">&lt;code>14.
kay Elrenge watsili kay malri ki lalake ki talialalay
kay Elrenge w-a-tsili kay malri
this Elrenge AF-RLS-throw this ball
這 Elrenge 主焦-實現-丟 這 球
ki lalake ki talialalay
OBL kid _ noble
斜格 小孩 _ 貴族
#e Elrenge throw a ball to the noble’s kid.
#c 這 Elrenge 丟一顆球給貴族的小孩
#n
&lt;/code>&lt;/pre>&lt;p>After normalizing the Word documents, the documents are parsed and convert into the Python dictionary as shown below:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1&lt;/span>&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2&lt;/span>&lt;span> &lt;span style="color:#e6db74">&amp;#39;20200325.docx&amp;#39;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3&lt;/span>&lt;span> (&lt;span style="color:#ae81ff">1&lt;/span>, {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4&lt;/span>&lt;span> &lt;span style="color:#e6db74">&amp;#39;ori&amp;#39;&lt;/span>: [&lt;span style="color:#e6db74">&amp;#39;yakay&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;ku&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;tatulru&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;ku&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;ababay&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;ku&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;agili&amp;#39;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5&lt;/span>&lt;span> &lt;span style="color:#e6db74">&amp;#39;gloss&amp;#39;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6&lt;/span>&lt;span> (&lt;span style="color:#e6db74">&amp;#39;yakay&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;have&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;有&amp;#39;&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7&lt;/span>&lt;span> (&lt;span style="color:#e6db74">&amp;#39;ku&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;three&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;3&amp;#39;&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8&lt;/span>&lt;span> (&lt;span style="color:#e6db74">&amp;#39;tatulru&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;female/male&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;女性/男性&amp;#39;&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9&lt;/span>&lt;span> (&lt;span style="color:#e6db74">&amp;#39;(ku&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;yonger_brother/sister-1SG.POSS&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;弟妹-我的.第一人稱單數.所有格&amp;#39;&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10&lt;/span>&lt;span> (&lt;span style="color:#e6db74">&amp;#39;ababay/sauvalay)&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;_&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;_&amp;#39;&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11&lt;/span>&lt;span> (&lt;span style="color:#e6db74">&amp;#39;ku&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;_&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;_&amp;#39;&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12&lt;/span>&lt;span> (&lt;span style="color:#e6db74">&amp;#39;agi-li&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;_&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;_&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13&lt;/span>&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14&lt;/span>&lt;span> &lt;span style="color:#e6db74">&amp;#39;free&amp;#39;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15&lt;/span>&lt;span> &lt;span style="color:#e6db74">&amp;#39;#e I have 3 younger brother/sister&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16&lt;/span>&lt;span> &lt;span style="color:#e6db74">&amp;#39;#c 我有 3 個弟弟/妹妹&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17&lt;/span>&lt;span> &lt;span style="color:#e6db74">&amp;#39;#n yakay ku 可省略&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18&lt;/span>&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19&lt;/span>&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20&lt;/span>&lt;span> ),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21&lt;/span>&lt;span> (&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#f92672">...&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23&lt;/span>&lt;span> &lt;span style="color:#f92672">...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24&lt;/span>&lt;span> &lt;span style="color:#e6db74">&amp;#39;20200408.docx&amp;#39;&lt;/span>: [&lt;span style="color:#f92672">...&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25&lt;/span>&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="frontend">Frontend&lt;/h2>
&lt;p>The construction of the frontend was relatively easy, given that the most challenging part was already done in &lt;a href="https://yongfu.name/2020/02/22/leipzigVue.html">my (dead) project on building a web app for interlinear glossing&lt;/a>. In brief, the component &lt;a href="https://github.com/liao961120/gloss-search-frontend/blob/master/src/components/Leipzig.vue">&lt;code>Leipzig.vue&lt;/code>&lt;/a> is used to construct the aligned glosses (see figure below) from the data sent from backend (i.e., the python dictionary in the previous section, converted to JSON format).&lt;/p>
&lt;img src="https://img.yongfu.name/posts/leipzig.js.png" style="width: 70%; float: center;">
&lt;p>Another relatively challenging part (to me) is implementing the highlighting function, which highlights the matching patterns in the glosses (as in the words with yellow background in the figure above). It was implemented by creating a &lt;a href="https://vuejs.org/v2/guide/computed.html">computed property&lt;/a> that wraps the parts of the data matching the search pattern into HTML &lt;code>&amp;lt;span class=&amp;quot;matchedtoken&amp;quot;&amp;gt;&lt;/code> tags. I can then use CSS to decorate these tags.&lt;/p>
&lt;p>The remaining parts of the fontend are about communicating with the server, which are relatively easy to set up. I actually just copy-and-pasted the code from my previous &lt;a href="https://github.com/liao961120/kwic/blob/master/src/components/kwic.vue">KWIC concordancer project&lt;/a>.&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>I didn&amp;rsquo;t spent much time exploring the API of &lt;a href="https://python-docx.readthedocs.io/en/latest/">&lt;code>python-docx&lt;/code>&lt;/a> thanks to Don&amp;rsquo;s PIONEERING (at least in our university, or even Taiwan, I believe) project &lt;a href="https://github.com/puerdon/corpus_processor">&lt;code>puerdon/corpus_processor&lt;/code>&lt;/a>.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description><category>app</category><category>Python</category><category>Linguistics</category></item><item><title>以 Python 實作 Concordancer</title><link>https://yongfu.name/2020/03/20/building-concordancer/</link><pubDate>Fri, 20 Mar 2020 00:00:00 +0000</pubDate><guid>https://yongfu.name/2020/03/20/building-concordancer/</guid><description>&lt;p>每次接近學期末的時候，寫程式癮就會開始發作 (可能是不想面對無趣的期末報告)，這時候腦袋會蹦出許多很有趣的想法，然後就會迫不及待地想將這些想法實作出來。這次(2019 年末) 的程式癮刺激來源是實驗室的雲端硬碟裡的某個 (版權封閉) 中文語料庫，雖然該語料庫已有很好的搜尋界面，但&lt;strong>我就是想 reinvent the wheel&lt;/strong>，自己手刻出一個 concordancer。不為了什麼，就只是因為這件事本身就很有樂趣。&lt;/p>
&lt;h2 id="初步嘗試for-loop-forever">初步嘗試：for loop&amp;hellip; forever&lt;/h2>
&lt;p>我本來並沒有太大的雄心壯志，就只想快速弄出個程式界面方便我查找 concordance，想說使用 &lt;a href="https://www.nltk.org/book/ch01.html#searching-text">NLTK concordance&lt;/a> 應該很快就可以弄出我想的東西。但 NLTK concordance 只能使用 word form (或 pattern) 去搜尋 concordance，我的需求卻是要能&lt;strong>使用 word form 或 PoS tag&lt;/strong> 搜尋語料庫 (類似 &lt;a href="http://cwb.sourceforge.net/files/CQP_Tutorial/CQP_Tutorial.html">Corpus Query Langauge&lt;/a>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>，但不用這麼複雜)。但要自己用 Python 實作這個功能也頗簡單，於是我就自己手刻了這個功能。然而事實證明我太過天真了。語料庫的大小約 1000 萬個 token，而每次搜尋時，我的程式使用 for 迴圈跑過整個語料，因此要花非常非常非常久的時間才能完成搜尋。對於非資訊背景出生的我，第一次體驗 $O(n)$ 是件不可忽視的問題以及 Database 存在的必要性。&lt;/p>
&lt;h2 id="重新規劃-database--python--vue">重新規劃： Database + Python + Vue&lt;/h2>
&lt;p>為了解決上述問題我暫時擱置了這個專案 (寒假開始到春節期間) 去學習必備的一些知識&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>，最後比較有系統地重新規劃了這個 concordancer 的架構：&lt;/p>
&lt;img src="https://img.yongfu.name/posts/concordancer-design.png" style="width:100%">
&lt;p>這個新的架構分成前&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>、後端，前端不是本文的重點 (原始碼&lt;a href="https://github.com/liao961120/kwic">在此&lt;/a>)，就不細談。這邊直接舉一個實例說明這個 concordancer 如何運作：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>首先，使用者在前端輸入一個搜尋的字串 (keyword)，這個字串需符特定的格式：&lt;code>[token 1][token 2][token 3]&lt;/code>。每對中括號代表一個 token，中括號內則是描述此 token 的特徵，如 word form 與 PoS tag，例如 &lt;code>[word=&amp;quot;打&amp;quot; pos=&amp;quot;V.*&amp;quot;]&lt;/code> 即是要搜尋 word form 為 &lt;code>打&lt;/code> 且詞類為動詞&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup> 的 token。這裡的例子使用 &lt;strong>&lt;code>[word.regex=&amp;quot;^[他她]$&amp;quot;][word=&amp;quot;打&amp;quot; pos=&amp;quot;V.*&amp;quot;]&lt;/code>&lt;/strong>，下方的幾個例子都是符合這個搜尋的 2-gram:&lt;/p>
&lt;ul>
&lt;li>&lt;code>他/Nh 打/VC&lt;/code>&lt;/li>
&lt;li>&lt;code>她/Nh 打/VC&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>&lt;code>[word.regex=&amp;quot;^[他她]$&amp;quot;][word=&amp;quot;打&amp;quot; pos=&amp;quot;V.*&amp;quot;]&lt;/code>&lt;/strong> 在傳給後端後，會先經過一個 &lt;a href="https://yongfu.name/kwic-backend/html/doc/queryParser.html">parser&lt;/a> 處理，讓後端可以將這個 query 轉換成 SQL 去搜尋 database。在搜尋時，這邊僅會在 DB 中以&lt;strong>其中一個 token 的資訊進行搜尋&lt;/strong>，並回傳所有符合的 token 於語料庫中的位置 (所在文件之 id、第幾個句子、token 於句子中的次序)。這些 token 是&lt;strong>可能符合 keyword pattern 的「候選者」&lt;/strong> ，讓接下來的 n-gram 比對可以更快速 (search space 從整個語料庫減少到只剩這些「候選者」所組成的 n-gram)。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>透過這些 token 的位置資訊，可以找出含有該 token 的 n-gram。例如，假設這裡使用 &lt;code>[word=&amp;quot;打&amp;quot; pos=&amp;quot;V.*&amp;quot;]&lt;/code> 在 DB 當中搜尋，取得結果後，可以再比對此 token &lt;strong>左邊&lt;/strong>的 token 是否符合 &lt;code>[word.regex=&amp;quot;^[他她]$&amp;quot;]&lt;/code>。若符合，則保留此 2-gram，並取得該 2-gram 左右的 context，作為未來要回傳給使用者的 KWIC concordance。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>跑完所有的「候選者」token，即可取得整個語料庫內，符合 keyword pattern 的 concordance。接下來僅需將資料轉換成 JSON 格式再傳到前端即可。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="database-設計">Database 設計&lt;/h2>
&lt;p>下圖是 Database&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup> 的 table 設計，共有 3 個 table:&lt;/p>
&lt;img src="https://img.yongfu.name/posts/db-design.png" style="width:100%">
&lt;ul>
&lt;li>&lt;strong>Token&lt;/strong>: 將語料庫中的每種 token (即 type) 對應至 id。如此搜尋單一 token 的 word form 時，即可搜尋此較小的 table (列數等於語料庫中 type 的數量)，而不用跑過整個語料庫。&lt;/li>
&lt;li>&lt;strong>Pos&lt;/strong>: 將語料庫中的每種 PoS tag 對應至 id。同上，可以快速找出符合的 token。&lt;/li>
&lt;li>&lt;strong>Corpus&lt;/strong>: 保留語料庫 token 位置資訊的 table。搜尋完 &lt;strong>Token&lt;/strong> 以及 &lt;strong>Pos&lt;/strong> 兩 table 之後，即可透過 token 與 pos id 在 &lt;strong>Corpus&lt;/strong> 裡找到符合的列 (e.g., &lt;code>tk_id == 3&lt;/code> (&lt;code>我&lt;/code>) 且 &lt;code>pos_id == 1&lt;/code> (&lt;code>Nh&lt;/code>)。這些列裡面含有這個 token 於語料庫中的位置 (&lt;code>text_id&lt;/code>, &lt;code>sent_idx&lt;/code>, &lt;code>tk_idx&lt;/code>)。&lt;/li>
&lt;/ul>
&lt;h2 id="原始碼--使用語料庫">原始碼 / 使用語料庫&lt;/h2>
&lt;p>這個專案一開始是使用版權封閉的語料庫製作，因此語料庫的資料並未放在 GitHub，但後端的原始碼仍放在 &lt;a href="https://github.com/liao961120/kwic-backend">&lt;code>liao961120/kwic-backend&lt;/code>&lt;/a>。&lt;/p>
&lt;p>為了讓這個專案至少能被使用，我另外爬了 &lt;a href="https://github.com/liao961120/dcard-corpus">Dcard 作為語料&lt;/a> (500 多萬詞，大小約平衡語料庫的一半)，並包成 docker image，方便有興趣的人使用。要搜尋 Dcard 語料庫僅需依照下方的步驟：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>取得 docker image (僅第一次需執行)&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>docker pull liao961120/dcard
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>執行後端 (執行後，請等待 cmd 出現 &lt;code>Corpus Loaded&lt;/code> 的字串)&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>docker run -it -p 127.0.0.1:1420:80 liao961120/dcard
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>前往 &lt;a href="https://kwic.yongfu.name">https://kwic.yongfu.name&lt;/a> 使用前端界面&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>一開始曾想過直接使用現成的 corpus framework，例如 &lt;a href="http://cwb.sourceforge.net">CWB&lt;/a>, &lt;a href="https://inl.github.io/BlackLab">BlackLab&lt;/a> 等。但一方面研究這些 framework 要花許多精力，且因為研究的都是別人做好的 API，不容易學到比較低階、處理語料的問題。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>快速掃過 &lt;a href="https://cs50.harvard.edu/x/2019">CS50&lt;/a> 的前 5 堂課 (我還是不會 C/C++)、複習之前&lt;a href="https://cs50.harvard.edu/web/#sql">不怎麼認真看待的 SQL Database&lt;/a>以及閱讀 &lt;a href="https://www.sqlite.org/queryplanner.html">SQLite 關於 indexing 的說明文件&lt;/a> (這最重要)。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>雖然本來不打算做前端，但由於花了大量時間學習 Database 的概念，多花個幾小時刻個前端相比之下簡單許多 (這邊前端的功能不多)。&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4">
&lt;p>這裡的語料是經&lt;a href="https://github.com/ckiplab/ckiptagger">中研院 ckiptagger&lt;/a> 斷詞，可&lt;a href="https://github.com/ckiplab/ckiptagger/wiki/POS-Tags">於此&lt;/a>檢視其詞類標記集。&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5">
&lt;p>建立資料庫以及索引的原始碼位於 &lt;a href="https://github.com/liao961120/dcard-corpus/blob/master/indexCorp.py">&lt;code>liao961120/dcard-corpus/indexCorp.py&lt;/code>&lt;/a>。&amp;#160;&lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description><category>app</category><category>Python</category><category>Linguistics</category><category>中文</category></item><item><title>Recreating Leipizig.js with Vue for Interlinear Glossing</title><link>https://yongfu.name/2020/02/22/leipzigvue/</link><pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate><guid>https://yongfu.name/2020/02/22/leipzigvue/</guid><description>&lt;p>I noticed &lt;a href="https://bdchauvette.net/leipzig.js">Leipzig.js&lt;/a> from &lt;a href="https://github.com/agricolamz">George Moroz&lt;/a>&amp;rsquo;s GitHub activity (he starred &lt;a href="https://github.com/bdchauvette/leipzig.js/">&lt;code>bdchauvette/leipzig.js&lt;/code>&lt;/a> a few months ago). This JS library is fantastic, and at the moment I saw it, I came up with an idea of building a web app facilitating interlinear glossing.
During Chinese New Year, I finally started on the project. I thought it would be easy since I had some experience with Vue.js before&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>, but it turned out that &lt;code>leipzig.js&lt;/code> wasn&amp;rsquo;t designed to work with Vue.&lt;/p>
&lt;h2 id="dynamic-input-interface">Dynamic Input Interface&lt;/h2>
&lt;p>What I had in mind was a web app that, while the user is typing, the rendered glosses get showed &lt;strong>synchronously&lt;/strong> in another panel. Vue&amp;rsquo;s conventional way of doing this is by creating a two-way data binding (&lt;code>v-model&lt;/code>) to capture the user&amp;rsquo;s input and dynamically render the HTML content based on the inputted data. This conflicts with &lt;code>leipzig.js&lt;/code> since it only provides a high level function (&lt;a href="https://github.com/bdchauvette/leipzig.js/wiki/Documentation">&lt;code>Leipzig()&lt;/code>&lt;/a>) to modify existing DOM elements to construct the glosses. Calling &lt;code>Leipzig()&lt;/code> multiple times (without erasing the already rendered HTML) would break the DOM elements, which makes the function hard to work together with Vue&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>After multiple failures of making &lt;code>Leipzig()&lt;/code> to work with Vue, I decided to abandoned &lt;code>leipzig.js&lt;/code> and recreate its functionality with Vue. This wasn&amp;rsquo;t as terrifying as it may seem, since I can use &lt;a href="https://github.com/bdchauvette/leipzig.js/blob/master/dist/leipzig.css">&lt;code>leipzig.js&lt;/code>&amp;rsquo;s CSS rules&lt;/a> directly to help me align the rendered DOM elements by Vue. What I had to do was making sure that Vue generates &lt;a href="https://github.com/bdchauvette/leipzig.js/wiki/Documentation#configclasses">the exact same HTML structure&lt;/a> as &lt;code>leipzig.js&lt;/code>&amp;rsquo;s rendered glosses. The resulting input interface is shown in the GIF below.&lt;/p>
&lt;p>
&lt;figure>
&lt;img src="https://img.yongfu.name/gif/leipzig-vue.gif" alt="Leipzig.js rebuilt with Vue">
&lt;figcaption>Leipzig.js rebuilt with Vue&lt;/figcaption>
&lt;/figure>
&lt;/p>
&lt;p>The source code of this vue component can be found in &lt;a href="https://github.com/liao961120/gloss/blob/master/src/components/Leipzig.vue">&lt;code>Leipzig.vue&lt;/code>&lt;/a>.&lt;/p>
&lt;h2 id="other-parts-of-the-app">Other Parts of the App&lt;/h2>
&lt;p>There are several advantages of adopting Vue instead of using traditional JS approaches to build the app. Since what I wanted to build was an app that can also &lt;strong>store, manage, and export glosses&lt;/strong> for the user, I needed a framework to help me manage this complexity (e.g., &lt;a href="https://github.com/liao961120/gloss/blob/master/src/views/Edit.vue">Vuex&lt;/a>), and Vue provides a good and manageable way to build a complex web app. After learning Vuex and experiencing some failures in my previous &lt;a href="https://github.com/liao961120/viewMark">Vue project&lt;/a> (due to increasing complexity as the app grows larger), I&amp;rsquo;m pretty sure that I could build a better app with less complexity this time. But just when I was moving forward to other parts of the app, I was stuck by other work to do, so I&amp;rsquo;m currently not developing this app. Currently, the only usable part of this app is its dynamic input interface for previewing glosses.&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>In 2019 summer, I learned Vue.js on &lt;a href="https://www.youtube.com/playlist?list=PL4cUxeGkcC9gQcYgjhBoeQH7wiAyZNrYa">The Net Ninja&amp;rsquo;s YouTube channel&lt;/a> and built a &lt;a href="https://viewmark.yongfu.name">markdown editor&lt;/a> for fun.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>Though it is possible to create a dynamic input experience with &lt;code>leipizig.js&lt;/code> with a more traditional JS approach. You can read the &lt;a href="https://bdchauvette.net/leipzig.js/theme/js/demo.js">source code&lt;/a> of this &lt;a href="https://bdchauvette.net/leipzig.js/demo/">Live demo of Leipzig.js&lt;/a> to find out how it works!&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description><category>app</category><category>JavaScript</category><category>Linguistics</category></item><item><title>閱讀筆記：Origins of Human Communication</title><link>https://yongfu.name/2019/03/04/originsofhumancommunication/</link><pubDate>Mon, 04 Mar 2019 00:00:00 +0000</pubDate><guid>https://yongfu.name/2019/03/04/originsofhumancommunication/</guid><description>&lt;div class="section level2">
&lt;h2>語言到底是什麼？&lt;/h2>
&lt;p>這個出現在語概課本第一章的問題，通常會說明人類語言和動物的溝通有什麼&lt;strong>本質上&lt;/strong>的不同，並且指出人類語言具有結構、可組合的特性等等。但這些說明只是描述人類語言的特性，但對於語言是什麼，或更精確地說 – 語言如何產生 (包含認知處理上、生理發展上、演化歷史上)，並未提供有洞見的解釋。&lt;/p>
&lt;p>我想認知語言學的主要貢獻在於，其看見&lt;strong>語言以外&lt;/strong>的世界，強調認知系統對於形塑語言的影響。對於語言的分析，因此需跨出「語言」，擴展到人類的認知系統。這真的是充滿雄心壯志的抱負，但我並不覺得這帶來的影響是全然正面的，因為面對人類心智運作的問題時，事情會變得&lt;strong>非常非常非常複雜&lt;/strong>。特別是語言，從人類語言的相關研究可以發現語言真的很「雜亂 (noisy)」 (相較於視覺系統)。這使將戰線拉得如此廣泛的認知語言學可能變得十分混亂，在沒有透徹理解一個現象中比較基礎的因素前，就直接研究更複雜的整體現象&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>。這也是為何我對於 &lt;strong>&lt;em>語言是什麼&lt;/em>&lt;/strong> 這個問題感到困惑。我一直找不到一個清晰、穩固的基礎，作為評斷各種對語言的看法與理論的基準。我們似乎根本不了解語言是什麼，卻常在很抽象的層次上試圖說明語言是什麼。&lt;/p>
&lt;p>於是，我決定先從 Tomasello 的專著下手，因為他的研究興趣是語言 (甚至是人類) 的演化，而就我所學過的東西而言，演化論應是僅次於數學，最可靠的一種想法。&lt;/p>
&lt;/div>
&lt;div class="section level2">
&lt;h2>看見更基礎的元素&lt;/h2>
&lt;p>看完 &lt;em>Origins of Human Communication&lt;/em> &lt;span class="citation">(Tomasello, &lt;a href="#ref-tomasello2008">2008&lt;/a>)&lt;/span> 後，不得不佩服 Tomasello 這位學者。剛了解他研究對象是嬰兒與靈長類動物、研究主題是心理學和語言學時，不太能理解為什麼，只以為他是興趣廣泛。讀完書後才了解到，這些內容都與 Tomasello 想回答的問題密切相關 – 語言的起源。&lt;/p>
&lt;p>Tomasello 厲害的地方在於其能夠跳脫「語言」的框架，嘗試找出語言要能運作所需的&lt;strong>更基礎的元素&lt;/strong>。而要找出這些基礎的元素，需要跳脫過去語言相關研究關注的主體 – 成年人類的語言使用，將目光聚焦在「尚未」發展出語言的族群上 – 黑猩猩與人類嬰兒，藉此找出哪些因素造成成年人類和這兩個族群有如此不同的語言表現。&lt;/p>
&lt;p>例如，「&lt;em>口語&lt;/em>」在語言學中可說是最受關注的焦點 (相較於「文字」與「手勢」)，所以許多對於語言的研究與分析都是以口語作為基礎。但 Tomasello 強調了「手勢」的重要性。要了解「語言 (language)」，我們應該先了解「溝通 (communication)」，因為語言只是人類溝通的一種形式，而「&lt;em>指向 (pointing)&lt;/em>」與「&lt;em>比手畫腳 (pantomiming)&lt;/em>」則是人類溝通的另外兩種重要方式。「手勢」( &lt;em>指向&lt;/em> 與 &lt;em>比手畫腳&lt;/em> ) 的重要性在於，由於其所能攜帶的資訊量遠少於語言，其特別容易突顯人類溝通時，溝通者需具備的社會認知結構。這裡以書中提到的例子說明：&lt;/p>
&lt;blockquote>
&lt;p>我和妳正在去圖書館的路上。走到圖書館外面時，我指向停放腳踏車的地方。這時妳應該會感到奇怪，因為妳不知道我要表達什麼。&lt;/p>
&lt;p>但假設如果妳剛和男朋友分手，而且妳和我都知道這件事，而我指向的地方停有妳男友的腳踏車，那這個手勢就和上一種情況有完全不同的意義 (代表：「妳男友可能在圖書館裡，妳確定要進去嗎？」)。&lt;/p>
&lt;p>又或者，假設我指向的地方停著妳之前被偷的腳踏車，那這個手勢又代表著完全不一樣的意義。&lt;/p>
&lt;/blockquote>
&lt;p>在上述的幾個例子中，同樣的手勢，甚至在同樣的客觀背景 (physical context) 下，表達了相異且十分複雜的意義。這些例子的差異僅來自於&lt;strong>我和妳先前的共同經驗&lt;/strong>。這種現象在人類溝通中 (包含手勢與語言) 隨處可見。因此，這裡需要回答的問題是，&lt;strong>什麼樣的認知結構使得人類在溝通時，能夠自然而然地形成上述的詮釋&lt;/strong>。&lt;/p>
&lt;/div>
&lt;div id="chimp" class="section level2">
&lt;h2>黑猩猩 vs. 人類&lt;/h2>
&lt;p>關於上述的問題，一個最精簡的答案是溝通者理解彼此是「有意圖 (intentional)」的個體，所以在我指向腳踏車停放處時，妳會進行類似的推論：「他為什麼指向那裡，他&lt;strong>想&lt;/strong>告訴我什麼？」但這只是個過於簡化的答案，因為黑猩猩也能理解溝通的對象是有意圖的，但黑猩猩卻無法發展出人類般複雜的溝通方式。例如，在餵食黑猩猩的情境中，若黑猩猩觀察到實驗者&lt;strong>不願意&lt;/strong> (unwilling) 餵食時，黑猩猩會表現出失望的行為；但如果實驗者是因為其它原因 (例如，餵食孔太小或是因為其它事情分心) &lt;strong>無法&lt;/strong> (unable) 餵食，黑猩猩會持續耐心的等待 &lt;span class="citation">(Call, Hare, Carpenter, &amp;amp; Tomasello, &lt;a href="#ref-call2004">2004&lt;/a>)&lt;/span>。&lt;/p>
&lt;p>所以，人類溝通運作的關鍵不僅僅是能夠理解彼此具有意圖，還需要其它關鍵因素。Tomasello 在經過大量對於黑猩猩與人類嬰兒手勢溝通 (gestural communication) 的研究後，指出人類與黑猩猩之間存在一項重要的差異 – 人類的溝通本質上是合作性的 (cooperative)，但黑猩猩的溝通幾乎是自我中心與命令式的 (imperative)。換言之，黑猩猩的溝通意圖僅有&lt;strong>要求 (request)&lt;/strong> 其他黑猩猩或人去做自己要他們達成的事情；人類的溝通意圖則不只侷限於要求，更多情況下是為了&lt;strong>提供對方資訊 (inform)&lt;/strong> (例如前述的圖書館例子：我透過手勢告知妳&lt;strong>對妳 (但不是我) 而言&lt;/strong>有用的資訊)，或是單純為了&lt;strong>分享 (sharing)&lt;/strong> (例如：「今天發生了 … ，心情好糟喔！」)。值得注意的是，即使人類意圖要求別人為自己做事情的時候，仍然是以「合作性」的方式提出要求。例如我們通常使用婉轉的方式提出要求 (例如，使用問句)，在對方完成我們的要求後，表達感謝甚至是必須的。&lt;/p>
&lt;/div>
&lt;div class="section level2">
&lt;h2>溝通的合作性結構&lt;/h2>
&lt;p>人類溝通中的「合作性」結構與人類的社會認知結構 (social-cognitive infrastructure) 之間關係密不可分。要有合作性的對話產生，溝通者之間必須建立一種抽象、共享的&lt;strong>共同經驗 (common ground)&lt;/strong> – 溝通者彼此都知道，且也都知道「對方知道我知道」的事情。承接上述圖書館的例子：&lt;/p>
&lt;blockquote>
&lt;p>妳知道我指向停腳踏車處是為了告訴妳：「妳男友在圖書館裡」。這是因為我知道妳和妳男友分手，而妳也知道我知道這件事。&lt;/p>
&lt;/blockquote>
&lt;p>值得注意的是這裡包含所謂&lt;strong>遞迴 (recursive) 的認知結構&lt;/strong>：妳必須知道「我知道妳和妳男友分手」這件事，上述溝通的情況才會產生。換言之，如果妳並未告訴過我妳和妳男友分手這件事，但我從其它管道得知了這件事，妳對我指向圖書館外的腳踏車就不會有「他在告訴我，我男友在圖書館內」這個詮釋 (縱使妳看到了妳男友的腳踏車)&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a>。因此，形成共同經驗的前提是，溝通者必須具備一種「遞迴讀心 (recursive mindreading)」的認知能力。&lt;/p>
&lt;p>當合作性的溝通是建立在共同經驗上，溝通者才能從共同經驗中推斷哪些資訊是對方感興趣的。同時，因為預設溝通者的動機是合作的，日常溝通中，我們才會以這種方式詮釋模糊的訊息：&lt;/p>
&lt;blockquote>
&lt;p>某個陌生人拍拍妳的肩膀再指向妳右邊臉頰，妳應該會認為他在告訴妳：「妳臉頰上有東西」。&lt;/p>
&lt;/blockquote>
&lt;p>這個手勢明明有千百種詮釋方式，但因為人類會隱性地預設對方是善意的、提供的是對自己有用的訊息，所以會形成這種詮釋。&lt;/p>
&lt;/div>
&lt;div class="section level2">
&lt;h2>語言的起源&lt;/h2>
&lt;p>人類的溝通，不論是&lt;em>指向 (pointing)&lt;/em>、&lt;em>比手畫腳 (pantomiming)&lt;/em> 或&lt;em>口語&lt;/em> (spoken language) 皆是建立在上述合作性的溝通結構&lt;a href="#fn3" class="footnote-ref" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a>。基本上，「合作」可說是造成今日語言的面貌的最重要的原因之一。&lt;/p>
&lt;div class="section level3">
&lt;h3>句法&lt;/h3>
&lt;p>人類語言中複雜的句法不會無緣無故出現，一定存在某種使用上的功能性壓力 (functional pressure)，才使語言演化出句法。人類溝通中的合作性結構提供了這種壓力。黑猩猩溝通的意圖僅有&lt;em>要求 (requesting)&lt;/em> ，而要表達要求僅需非常精簡的 (或甚至不需要) 句法：試想祈使句的文法有多精簡 (例如，「(你) 走開」)。這是因為 &lt;em>要求&lt;/em> 的溝通意圖所涉及的情境非常簡單 – 當下 (時間點)、你 (主體)、去做某事 (事件)。但人類的溝通是合作性的，我們溝通的意圖多半是為了&lt;em>提供訊息 (informing) &lt;/em>和&lt;em>分享 (sharing)&lt;/em>。&lt;/p>
&lt;p>&lt;em>提供訊息&lt;/em> 涉及的情境就比單純要求別人作某事要複雜的多了，因為提供訊息給對方常需涉及&lt;strong>不在當下 (時間上或空間上) 的事件&lt;/strong> (對方不知道的事情，例如，「我在回來的路上看到眼鏡蛇」，常常不是在溝通當下能看到的事情)。&lt;em>提供訊息&lt;/em> 這種溝通上的需求因而就使句法變得必要 – 我們需要標示訊息中&lt;strong>不在對方當下注意力可及範圍內的人或事件&lt;/strong>、需要標示&lt;strong>&lt;em>誰&lt;/em> 對 &lt;em>誰&lt;/em> 做了什麼 &lt;em>事&lt;/em>&lt;/strong>，而句法可以達成這些目的。分享所見所聞又比起提供訊息涉及更為複雜的情境，因為我們需要完整地描述所見所聞或甚至「說故事」。這使得溝通必須仰賴更加複雜句法才能達成目的，所以語言中開始出現更複雜結構，例如，子句結構，以描述許多彼此環環相扣的事件。&lt;/p>
&lt;/div>
&lt;div class="section level3">
&lt;h3>先有手勢，才有口語&lt;/h3>
&lt;p>語言的相關研究十分強調 &lt;em>口語&lt;/em> 的重要性，甚至有關尼安德塔人是否具備語言能力的爭論都被簡化成尼安德塔人會不會說話的爭論&lt;a href="#fn4" class="footnote-ref" id="fnref4">&lt;sup>4&lt;/sup>&lt;/a> &lt;span class="citation">(Arensburg et al., &lt;a href="#ref-arensburg1989">1989&lt;/a>; D’Anastasio et al., &lt;a href="#ref-danastasio2013">2013&lt;/a>)&lt;/span>。口語固然有其重要性，但 Tomasello 認為口語不是語言的起源。口語是在手語之後 (或伴隨手語）出現的，而手語則是由比手畫腳演變而成。主要論點如下：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;p>黑猩猩，目前在演化樹上與人類最接近的親屬，能透過手勢彈性地傳達多種訊息。但黑猩猩的發聲器官卻相當侷限，其發出的聲音僅能用於固定的情緒表達。因此在演化歷史上，「手勢」會是個比較好的材料，較可能作為形塑語言的基礎。&lt;/p>&lt;/li>
&lt;li>&lt;p>&lt;em>口語&lt;/em> (spoken language) 是約定俗成 (conventionalized) 與專斷的 (arbitrary)。換句話說，同樣的物體，例如「月亮」，在不同語言會有完全不同的形式 (發音)。因此，&lt;strong>除非經過約定&lt;/strong>，口語本身並無法「攜帶」意義。相反地，手勢本身就能蘊含意義：&lt;/p>
&lt;ul>
&lt;li>&lt;p>&lt;em>指向 (pointing)&lt;/em> 能透過引導對方的注意力至你我之外的第三個物體，期望對方在看到物體後能做出適當的推論&lt;a href="#fn5" class="footnote-ref" id="fnref5">&lt;sup>5&lt;/sup>&lt;/a>，解讀我欲傳達的訊息。但「未約定俗成的口語」就只是無意義的聲音而已，而聲音無法像「&lt;em>指向&lt;/em>」一般具有彈性操弄對方注意力焦點的功能 (可以指向這裡、那裡、我、你、他)，因為聲音只能將對方注意力吸引到自己身上。&lt;/p>&lt;/li>
&lt;li>&lt;p>&lt;em>比手畫腳 (pantomiming)&lt;/em> 比起&lt;em>指向 (pointing)&lt;/em> 又更能彈性地傳達意義。&lt;em>比手畫腳&lt;/em> 是透過手勢去模擬真實世界中發生的事情，因此即使溝通者之間的共同經驗 (common ground) 很少，也能透過這種方式溝通 (試想自己是如何在語言不通的外國生存的)。&lt;/p>&lt;/li>
&lt;/ul>
&lt;p>因此，演化歷史上比較可能的情況是先有手勢，而手勢中能傳達較豐富意義之 &lt;em>比手畫腳&lt;/em> 逐漸被約定俗成，進而形成了手語&lt;a href="#fn6" class="footnote-ref" id="fnref6">&lt;sup>6&lt;/sup>&lt;/a>。手勢中的 &lt;em>指向&lt;/em> 則保留自今，變成口語的輔助。而口語則是在手語出現之後才演化出來，並取代原本手語的角色。&lt;/p>&lt;/li>
&lt;li>&lt;p>在適當的環境之下，人類能自然而然發展出手語。手語在各方面都與我們所熟知的「語言」沒有什麼太大的區別 – 使用手語時，大腦語言區或活化；手語和所有語言一樣富含規則，違反句文法的使用也會讓手語使用者覺得「怪怪的」。事實上，&lt;code>語言 = 口語&lt;/code> 的概念似乎太過深植人心，導致許多人在知道「原來使用手語時，大腦語言區會『亮起』」時，感到非常訝異 (包含我)。但如果在演化歷史上，語言本來就是從視覺模態 (visual modality) 轉變成聽覺模態 (auditory modality)，那今日所觀察到的手語現象就有相當自然的解釋。&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;div class="section level2">
&lt;h2>小結&lt;/h2>
&lt;blockquote>
&lt;p>Truth is much too complicated to allow anything but approximations.&lt;/p>
&lt;p>— John von Neumann&lt;/p>
&lt;/blockquote>
&lt;p>&lt;span class="citation">Tomasello (&lt;a href="#ref-tomasello2008">2008&lt;/a>)&lt;/span> 提供了一篇龐雜，但相當具有說服力的關於語言演化的故事。然而任何理論都是假的，包含 Tomasello 令人印象深刻的故事，有些理論卻是有用的。在這裡，演化論扮演相當好的角色 – 它幫助我們思考、提出合理的猜測，去解釋人類那些看似彼此沒有任何關係的功能如何互相依存與支持，在演化歷史上孕育出新的功能。縱使這個故事是假的，它提供了許多能被驗證的假設。看著假設提出與驗證的過程，我似乎能在複雜到令人絕望的心智科學中，看見一條能夠前進的道路。&lt;/p>
&lt;/div>
&lt;div id="references" class="section level2 unnumbered">
&lt;h2>參考資料&lt;/h2>
&lt;div id="refs" class="references">
&lt;div id="ref-arensburg1989">
&lt;p>Arensburg, B., Tillier, A. M., Vandermeersch, B., Duday, H., Schepartz, L. A., &amp;amp; Rak, Y. (1989). A Middle Palaeolithic human hyoid bone. &lt;em>Nature&lt;/em>, &lt;em>338&lt;/em>, 758. Journal Article. &lt;a href="https://doi.org/10.1038/338758a0">https://doi.org/10.1038/338758a0&lt;/a>&lt;/p>
&lt;/div>
&lt;div id="ref-call2004">
&lt;p>Call, J., Hare, B., Carpenter, M., &amp;amp; Tomasello, M. (2004). “Unwilling” versus “unable”: Chimpanzees’ understanding of human intentional action. &lt;em>Developmental Science&lt;/em>, &lt;em>7&lt;/em>(4), 488–498. &lt;a href="https://doi.org/10.1111/j.1467-7687.2004.00368.x">https://doi.org/10.1111/j.1467-7687.2004.00368.x&lt;/a>&lt;/p>
&lt;/div>
&lt;div id="ref-danastasio2013">
&lt;p>D’Anastasio, R., Wroe, S., Tuniz, C., Mancini, L., Cesana, D. T., Dreossi, D., … Capasso, L. (2013). Micro-Biomechanics of the Kebara 2 Hyoid and Its Implications for Speech in Neanderthals. &lt;em>PLOS ONE&lt;/em>, &lt;em>8&lt;/em>(12), e82261. Journal Article. &lt;a href="https://doi.org/10.1371/journal.pone.0082261">https://doi.org/10.1371/journal.pone.0082261&lt;/a>&lt;/p>
&lt;/div>
&lt;div id="ref-geeraerts2006">
&lt;p>Geeraerts, D. (Ed.). (2006). &lt;em>Cognitive linguistics: Basic readings&lt;/em>. Berlin: Walter de Gruyter.&lt;/p>
&lt;/div>
&lt;div id="ref-tomasello2008">
&lt;p>Tomasello, M. (2008). &lt;em>Origins of human communication&lt;/em>. Cambridge, Massachusetts: MIT Press.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="footnotes">
&lt;ol>
&lt;li id="fn1">&lt;p>我覺得這是人類心智科學普遍的情況，因為人類大腦非常複雜、難以窺視其運作，不像物理、化學等基礎學科，我們難以知曉心智的哪些功能與現象是基礎的，哪些是複雜的。&lt;a href="#fnref1" class="footnote-back">↩&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>或是另一種更複雜的情況：妳並未告訴過我妳和妳男友分手這件事，但我從其它管道得知了這件事，而妳又從某個管道得知「我從其它管道得知妳和妳男友分手」這件事。換言之，我知道妳和妳男友分手，妳也知道我知道這件事 (這種結構還能持續無限遞迴下去)，但因為我們從未將此事納入我們的共同經驗 (common ground) 中，亦即這件事並未在我們過去的互動中「公開」(妳並未告訴我)，這件事就不會造成妳認為我是在告訴妳「妳男友在圖書館」。&lt;a href="#fnref2" class="footnote-back">↩&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>值得注意的是，當溝通中的合作性結構消失時，可能代表著非常可怕的事情即將發生。試想自己見過最火爆的爭吵，對話者說話 (「吼」話或許比較貼切) 不是為了提供訊息或分享，而是單純希望壓制對方、讓對方閉嘴。若透過聲音彰顯的怒氣不足以抑制對方，甚至可能使用肢體暴力。&lt;a href="#fnref3" class="footnote-back">↩&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn4">&lt;p>當然，若尼安德塔人確實會說話，那確實 (至少從 &lt;span class="citation">Tomasello (&lt;a href="#ref-tomasello2008">2008&lt;/a>)&lt;/span> 的理論) 能證實其擁有語言能力。但這裡想強調的是，縱使尼安德塔人不會說話，&lt;strong>並不代表尼安德塔人不具有語言能力&lt;/strong>。&lt;a href="#fnref4" class="footnote-back">↩&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn5">&lt;p>&lt;em>指向 (pointing)&lt;/em> 所能傳達之訊息的複雜程度，受到溝通者之間的共同經驗 (common ground) 影響。摯友、家人之間有很許多共同經驗，所以一個 &lt;em>指向&lt;/em> 就能傳達含有非常複雜意義的訊息。相反的，陌生人，或甚至是來自不同國家的陌生人，彼此的共同經驗就很少，因此無法透過 &lt;em>指向&lt;/em> 傳達太過複雜的訊息。&lt;a href="#fnref5" class="footnote-back">↩&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn6">&lt;p>有趣的是，&lt;em>口語&lt;/em> (spoken language) 與 &lt;em>比手畫腳 (pantomiming)&lt;/em> 之間的對應關係也可在發展語言中的嬰兒身上見到。嬰兒在 1 歲到 2 歲的過程中，使用 &lt;em>指向 (pointing)&lt;/em> 的頻率逐漸攀升，但使用 &lt;em>比手畫腳 (pantomiming)&lt;/em> 與固定手勢 (conventional gestures) 的頻率卻持續下降。換句話說，&lt;em>口語&lt;/em> 的功能在嬰兒語言發展過程中，逐漸取代了 &lt;em>比手畫腳&lt;/em> 與固定手勢 &lt;span class="citation">(Tomasello, &lt;a href="#ref-tomasello2008">2008&lt;/a>, p. 145 - 153)&lt;/span>。&lt;a href="#fnref6" class="footnote-back">↩&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div>
&lt;p style="text-align:right;font-size:7px;margin-top:0px;margin-bottom:0px;padding-top:0px;padding-bottom:1px">
Last updated: 2019-03-07
&lt;/p></description><category>book</category><category>Linguistics</category><category>Psychology</category><category>Evolution</category><category>中文</category></item><item><title>Visualizing Language Loss in Taiwan</title><link>https://yongfu.name/2019/02/17/visualize-language-loss/</link><pubDate>Sun, 17 Feb 2019 00:00:00 +0000</pubDate><guid>https://yongfu.name/2019/02/17/visualize-language-loss/</guid><description>
&lt;p>&lt;a href="https://twlangsurvey.github.io">Taiwan Language Survey&lt;/a> is a small project I worked on during May to June in 2018. The idea was to create a survey that &lt;strong>continuously&lt;/strong> collects data and a web page that visualizes the collected data. The web page is updated weekly using &lt;a href="https://travis-ci.org/twLangSurvey/twLangSurvey.github.io">Travis-CI&lt;/a>.&lt;/p>
&lt;p>The main purpose of this survey is to raise public awareness of &lt;strong>language loss&lt;/strong> in Taiwan. Hence, the survey is designed to collect data that can provide valuable information about language loss, for example, some questions were asked to gain insight about the change of linguistic competence acoss generations in a family (i.e. across the subject’s parents, the subject, and the subject’s children). In addition to changes within family, information about the age of the subjects is also colleceted, meaning that we can see how linguistic competence changes among diffrent age groups of subjects in a community, i.e. is a language becoming more dominant or entering the dying process?&lt;/p>
&lt;p>Visualization is a powerful tool to capture how linguistic competences of different langauges are changing. But creating visualizations necessitates creativity – how can language loss be visualized? Below, I illustrate one of the methods I created for visualizing language loss – a visaulization inspired by the &lt;a href="https://en.wikipedia.org/wiki/Population_pyramid">age-sex pyramid&lt;/a>.&lt;/p>
&lt;div id="age-sex-pyramid-of-language" class="section level2">
&lt;h2>Age-Sex Pyramid of Language&lt;/h2>
&lt;p>The age-sex pyramid is used to visualize the population structure of a community. The vertical axis indicates the age and each horizontal bar represents an age group. The horizontal axis indicates the population size of male or female of a particular age group.&lt;/p>
&lt;p>The age-sex pyramid is a great tool to visualize the population structure since the ‘shape’ of the pyramid gives readers a lot information. For example, an ‘expansive pyramid’ has longer bars at the bottom of the pyramid, which indicates the population is young and growing. A ‘stationary pyramid’ looks like a rectangular bar, indicating the population sizes of different age groups are about the same. A ‘constructive’ pyramid indicates a shrinking population, which is narrowed at the bottom.&lt;/p>
&lt;p>Similarly, a &lt;strong>modified&lt;/strong> version of the age-sex pyramid, which I’ll call the ‘&lt;strong>age-sex pyramid of language&lt;/strong>’, can be used to visualize the population structure of a language and predicts the language’s &lt;strong>vitality&lt;/strong>. Instead of visualizing population size, the age-sex pyramid of language visualizes the &lt;strong>average fluency of a language&lt;/strong> on the horizontal axis.&lt;/p>
&lt;div class="figure">&lt;span id="fig:tw-pyramid">&lt;/span>
&lt;img src="https://twlangsurvey.github.io/out_graph/Tw_pyramid.png" alt="An age-sex pyramid of Taiwanese. The red bars on the left indicates females of different age groups and the blue bars on the right indicates males. The average fluency (values on the horizontal axis) is calculated from a six-point scale (0-5) on Taiwanese fluency." width="70%" />
&lt;p class="caption">
Figure 1: An age-sex pyramid of Taiwanese. The red bars on the left indicates females of different age groups and the blue bars on the right indicates males. The average fluency (values on the horizontal axis) is calculated from a six-point scale (0-5) on Taiwanese fluency.
&lt;/p>
&lt;/div>
&lt;p>As shown in Figure &lt;a href="#fig:tw-pyramid">1&lt;/a>, the shape of the age-sex pyramid of &lt;a href="https://en.wikipedia.org/wiki/Taiwanese_Hokkien">Taiwanese&lt;/a> in Taiwan&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> is an ‘&lt;strong>inverted triangle&lt;/strong>’, which is almost never seen in the conventional population pyramid. However, this inverted triangular shape is expected to appear quite often, since it indicates an ongoing language loss in a community.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;strong>Vitality of Language&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Shape of Pyramid&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td>Shrinking and Dying&lt;/td>
&lt;td>Inverted Triangle&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td>Growing&lt;/td>
&lt;td>Triangle&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td>Stable&lt;/td>
&lt;td>Rectangular Bar&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/div>
&lt;div id="drawing-age-sex-pyramid-with-ggplot2" class="section level2">
&lt;h2>Drawing Age-Sex Pyramid with ggplot2&lt;/h2>
&lt;p>As complex as it might seem, an age-sex pyramid created with ggplot2 is actually a (modified) bar chart. I learned this on &lt;a href="https://stackoverflow.com/a/36804394">stackoverflow&lt;/a>, and the trick is&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>Use &lt;code>ifelse&lt;/code> to flip the value (here, population size) according to the gender of the age group&lt;/li>
&lt;li>Use &lt;code>geom_bar(stat = &amp;quot;identity&amp;quot;)&lt;/code> to let the heights of the bars represent values in the data frame, i.e. the value given to &lt;code>y&lt;/code>&lt;/li>
&lt;li>Use &lt;code>coord_flip()&lt;/code> to make the bars horizontal&lt;/li>
&lt;/ol>
&lt;pre class="language-r">&lt;code class="language-r">&lt;span class="kw">set.seed&lt;/span>(&lt;span class="dv">1&lt;/span>)
df0 &amp;lt;-&lt;span class="st"> &lt;/span>tibble&lt;span class="op">::&lt;/span>&lt;span class="kw">tibble&lt;/span>(
&lt;span class="dt">Age =&lt;/span> &lt;span class="kw">rep&lt;/span>(&lt;span class="kw">c&lt;/span>(&lt;span class="st">&amp;#39;10-19&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;20-29&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;30-39&amp;#39;&lt;/span>), &lt;span class="dv">2&lt;/span>),
&lt;span class="dt">Gender =&lt;/span> &lt;span class="kw">rep&lt;/span>(&lt;span class="kw">c&lt;/span>(&lt;span class="st">&amp;#39;Female&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;Male&amp;#39;&lt;/span>), &lt;span class="dt">each =&lt;/span> &lt;span class="dv">3&lt;/span>),
&lt;span class="dt">PopSize =&lt;/span> &lt;span class="kw">sample&lt;/span>(&lt;span class="dv">0&lt;/span>&lt;span class="op">:&lt;/span>&lt;span class="dv">100&lt;/span>, &lt;span class="dt">size =&lt;/span> &lt;span class="dv">6&lt;/span>, &lt;span class="dt">replace =&lt;/span> T)
)
df0&lt;/code>&lt;/pre>
&lt;div class="kable-table">
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th align="left">Age&lt;/th>
&lt;th align="left">Gender&lt;/th>
&lt;th align="right">PopSize&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="left">10-19&lt;/td>
&lt;td align="left">Female&lt;/td>
&lt;td align="right">26&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">20-29&lt;/td>
&lt;td align="left">Female&lt;/td>
&lt;td align="right">37&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">30-39&lt;/td>
&lt;td align="left">Female&lt;/td>
&lt;td align="right">57&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">10-19&lt;/td>
&lt;td align="left">Male&lt;/td>
&lt;td align="right">91&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">20-29&lt;/td>
&lt;td align="left">Male&lt;/td>
&lt;td align="right">20&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">30-39&lt;/td>
&lt;td align="left">Male&lt;/td>
&lt;td align="right">90&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/div>
&lt;pre class="language-r">&lt;code class="language-r">&lt;span class="kw">library&lt;/span>(ggplot2)
pl &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">ggplot&lt;/span>(df0, &lt;span class="kw">aes&lt;/span>(&lt;span class="dt">x =&lt;/span> Age,
&lt;span class="dt">y =&lt;/span> &lt;span class="kw">ifelse&lt;/span>(Gender &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;Male&amp;#39;&lt;/span>, PopSize, &lt;span class="op">-&lt;/span>PopSize),
&lt;span class="dt">fill =&lt;/span> Gender)) &lt;span class="op">+&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">geom_bar&lt;/span>(&lt;span class="dt">stat =&lt;/span> &lt;span class="st">&amp;#39;identity&amp;#39;&lt;/span>) &lt;span class="op">+&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">coord_flip&lt;/span>()
pl&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://img.yongfu.name/assets/visualize-language-loss/unnamed-chunk-1-1.png" width="70%" />&lt;/p>
&lt;p>To center the plot (i.e. to make the point where population size is zero at the center of the plot), we have to scale the axis of ‘population size’ (&lt;code>y&lt;/code>) with &lt;code>scale_y_continuous&lt;/code>:&lt;/p>
&lt;pre class="language-r">&lt;code class="language-r">pl &lt;span class="op">+&lt;/span>&lt;span class="st"> &lt;/span>&lt;span class="kw">scale_y_continuous&lt;/span>(&lt;span class="dt">limits =&lt;/span> &lt;span class="kw">c&lt;/span>(&lt;span class="op">-&lt;/span>&lt;span class="dv">100&lt;/span>, &lt;span class="dv">100&lt;/span>),
&lt;span class="dt">breaks =&lt;/span> &lt;span class="kw">seq&lt;/span>(&lt;span class="op">-&lt;/span>&lt;span class="dv">100&lt;/span>, &lt;span class="dv">100&lt;/span>, &lt;span class="dv">25&lt;/span>),
&lt;span class="dt">labels =&lt;/span> abs) &lt;span class="op">+&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">labs&lt;/span>(&lt;span class="dt">y =&lt;/span> &lt;span class="st">&amp;#39;Population Size&amp;#39;&lt;/span>)&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://img.yongfu.name/assets/visualize-language-loss/unnamed-chunk-2-1.png" width="70%" />&lt;/p>
&lt;p>where &lt;code>abs&lt;/code> in &lt;code>labels&lt;/code> is the function &lt;code>abs()&lt;/code>. By default, &lt;code>ggplot2&lt;/code> pass the value given in &lt;code>breaks&lt;/code> to the the function specified in &lt;code>labels&lt;/code>.&lt;/p>
&lt;/div>
&lt;div id="visualizing-language-loss" class="section level2">
&lt;h2>Visualizing Language Loss&lt;/h2>
&lt;p>To create an age-sex pyramid of language, the data structure needed is exactly the same as the one above, except the variable, &lt;code>PopSize&lt;/code>, is replaced by ‘average fluency’ of a language. But since most people in Taiwan can speak more than one language (e.g. Mandarin-Taiwanese, Mandarin-Taiwanese-Hakka, Mandarin-English, etc.), the real data from the survey is a bit more complex Basically, the data structure needed to draw an age-sex pyramid of language looks like:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;strong>Gender&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Ethnicity&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Age Group&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Avg. Fluency&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td>female&lt;/td>
&lt;td>Mandarin&lt;/td>
&lt;td>20-24&lt;/td>
&lt;td>4.53&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td>male&lt;/td>
&lt;td>Taiwanese&lt;/td>
&lt;td>20-24&lt;/td>
&lt;td>2.78&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td>…&lt;/td>
&lt;td>…&lt;/td>
&lt;td>…&lt;/td>
&lt;td>…&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td>female&lt;/td>
&lt;td>Hakka&lt;/td>
&lt;td>25-29&lt;/td>
&lt;td>2.23&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td>male&lt;/td>
&lt;td>Taiwanese&lt;/td>
&lt;td>35-39&lt;/td>
&lt;td>3.57&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;div id="preparation-of-data" class="section level3">
&lt;h3>Preparation of Data&lt;/h3>
&lt;p>The raw data of &lt;a href="https://twlangsurvey.github.io/">Taiwan Language Survey&lt;/a> can be retrieved &lt;a href="https://docs.google.com/spreadsheets/d/1NOJ9O_zBR6s-9e1fFGVcRaBjn5qQuVB9ZeSebhBctoM/edit?usp=sharing">here&lt;/a>. The survey and raw data is in traditional Chinese. I’ll skip the step of cleaning raw data (e.g., turn variable names to English) and used the cleaned data &lt;code>survey.rds&lt;/code> instead.&lt;/p>
&lt;pre class="language-r">&lt;code class="language-r">temp &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">tempfile&lt;/span>()
&lt;span class="kw">download.file&lt;/span>(&lt;span class="st">&amp;#39;https://raw.githubusercontent.com/twLangSurvey/twLangSurvey.github.io/master/data/survey.rds&amp;#39;&lt;/span>, &lt;span class="dt">destfile =&lt;/span> temp)
data &amp;lt;-&lt;span class="st"> &lt;/span>readr&lt;span class="op">::&lt;/span>&lt;span class="kw">read_rds&lt;/span>(temp)
&lt;span class="kw">head&lt;/span>(data, &lt;span class="dv">3&lt;/span>)&lt;/code>&lt;/pre>
&lt;div class="kable-table">
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th align="left">date&lt;/th>
&lt;th align="left">curr_resid&lt;/th>
&lt;th align="right">curr_resid_since&lt;/th>
&lt;th align="left">settle_5yy&lt;/th>
&lt;th align="left">home_town&lt;/th>
&lt;th align="left">gender&lt;/th>
&lt;th align="right">age&lt;/th>
&lt;th align="right">kid_num&lt;/th>
&lt;th align="left">edu_level&lt;/th>
&lt;th align="left">work&lt;/th>
&lt;th align="left">income&lt;/th>
&lt;th align="left">work_hr&lt;/th>
&lt;th align="left">tribe&lt;/th>
&lt;th align="right">Mand_listen&lt;/th>
&lt;th align="right">Mand_speak&lt;/th>
&lt;th align="right">Tw_listen&lt;/th>
&lt;th align="right">Tw_speak&lt;/th>
&lt;th align="right">Hak_listen&lt;/th>
&lt;th align="right">Hak_speak&lt;/th>
&lt;th align="right">Ind_listen&lt;/th>
&lt;th align="right">Ind_speak&lt;/th>
&lt;th align="right">SEA_listen&lt;/th>
&lt;th align="right">SEA_speak&lt;/th>
&lt;th align="right">Eng_listen&lt;/th>
&lt;th align="right">Eng_speak&lt;/th>
&lt;th align="left">first_lang&lt;/th>
&lt;th align="left">when_Mand&lt;/th>
&lt;th align="left">when_Tw&lt;/th>
&lt;th align="left">when_Hak&lt;/th>
&lt;th align="left">when_Ind&lt;/th>
&lt;th align="left">when_SEA&lt;/th>
&lt;th align="left">when_Eng&lt;/th>
&lt;th align="left">m_guard_identity&lt;/th>
&lt;th align="left">f_guard_identity&lt;/th>
&lt;th align="right">dad_Mand_speak&lt;/th>
&lt;th align="right">dad_Tw_speak&lt;/th>
&lt;th align="right">dad_Hak_speak&lt;/th>
&lt;th align="right">dad_Eng_speak&lt;/th>
&lt;th align="right">dad_Ind_speak&lt;/th>
&lt;th align="right">dad_SEA_speak&lt;/th>
&lt;th align="right">mom_Mand_speak&lt;/th>
&lt;th align="right">mom_Tw_speak&lt;/th>
&lt;th align="right">mom_Hak_speak&lt;/th>
&lt;th align="right">mom_Eng_speak&lt;/th>
&lt;th align="right">mom_Ind_speak&lt;/th>
&lt;th align="right">mom_SEA_speak&lt;/th>
&lt;th align="left">dad_mom_Mand_fq&lt;/th>
&lt;th align="left">dad_mom_Tw_fq&lt;/th>
&lt;th align="left">dad_mom_Hak_fq&lt;/th>
&lt;th align="left">dad_mom_Ind_fq&lt;/th>
&lt;th align="left">dad_mom_SEA_fq&lt;/th>
&lt;th align="left">dad_mom_Other_fq&lt;/th>
&lt;th align="left">me_dad_Mand_fq&lt;/th>
&lt;th align="left">me_dad_Tw_fq&lt;/th>
&lt;th align="left">me_dad_Hak_fq&lt;/th>
&lt;th align="left">me_dad_Ind_fq&lt;/th>
&lt;th align="left">me_dad_SEA_fq&lt;/th>
&lt;th align="left">me_dad_Other_fq&lt;/th>
&lt;th align="left">me_mom_Mand_fq&lt;/th>
&lt;th align="left">me_mom_Tw_fq&lt;/th>
&lt;th align="left">me_mom_Hak_fq&lt;/th>
&lt;th align="left">me_mom_Ind_fq&lt;/th>
&lt;th align="left">me_mom_SEA_fq&lt;/th>
&lt;th align="left">me_mom_Other_fq&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="left">2018-06-12&lt;/td>
&lt;td align="left">106&lt;/td>
&lt;td align="right">1996&lt;/td>
&lt;td align="left">是&lt;/td>
&lt;td align="left">428&lt;/td>
&lt;td align="left">女&lt;/td>
&lt;td align="right">56&lt;/td>
&lt;td align="right">2&lt;/td>
&lt;td align="left">大學&lt;/td>
&lt;td align="left">金融業&lt;/td>
&lt;td align="left">10萬以上&lt;/td>
&lt;td align="left">45 - 50 小時&lt;/td>
&lt;td align="left">不具原住民身份&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">4&lt;/td>
&lt;td align="right">3&lt;/td>
&lt;td align="right">2&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">2&lt;/td>
&lt;td align="right">1&lt;/td>
&lt;td align="left">華語&lt;/td>
&lt;td align="left">7歲前&lt;/td>
&lt;td align="left">7歲前&lt;/td>
&lt;td align="left">未學會&lt;/td>
&lt;td align="left">未學會&lt;/td>
&lt;td align="left">未學會&lt;/td>
&lt;td align="left">12-15歲&lt;/td>
&lt;td align="left">父親&lt;/td>
&lt;td align="left">母親&lt;/td>
&lt;td align="right">3&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">3&lt;/td>
&lt;td align="right">4&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="left">幾乎全用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎全用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">約一半&lt;/td>
&lt;td align="left">多數使用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">2018-06-13&lt;/td>
&lt;td align="left">204&lt;/td>
&lt;td align="right">2004&lt;/td>
&lt;td align="left">是&lt;/td>
&lt;td align="left">204&lt;/td>
&lt;td align="left">女&lt;/td>
&lt;td align="right">57&lt;/td>
&lt;td align="right">1&lt;/td>
&lt;td align="left">碩士&lt;/td>
&lt;td align="left">製造業&lt;/td>
&lt;td align="left">10萬以上&lt;/td>
&lt;td align="left">50 - 55 小時&lt;/td>
&lt;td align="left">不具原住民身份&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">4&lt;/td>
&lt;td align="right">4&lt;/td>
&lt;td align="left">華語&lt;/td>
&lt;td align="left">7歲前&lt;/td>
&lt;td align="left">7歲前&lt;/td>
&lt;td align="left">未學會&lt;/td>
&lt;td align="left">未學會&lt;/td>
&lt;td align="left">未學會&lt;/td>
&lt;td align="left">12-15歲&lt;/td>
&lt;td align="left">父親&lt;/td>
&lt;td align="left">母親&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">1&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">1&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">多數使用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">多數使用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">多數使用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">2018-06-13&lt;/td>
&lt;td align="left">103&lt;/td>
&lt;td align="right">2013&lt;/td>
&lt;td align="left">是&lt;/td>
&lt;td align="left">100&lt;/td>
&lt;td align="left">男&lt;/td>
&lt;td align="right">37&lt;/td>
&lt;td align="right">2&lt;/td>
&lt;td align="left">大學&lt;/td>
&lt;td align="left">金融業&lt;/td>
&lt;td align="left">55,000 - 60,000&lt;/td>
&lt;td align="left">25 - 30 小時&lt;/td>
&lt;td align="left">不具原住民身份&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">2&lt;/td>
&lt;td align="right">1&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">3&lt;/td>
&lt;td align="right">2&lt;/td>
&lt;td align="left">華語&lt;/td>
&lt;td align="left">7歲前&lt;/td>
&lt;td align="left">未學會&lt;/td>
&lt;td align="left">未學會&lt;/td>
&lt;td align="left">未學會&lt;/td>
&lt;td align="left">未學會&lt;/td>
&lt;td align="left">7-12歲&lt;/td>
&lt;td align="left">父親&lt;/td>
&lt;td align="left">母親&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">1&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">3&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">4&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="left">幾乎全用&lt;/td>
&lt;td align="left">少數使用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">多數使用&lt;/td>
&lt;td align="left">少數使用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎全用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;td align="left">幾乎不用&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/div>
&lt;p>The survey data, &lt;code>data&lt;/code>, contains 22 variables and 267 observations (subjects). I only need these variables below to create the plot I want:&lt;/p>
&lt;ul>
&lt;li>&lt;code>gender&lt;/code>: The gender of the subject&lt;/li>
&lt;li>&lt;code>age&lt;/code>: The age of the subject&lt;/li>
&lt;li>&lt;code>m_guard_identity&lt;/code>: Male guardian of the subject, should be ‘father’ in most cases&lt;/li>
&lt;li>&lt;code>f_guard_identity&lt;/code>: Female guardian of the subject, should be ‘mother’ in most cases&lt;/li>
&lt;li>&lt;code>&amp;lt;lang&amp;gt;_speak&lt;/code>: The subject’s fluency of a language. &lt;code>&amp;lt;lang&amp;gt;&lt;/code> is one of ‘Mand’ (Mandarin), ‘Tw’ (Taiwanese), ‘Hak’ (&lt;a href="https://en.wikipedia.org/wiki/Hakka_Chinese">Hakka&lt;/a>), ‘Ind’ (languages of the indigenous peoples, aka &lt;a href="https://en.wikipedia.org/wiki/Formosan_languages">Formosan languages&lt;/a>, belong to Austronesian languages), ‘SEA’ (languages from South Easth Asia), and ‘Eng’ (English)&lt;/li>
&lt;li>&lt;code>dad_&amp;lt;lang&amp;gt;_speak&lt;/code>: The subject’s male guardian’s fluency of a language. &lt;code>&amp;lt;lang&amp;gt;&lt;/code> is same as above.&lt;/li>
&lt;li>&lt;code>mom_&amp;lt;lang&amp;gt;_speak&lt;/code>: The subject’s female guardian’s fluency of a language. &lt;code>&amp;lt;lang&amp;gt;&lt;/code> is same as above.&lt;/li>
&lt;/ul>
&lt;pre class="language-r">&lt;code class="language-r">&lt;span class="kw">library&lt;/span>(dplyr)
lang &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">c&lt;/span>(&lt;span class="st">&amp;#39;Mand&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;Tw&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;Hak&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;Ind&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;SEA&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;Eng&amp;#39;&lt;/span>)
cols &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">c&lt;/span>(&lt;span class="st">&amp;#39;gender&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;age&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;m_guard_identity&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;f_guard_identity&amp;#39;&lt;/span>,
&lt;span class="kw">paste0&lt;/span>(lang, &lt;span class="st">&amp;#39;_speak&amp;#39;&lt;/span>),
&lt;span class="kw">paste0&lt;/span>(&lt;span class="st">&amp;#39;dad_&amp;#39;&lt;/span>, lang, &lt;span class="st">&amp;#39;_speak&amp;#39;&lt;/span>),
&lt;span class="kw">paste0&lt;/span>(&lt;span class="st">&amp;#39;mom_&amp;#39;&lt;/span>, lang, &lt;span class="st">&amp;#39;_speak&amp;#39;&lt;/span>)
)
data &amp;lt;-&lt;span class="st"> &lt;/span>data[, cols] &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">filter&lt;/span>(gender &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;男&amp;#39;&lt;/span> &lt;span class="op">|&lt;/span>&lt;span class="st"> &lt;/span>gender &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;女&amp;#39;&lt;/span>)&lt;/code>&lt;/pre>
&lt;p>Since some content of the survey data is in Chinese, the code below is used to translate it to English:&lt;/p>
&lt;pre class="language-r">&lt;code class="language-r">ch2eng &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="cf">function&lt;/span>(x) {
&lt;span class="cf">if&lt;/span> (x &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;男&amp;#39;&lt;/span>) &lt;span class="kw">return&lt;/span>(&lt;span class="st">&amp;#39;Male&amp;#39;&lt;/span>)
&lt;span class="cf">if&lt;/span> (x &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;女&amp;#39;&lt;/span>) &lt;span class="kw">return&lt;/span>(&lt;span class="st">&amp;#39;Female&amp;#39;&lt;/span>)
&lt;span class="cf">if&lt;/span> (x &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;母親&amp;#39;&lt;/span>) &lt;span class="kw">return&lt;/span>(&lt;span class="st">&amp;#39;Mother&amp;#39;&lt;/span>)
&lt;span class="cf">if&lt;/span> (x &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;父親&amp;#39;&lt;/span>) &lt;span class="kw">return&lt;/span>(&lt;span class="st">&amp;#39;Father&amp;#39;&lt;/span>)
&lt;span class="cf">if&lt;/span> (x &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;無&amp;#39;&lt;/span>) &lt;span class="kw">return&lt;/span>(&lt;span class="st">&amp;#39;None&amp;#39;&lt;/span>)
&lt;span class="cf">if&lt;/span> (x &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;(外)祖父&amp;#39;&lt;/span>) &lt;span class="kw">return&lt;/span>(&lt;span class="st">&amp;#39;Grandpa&amp;#39;&lt;/span>)
&lt;span class="cf">if&lt;/span> (x &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;(外)祖母&amp;#39;&lt;/span>) &lt;span class="kw">return&lt;/span>(&lt;span class="st">&amp;#39;Grandma&amp;#39;&lt;/span>)
&lt;span class="cf">if&lt;/span> (x &lt;span class="op">%in%&lt;/span>&lt;span class="st"> &lt;/span>&lt;span class="kw">c&lt;/span>(&lt;span class="st">&amp;#39;阿姨&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;嬸嬸&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;舅媽&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;姑姑&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;伯母&amp;#39;&lt;/span>)) &lt;span class="kw">return&lt;/span>(&lt;span class="st">&amp;#39;Aunt&amp;#39;&lt;/span>)
&lt;span class="cf">if&lt;/span> (x &lt;span class="op">%in%&lt;/span>&lt;span class="st"> &lt;/span>&lt;span class="kw">c&lt;/span>(&lt;span class="st">&amp;#39;叔叔&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;伯伯&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;舅舅&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;姑丈&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;姨丈&amp;#39;&lt;/span>)) &lt;span class="kw">return&lt;/span>(&lt;span class="st">&amp;#39;Uncle&amp;#39;&lt;/span>)
&lt;span class="kw">message&lt;/span>(&lt;span class="st">&amp;#39;No translation found for `&amp;#39;&lt;/span>, x, &lt;span class="st">&amp;#39;`&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;&lt;/span>&lt;span class="ch">\n&lt;/span>&lt;span class="st">&amp;#39;&lt;/span>)
&lt;span class="kw">return&lt;/span>(x)
}
ch2eng_vec &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="cf">function&lt;/span>(vec) {
new_vec &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">vector&lt;/span>(&lt;span class="kw">typeof&lt;/span>(vec), &lt;span class="kw">length&lt;/span>(vec))
&lt;span class="cf">for&lt;/span> (i &lt;span class="cf">in&lt;/span> &lt;span class="kw">seq_along&lt;/span>(vec)) {
new_vec[[i]] &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">ch2eng&lt;/span>(vec[[i]])
}
&lt;span class="kw">return&lt;/span>(new_vec)
}
data &amp;lt;-&lt;span class="st"> &lt;/span>data &lt;span class="op">%&amp;gt;%&lt;/span>&lt;span class="st"> &lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">mutate&lt;/span>(&lt;span class="dt">gender =&lt;/span> &lt;span class="kw">ch2eng_vec&lt;/span>(gender),
&lt;span class="dt">m_guard_identity =&lt;/span> &lt;span class="kw">ch2eng_vec&lt;/span>(m_guard_identity),
&lt;span class="dt">f_guard_identity =&lt;/span> &lt;span class="kw">ch2eng_vec&lt;/span>(f_guard_identity))
&lt;span class="kw">head&lt;/span>(data)&lt;/code>&lt;/pre>
&lt;div class="kable-table">
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th align="left">gender&lt;/th>
&lt;th align="right">age&lt;/th>
&lt;th align="left">m_guard_identity&lt;/th>
&lt;th align="left">f_guard_identity&lt;/th>
&lt;th align="right">Mand_speak&lt;/th>
&lt;th align="right">Tw_speak&lt;/th>
&lt;th align="right">Hak_speak&lt;/th>
&lt;th align="right">Ind_speak&lt;/th>
&lt;th align="right">SEA_speak&lt;/th>
&lt;th align="right">Eng_speak&lt;/th>
&lt;th align="right">dad_Mand_speak&lt;/th>
&lt;th align="right">dad_Tw_speak&lt;/th>
&lt;th align="right">dad_Hak_speak&lt;/th>
&lt;th align="right">dad_Ind_speak&lt;/th>
&lt;th align="right">dad_SEA_speak&lt;/th>
&lt;th align="right">dad_Eng_speak&lt;/th>
&lt;th align="right">mom_Mand_speak&lt;/th>
&lt;th align="right">mom_Tw_speak&lt;/th>
&lt;th align="right">mom_Hak_speak&lt;/th>
&lt;th align="right">mom_Ind_speak&lt;/th>
&lt;th align="right">mom_SEA_speak&lt;/th>
&lt;th align="right">mom_Eng_speak&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="left">Female&lt;/td>
&lt;td align="right">56&lt;/td>
&lt;td align="left">Father&lt;/td>
&lt;td align="left">Mother&lt;/td>
&lt;td align="right">4&lt;/td>
&lt;td align="right">2&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">1&lt;/td>
&lt;td align="right">3&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">3&lt;/td>
&lt;td align="right">4&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">Female&lt;/td>
&lt;td align="right">57&lt;/td>
&lt;td align="left">Father&lt;/td>
&lt;td align="left">Mother&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">4&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">1&lt;/td>
&lt;td align="right">1&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">Male&lt;/td>
&lt;td align="right">37&lt;/td>
&lt;td align="left">Father&lt;/td>
&lt;td align="left">Mother&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">1&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">2&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">1&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">3&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">4&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">Female&lt;/td>
&lt;td align="right">44&lt;/td>
&lt;td align="left">Father&lt;/td>
&lt;td align="left">Mother&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">4&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">4&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">Male&lt;/td>
&lt;td align="right">62&lt;/td>
&lt;td align="left">None&lt;/td>
&lt;td align="left">None&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">1&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">4&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">Female&lt;/td>
&lt;td align="right">56&lt;/td>
&lt;td align="left">Father&lt;/td>
&lt;td align="left">Mother&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">1&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;td align="right">0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/div>
&lt;div id="defining-ethnicity" class="section level4">
&lt;h4>Defining Ethnicity&lt;/h4>
&lt;p>You might notice that there is no variable in the data which explicitly indicates the ethnicity of the subject. To serve the purpose of this survey – visualizing the vitality of languages in a community, ethnicity is defined solely by the linguistics competence of a subject’s guardians.
To give a specific example, let &lt;code>subject A&lt;/code> has a mother who &lt;strong>can speak&lt;/strong>&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> Mandarin and Taiwanese and a father who speaks Mandarin and Hakka, then &lt;code>subject A&lt;/code> is categorized as a Mandarin, a Taiwanese, and a Hakka simultaneously.&lt;/p>
&lt;p>The function &lt;code>filter_ethnic()&lt;/code> is used to filter out subjects with specified ‘ethnicity’. This function is useful for drawing age-sex pyramid for each of the six languages.&lt;/p>
&lt;pre class="language-r">&lt;code class="language-r">filter_ethnic &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="cf">function&lt;/span>(df, lang, &lt;span class="dt">lev =&lt;/span> &lt;span class="dv">3&lt;/span>) {
sp_lang &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">vector&lt;/span>(&lt;span class="st">&amp;quot;character&amp;quot;&lt;/span>, &lt;span class="dv">3&lt;/span>)
sp_lang[&lt;span class="dv">1&lt;/span>] &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">paste0&lt;/span>(&lt;span class="st">&amp;quot;dad_&amp;quot;&lt;/span>, lang, &lt;span class="st">&amp;quot;_speak&amp;quot;&lt;/span>)
sp_lang[&lt;span class="dv">2&lt;/span>] &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">paste0&lt;/span>(&lt;span class="st">&amp;quot;mom_&amp;quot;&lt;/span>, lang, &lt;span class="st">&amp;quot;_speak&amp;quot;&lt;/span>)
sp_lang[&lt;span class="dv">3&lt;/span>] &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">paste0&lt;/span>(lang, &lt;span class="st">&amp;quot;_speak&amp;quot;&lt;/span>)
df2 &amp;lt;-&lt;span class="st"> &lt;/span>df &lt;span class="op">%&amp;gt;%&lt;/span>&lt;span class="st"> &lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">filter&lt;/span>(m_guard_identity &lt;span class="op">!=&lt;/span>&lt;span class="st"> &amp;#39;None&amp;#39;&lt;/span> &lt;span class="op">|&lt;/span>&lt;span class="st"> &lt;/span>f_guard_identity &lt;span class="op">!=&lt;/span>&lt;span class="st"> &amp;#39;None&amp;#39;&lt;/span>) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">filter&lt;/span>(.data[[sp_lang[&lt;span class="dv">1&lt;/span>]]] &lt;span class="op">&amp;gt;=&lt;/span>&lt;span class="st"> &lt;/span>lev &lt;span class="op">|&lt;/span>&lt;span class="st"> &lt;/span>.data[[sp_lang[&lt;span class="dv">2&lt;/span>]]] &lt;span class="op">&amp;gt;=&lt;/span>&lt;span class="st"> &lt;/span>lev) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">select&lt;/span>(age, gender, sp_lang)
&lt;span class="kw">return&lt;/span>(df2)
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div id="assinging-age-group-to-subjects" class="section level3">
&lt;h3>Assinging Age Group to Subjects&lt;/h3>
&lt;p>Remember that the data structure needed for plotting age-sex pyramids requires &lt;strong>age group to be the basic unit&lt;/strong>. &lt;code>data&lt;/code> now consisits of single subjects, and we need information to group subjects together according to their ages. &lt;code>mutate_age_group()&lt;/code> creates a new variable &lt;code>age_group&lt;/code> by the subject’s age.&lt;/p>
&lt;pre class="language-r">&lt;code class="language-r">mutate_age_group &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="cf">function&lt;/span>(df, &lt;span class="dt">range =&lt;/span> &lt;span class="dv">5&lt;/span>){
df&lt;span class="op">$&lt;/span>age_group &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">as.character&lt;/span>(
&lt;span class="kw">cut&lt;/span>(df&lt;span class="op">$&lt;/span>age, &lt;span class="dt">right =&lt;/span> F, &lt;span class="dt">breaks =&lt;/span> &lt;span class="kw">seq&lt;/span>(&lt;span class="dv">10&lt;/span>, &lt;span class="dv">95&lt;/span>, &lt;span class="dt">by =&lt;/span> range))
)
&lt;span class="kw">return&lt;/span>(df)
}&lt;/code>&lt;/pre>
&lt;p>&lt;code>cut()&lt;/code> takes a numeric vector as its first input, and codes the values of the vector into new values according to the interval they fall into. In &lt;code>mutate_age_group()&lt;/code>, &lt;code>cut()&lt;/code> codes the input vectors according to the intervals specified in the argument &lt;code>breaks&lt;/code>.&lt;/p>
&lt;p>Now we can use these functions to add more information to the data frame. The idea is to first create a separated data frame for each ethnicity&lt;a href="#fn3" class="footnote-ref" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a> (by &lt;code>filter_ethnic()&lt;/code>), then attact new variables to the data frame that indicate a subject’s ethnicity (&lt;code>ethn_group&lt;/code>) and age group (&lt;code>age_group&lt;/code>).&lt;/p>
&lt;pre class="language-r">&lt;code class="language-r">lang &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">c&lt;/span>(&lt;span class="st">&amp;#39;Mand&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;Tw&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;Hak&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;Ind&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;SEA&amp;#39;&lt;/span>, &lt;span class="st">&amp;#39;Eng&amp;#39;&lt;/span>)
lev &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">c&lt;/span>(&lt;span class="dv">3&lt;/span>, &lt;span class="dv">3&lt;/span>, &lt;span class="dv">3&lt;/span>, &lt;span class="dv">3&lt;/span>, &lt;span class="dv">3&lt;/span>, &lt;span class="dv">0&lt;/span>)
ethn_list_df &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">vector&lt;/span>(&lt;span class="st">&amp;quot;list&amp;quot;&lt;/span>, &lt;span class="kw">length&lt;/span>(lang))
&lt;span class="cf">for&lt;/span> (i &lt;span class="cf">in&lt;/span> &lt;span class="kw">seq_along&lt;/span>(lang)){
ethn_list_df[[i]] &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">filter_ethnic&lt;/span>(data,
&lt;span class="dt">lang =&lt;/span> lang[i],
&lt;span class="dt">lev =&lt;/span> lev[i]) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">mutate&lt;/span>(&lt;span class="dt">ethn_group =&lt;/span> lang[i]) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">mutate_age_group&lt;/span>() &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">select&lt;/span>(age, gender, age_group, ethn_group,
&lt;span class="kw">paste0&lt;/span>(lang[i], &lt;span class="st">&amp;quot;_speak&amp;quot;&lt;/span>)) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">rename&lt;/span>(&lt;span class="dt">lang_fluency =&lt;/span> &lt;span class="kw">paste0&lt;/span>(lang[i], &lt;span class="st">&amp;quot;_speak&amp;quot;&lt;/span>))
}&lt;/code>&lt;/pre>
&lt;p>Then we can recombine these data frames back to a single one, and this new data frame now has information about a subject’s ethinicity and age group he/she belongs to. (Note that the new data frame is &lt;strong>expended&lt;/strong> since one subject can have several ethnicity, i.e. one subject can appear in different rows of the data frame with different ethnicity.)&lt;/p>
&lt;pre class="language-r">&lt;code class="language-r">&lt;span class="kw">bind_rows&lt;/span>(ethn_list_df) &lt;span class="op">%&amp;gt;%&lt;/span>&lt;span class="st"> &lt;/span>&lt;span class="kw">head&lt;/span>()&lt;/code>&lt;/pre>
&lt;div class="kable-table">
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th align="right">age&lt;/th>
&lt;th align="left">gender&lt;/th>
&lt;th align="left">age_group&lt;/th>
&lt;th align="left">ethn_group&lt;/th>
&lt;th align="right">lang_fluency&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="right">56&lt;/td>
&lt;td align="left">Female&lt;/td>
&lt;td align="left">[55,60)&lt;/td>
&lt;td align="left">Mand&lt;/td>
&lt;td align="right">4&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="right">57&lt;/td>
&lt;td align="left">Female&lt;/td>
&lt;td align="left">[55,60)&lt;/td>
&lt;td align="left">Mand&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="right">37&lt;/td>
&lt;td align="left">Male&lt;/td>
&lt;td align="left">[35,40)&lt;/td>
&lt;td align="left">Mand&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="right">44&lt;/td>
&lt;td align="left">Female&lt;/td>
&lt;td align="left">[40,45)&lt;/td>
&lt;td align="left">Mand&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="right">56&lt;/td>
&lt;td align="left">Female&lt;/td>
&lt;td align="left">[55,60)&lt;/td>
&lt;td align="left">Mand&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="right">53&lt;/td>
&lt;td align="left">Male&lt;/td>
&lt;td align="left">[50,55)&lt;/td>
&lt;td align="left">Mand&lt;/td>
&lt;td align="right">5&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/div>
&lt;/div>
&lt;div id="data-for-plotting" class="section level3">
&lt;h3>Data for Plotting&lt;/h3>
&lt;p>Finally, we are ready to group the subjects together according to his/her &lt;code>gender&lt;/code>, &lt;code>ethnicity&lt;/code>, and &lt;code>age_group&lt;/code>. After grouping, we can use &lt;code>dplyr::summarise()&lt;/code> to calculate each group’s fluency of the language, which will be used as the variable on the horizontal axis of the age-sex pyramid.&lt;/p>
&lt;pre class="language-r">&lt;code class="language-r">pl_data &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">bind_rows&lt;/span>(ethn_list_df) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">group_by&lt;/span>(gender, ethn_group, age_group) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">summarise&lt;/span>(&lt;span class="kw">mean&lt;/span>(lang_fluency)) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">rename&lt;/span>(&lt;span class="dt">avg_fluency =&lt;/span> &lt;span class="st">`&lt;/span>&lt;span class="dt">mean(lang_fluency)&lt;/span>&lt;span class="st">`&lt;/span>)
&lt;span class="kw">head&lt;/span>(pl_data)&lt;/code>&lt;/pre>
&lt;div class="kable-table">
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th align="left">gender&lt;/th>
&lt;th align="left">ethn_group&lt;/th>
&lt;th align="left">age_group&lt;/th>
&lt;th align="right">avg_fluency&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="left">Female&lt;/td>
&lt;td align="left">Eng&lt;/td>
&lt;td align="left">[15,20)&lt;/td>
&lt;td align="right">1.750&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">Female&lt;/td>
&lt;td align="left">Eng&lt;/td>
&lt;td align="left">[20,25)&lt;/td>
&lt;td align="right">2.950&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">Female&lt;/td>
&lt;td align="left">Eng&lt;/td>
&lt;td align="left">[25,30)&lt;/td>
&lt;td align="right">2.600&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">Female&lt;/td>
&lt;td align="left">Eng&lt;/td>
&lt;td align="left">[30,35)&lt;/td>
&lt;td align="right">3.000&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">Female&lt;/td>
&lt;td align="left">Eng&lt;/td>
&lt;td align="left">[35,40)&lt;/td>
&lt;td align="right">1.750&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">Female&lt;/td>
&lt;td align="left">Eng&lt;/td>
&lt;td align="left">[40,45)&lt;/td>
&lt;td align="right">2.125&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/div>
&lt;/div>
&lt;div id="plotting-function" class="section level3">
&lt;h3>Plotting Function&lt;/h3>
&lt;p>We are going to draw 6 age-sex pyramids, one for each languages. So instead of writing &lt;code>ggplot()&lt;/code> six times, I wrote a plotting function:&lt;/p>
&lt;pre class="language-r">&lt;code class="language-r">&lt;span class="kw">library&lt;/span>(ggplot2)
pl_pyramid &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="cf">function&lt;/span>(data, &lt;span class="dt">title =&lt;/span> &lt;span class="ot">NULL&lt;/span>) {
&lt;span class="kw">ggplot&lt;/span>(data,
&lt;span class="kw">aes&lt;/span>(&lt;span class="dt">x =&lt;/span> age_group,
&lt;span class="dt">y =&lt;/span> &lt;span class="kw">ifelse&lt;/span>(gender &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;Male&amp;#39;&lt;/span>, avg_fluency, &lt;span class="op">-&lt;/span>avg_fluency),
&lt;span class="dt">fill =&lt;/span> gender)) &lt;span class="op">+&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">geom_bar&lt;/span>(&lt;span class="dt">stat =&lt;/span> &lt;span class="st">&amp;quot;identity&amp;quot;&lt;/span>, &lt;span class="dt">width =&lt;/span> &lt;span class="fl">0.7&lt;/span>) &lt;span class="op">+&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">scale_y_continuous&lt;/span>(&lt;span class="dt">limits =&lt;/span> &lt;span class="kw">c&lt;/span>(&lt;span class="op">-&lt;/span>&lt;span class="dv">5&lt;/span>, &lt;span class="dv">5&lt;/span>),
&lt;span class="dt">breaks =&lt;/span> &lt;span class="kw">seq&lt;/span>(&lt;span class="op">-&lt;/span>&lt;span class="dv">5&lt;/span>, &lt;span class="dv">5&lt;/span>, &lt;span class="dv">1&lt;/span>),
&lt;span class="dt">labels =&lt;/span> &lt;span class="kw">abs&lt;/span>(&lt;span class="kw">seq&lt;/span>(&lt;span class="op">-&lt;/span>&lt;span class="dv">5&lt;/span>, &lt;span class="dv">5&lt;/span>, &lt;span class="dv">1&lt;/span>))) &lt;span class="op">+&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">coord_flip&lt;/span>() &lt;span class="op">+&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">scale_fill_manual&lt;/span>(&lt;span class="dt">values =&lt;/span> &lt;span class="kw">c&lt;/span>(&lt;span class="st">&amp;quot;#E41A1C&amp;quot;&lt;/span>, &lt;span class="st">&amp;quot;#377EB8&amp;quot;&lt;/span>),
&lt;span class="dt">breaks =&lt;/span> &lt;span class="kw">c&lt;/span>(&lt;span class="st">&amp;quot;Female&amp;quot;&lt;/span>, &lt;span class="st">&amp;quot;Male&amp;quot;&lt;/span>)) &lt;span class="op">+&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">labs&lt;/span>(&lt;span class="dt">x =&lt;/span> &lt;span class="st">&amp;quot;Age&amp;quot;&lt;/span>, &lt;span class="dt">y =&lt;/span> &lt;span class="st">&amp;quot;Fluency&amp;quot;&lt;/span>, &lt;span class="dt">fill =&lt;/span> &lt;span class="st">&amp;quot;&amp;quot;&lt;/span>, &lt;span class="dt">title =&lt;/span> title)
}&lt;/code>&lt;/pre>
&lt;p>Now we can start plotting. Let’s try &lt;code>Mand&lt;/code> (Mandarin) and &lt;code>Hak&lt;/code> (Hakka) first. We can use &lt;code>dplyr::filter()&lt;/code> to filter out people speaking these languages:&lt;/p>
&lt;pre class="language-r">&lt;code class="language-r">tweak &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">theme_bw&lt;/span>() &lt;span class="op">+&lt;/span>&lt;span class="st"> &lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">theme&lt;/span>(&lt;span class="dt">axis.text =&lt;/span> &lt;span class="kw">element_text&lt;/span>(&lt;span class="dt">size =&lt;/span> &lt;span class="dv">15&lt;/span>),
&lt;span class="dt">legend.justification =&lt;/span> &lt;span class="st">&amp;quot;right&amp;quot;&lt;/span>,
&lt;span class="dt">legend.position =&lt;/span> &lt;span class="st">&amp;quot;bottom&amp;quot;&lt;/span>,
&lt;span class="dt">legend.box =&lt;/span> &lt;span class="st">&amp;quot;vertical&amp;quot;&lt;/span>)
pl_data &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">filter&lt;/span>(ethn_group &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;Mand&amp;#39;&lt;/span>) &lt;span class="op">%&amp;gt;%&lt;/span>&lt;span class="st"> &lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">pl_pyramid&lt;/span>(&lt;span class="dt">title =&lt;/span> &lt;span class="st">&amp;#39;Mandarin&amp;#39;&lt;/span>) &lt;span class="op">+&lt;/span>&lt;span class="st"> &lt;/span>tweak
pl_data &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">filter&lt;/span>(ethn_group &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;Ind&amp;#39;&lt;/span>) &lt;span class="op">%&amp;gt;%&lt;/span>&lt;span class="st"> &lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">pl_pyramid&lt;/span>(&lt;span class="dt">title =&lt;/span> &lt;span class="st">&amp;#39;Formosan Languages&amp;#39;&lt;/span>) &lt;span class="op">+&lt;/span>&lt;span class="st"> &lt;/span>tweak&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://img.yongfu.name/assets/visualize-language-loss/unnamed-chunk-12-1.svg" width="49%" />&lt;img src="https://img.yongfu.name/assets/visualize-language-loss/unnamed-chunk-12-2.svg" width="49%" />&lt;/p>
&lt;p>Wait! It seems quite strange. The age-sex pyramid of ‘Formosan Languages’ doesn’t look like a pyramid at all!
This is because there were very few subjects defined as ‘indigenous people’ in the survey. To make plots like this (with only one or two age groups) comparable to others (such as that in ‘Mandarin’), we need one more function to &lt;strong>insert missing age groups&lt;/strong> to the data frame so that ggplot can draw empty bars for us.&lt;/p>
&lt;p>First, we need to find out &lt;strong>all age groups in the data&lt;/strong>:&lt;/p>
&lt;pre class="language-r">&lt;code class="language-r">age_groups &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">unique&lt;/span>(pl_data&lt;span class="op">$&lt;/span>age_group)
age_groups&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight"> [1] &amp;quot;[15,20)&amp;quot; &amp;quot;[20,25)&amp;quot; &amp;quot;[25,30)&amp;quot; &amp;quot;[30,35)&amp;quot; &amp;quot;[35,40)&amp;quot; &amp;quot;[40,45)&amp;quot; &amp;quot;[45,50)&amp;quot;
[8] &amp;quot;[50,55)&amp;quot; &amp;quot;[55,60)&amp;quot; &amp;quot;[60,65)&amp;quot; &amp;quot;[65,70)&amp;quot;&lt;/code>&lt;/pre>
&lt;p>Then we can write a function &lt;code>fill_empty_age_group()&lt;/code>, which takes a data frame as its first argument and checks whether there are age groups missing in the data frame (using its second argument, &lt;code>age_group_all&lt;/code>, as comparison). If the age group is missing, &lt;code>fill_empty_age_group()&lt;/code> appends a new row, which has &lt;code>age_group&lt;/code> set to the missing age group and &lt;code>avg_fluency&lt;/code> set to &lt;code>0&lt;/code> (create an empty bar), to the input data frame.&lt;/p>
&lt;pre class="language-r">&lt;code class="language-r">fill_empty_age_group &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="cf">function&lt;/span>(df, age_group_all) {
&lt;span class="cf">for&lt;/span> (i &lt;span class="cf">in&lt;/span> &lt;span class="kw">seq_along&lt;/span>(age_group_all)) {
&lt;span class="cf">if&lt;/span> (&lt;span class="op">!&lt;/span>(age_group_all[i] &lt;span class="op">%in%&lt;/span>&lt;span class="st"> &lt;/span>df&lt;span class="op">$&lt;/span>age_group)) {
df &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">rbind&lt;/span>(df, &lt;span class="kw">list&lt;/span>(&lt;span class="dt">gender =&lt;/span> &lt;span class="st">&amp;quot;Female&amp;quot;&lt;/span>,
&lt;span class="dt">ethn_group =&lt;/span> &lt;span class="st">&amp;quot;doesnt_matter&amp;quot;&lt;/span>,
&lt;span class="dt">age_group =&lt;/span> age_group_all[i],
&lt;span class="dt">avg_fluency =&lt;/span> &lt;span class="dv">0&lt;/span>))
}
}
&lt;span class="kw">return&lt;/span>(df)
}&lt;/code>&lt;/pre>
&lt;p>Now we’re ready to explore language loss in Taiwan. &lt;code>multiplot()&lt;/code> is used to put multiple plots together. The source code of &lt;code>multiplot()&lt;/code> is copied directly from Winston Chang’s &lt;a href="http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)">Cookbook for R&lt;/a>.&lt;/p>
&lt;pre class="language-r">&lt;code class="language-r">tweak2 &amp;lt;-&lt;span class="st"> &lt;/span>&lt;span class="kw">theme_bw&lt;/span>() &lt;span class="op">+&lt;/span>&lt;span class="st"> &lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">theme&lt;/span>(&lt;span class="dt">legend.justification =&lt;/span> &lt;span class="st">&amp;quot;right&amp;quot;&lt;/span>,
&lt;span class="dt">legend.position =&lt;/span> &lt;span class="st">&amp;quot;bottom&amp;quot;&lt;/span>,
&lt;span class="dt">legend.box =&lt;/span> &lt;span class="st">&amp;quot;vertical&amp;quot;&lt;/span>)
py1 &amp;lt;-&lt;span class="st"> &lt;/span>pl_data &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">filter&lt;/span>(ethn_group &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;Mand&amp;#39;&lt;/span>) &lt;span class="op">%&amp;gt;%&lt;/span>&lt;span class="st"> &lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">fill_empty_age_group&lt;/span>(age_groups) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">pl_pyramid&lt;/span>(&lt;span class="dt">title =&lt;/span> &lt;span class="st">&amp;#39;Mandarin&amp;#39;&lt;/span>) &lt;span class="op">+&lt;/span>&lt;span class="st"> &lt;/span>tweak2
py2 &amp;lt;-&lt;span class="st"> &lt;/span>pl_data &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">filter&lt;/span>(ethn_group &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;Tw&amp;#39;&lt;/span>) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">fill_empty_age_group&lt;/span>(age_groups) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">pl_pyramid&lt;/span>(&lt;span class="dt">title =&lt;/span> &lt;span class="st">&amp;#39;Taiwanese&amp;#39;&lt;/span>) &lt;span class="op">+&lt;/span>&lt;span class="st"> &lt;/span>tweak2
py3 &amp;lt;-&lt;span class="st"> &lt;/span>pl_data &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">filter&lt;/span>(ethn_group &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;Hak&amp;#39;&lt;/span>) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">fill_empty_age_group&lt;/span>(age_groups) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">pl_pyramid&lt;/span>(&lt;span class="dt">title =&lt;/span> &lt;span class="st">&amp;#39;Hakka&amp;#39;&lt;/span>) &lt;span class="op">+&lt;/span>&lt;span class="st"> &lt;/span>tweak2
py4 &amp;lt;-&lt;span class="st"> &lt;/span>pl_data &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">filter&lt;/span>(ethn_group &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;Ind&amp;#39;&lt;/span>) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">fill_empty_age_group&lt;/span>(age_groups) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">pl_pyramid&lt;/span>(&lt;span class="dt">title =&lt;/span> &lt;span class="st">&amp;#39;Formosan Languages&amp;#39;&lt;/span>) &lt;span class="op">+&lt;/span>&lt;span class="st"> &lt;/span>tweak2
py5 &amp;lt;-&lt;span class="st"> &lt;/span>pl_data &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">filter&lt;/span>(ethn_group &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;SEA&amp;#39;&lt;/span>) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">fill_empty_age_group&lt;/span>(age_groups) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">pl_pyramid&lt;/span>(&lt;span class="dt">title =&lt;/span> &lt;span class="st">&amp;#39;Languages of South East Asia&amp;#39;&lt;/span>) &lt;span class="op">+&lt;/span>&lt;span class="st"> &lt;/span>tweak2
py6 &amp;lt;-&lt;span class="st"> &lt;/span>pl_data &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">filter&lt;/span>(ethn_group &lt;span class="op">==&lt;/span>&lt;span class="st"> &amp;#39;Eng&amp;#39;&lt;/span>) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">fill_empty_age_group&lt;/span>(age_groups) &lt;span class="op">%&amp;gt;%&lt;/span>
&lt;span class="st"> &lt;/span>&lt;span class="kw">pl_pyramid&lt;/span>(&lt;span class="dt">title =&lt;/span> &lt;span class="st">&amp;#39;English&amp;#39;&lt;/span>) &lt;span class="op">+&lt;/span>&lt;span class="st"> &lt;/span>tweak2
&lt;span class="kw">multiplot&lt;/span>(py1, py2, py3, py4, py5, py6, &lt;span class="dt">cols =&lt;/span> &lt;span class="dv">2&lt;/span>)&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://img.yongfu.name/assets/visualize-language-loss/unnamed-chunk-16-1.svg" width="100%" />&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="language-loss-in-taiwan" class="section level2">
&lt;h2>Language Loss in Taiwan&lt;/h2>
&lt;p>As described in &lt;a href="#age-sex-pyramid-of-language">Age-Sex Pyramid of Language&lt;/a> above, we can learn about a language’s vitality in Taiwan from the age-sex pyramids drawn above.&lt;/p>
&lt;p>For Formosan and South East Asian languages, there are too few data, and we can’t learn much about these languages from the plots. For Mandarin, the shape of the pyramid is rectangular, indicating the linguistic competence of Mandarin is stable across people of all ages. This is expected as Mandarin, in Taiwan, is the most prevalent language, and most people use it as the primary language in workplace and home.&lt;/p>
&lt;p>Pyramids of Taiwanese and Hakka have inverted trianglular shapes, indicating lower linguistic competence among yonger people. Indeed, it’s not uncommmon to see the fathers and mothers talk to their children in Mandarin but talk to their parents in Taiwanese. Taiwanese is the second prevalent language in Taiwan, but it is shrinking, particularly among young people. Hakka ranks third in prevalence. It faces similar situation to Taiwanese but the situation is even worse, since the usage of Hakka is mostly restricted to Hakka people whereas usage of Taiwanese is not restricted to particular groups of people (many indigenous and Hakka peoples speak fluent Taiwanese).&lt;/p>
&lt;p>English has a special status in Taiwan. It is not a native tongue to people born and raised in Taiwan, but many people know at least a little English. This is because formal education and the (awareness of) globalization lead parents to place importance on English education of their children. This also gives the age-sex pyramid of English its appearance – a triangular shape with wider bottom than top. English is the only language that is growing in Taiwan and, arguably, the language with the strongest vitality. &lt;a href="#tab:tw-pyramids">Table 1&lt;/a> summarizes the discussion above.&lt;/p>
&lt;table>
&lt;caption>&lt;span id="tab:tw-pyramids">Table 1: &lt;/span> Situations of the four most prevalent languages in Taiwan.&lt;/caption>
&lt;thead>
&lt;tr class="header">
&lt;th>&lt;strong>Vitality of Language&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Shape of Pyramid&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Examples (Taiwan)&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td>Shrinking and Dying&lt;/td>
&lt;td>Inverted Triangle&lt;/td>
&lt;td>Taiwanese, Hakka&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td>Growing&lt;/td>
&lt;td>Triangle&lt;/td>
&lt;td>English&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td>Stable&lt;/td>
&lt;td>Rectangular Bar&lt;/td>
&lt;td>Mandarin&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/div>
&lt;div class="footnotes">
&lt;ol>
&lt;li id="fn1">&lt;p>The samples are not representative though, and it might only reflect the situation in Taipei (see the geographical distribution of the samples below). But I think there are still reasons to believe that other locations in Taiwan have similar phenomena.&lt;/p>
&lt;p>&lt;img src="https://twlangsurvey.github.io/out_graph/sample_spatial_distr.gif" title="fig:" alt="geo-distribution of samples" style="width: 43%;display:block; margin-left:auto;margin-right:auto" />&lt;a href="#fnref1" class="footnote-back">↩&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>Defined by scoring 3 or above in a self-reported 6-point scale measuring the fluency of a language spoken by the subject’s parents.&lt;a href="#fnref2" class="footnote-back">↩&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>For English, different from all other languages, the level used to determine ethnicity is &lt;code>0&lt;/code>, i.e. there is no filtering occuring, and all subjects are used. This is because, in Taiwan (and many other non-English speaking communities as well), English is not related to ethnicity and is strongly related to formal education and job requirements.&lt;a href="#fnref3" class="footnote-back">↩&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div>
&lt;p style="text-align:right;font-size:7px;margin-top:0px;margin-bottom:0px;padding-top:0px;padding-bottom:1px">
Last updated: 2019-04-03
&lt;/p></description><category>R</category><category>Travis-CI</category><category>Linguistics</category><category>R-bloggers</category></item><item><title>Easy Linguistics Document Writing with R Markdown</title><link>https://yongfu.name/2018/09/09/linguistics-down/</link><pubDate>Sun, 09 Sep 2018 00:00:00 +0000</pubDate><guid>https://yongfu.name/2018/09/09/linguistics-down/</guid><description>
&lt;p>I’ve written &lt;a href="https://liao961120.github.io/2018/09/06/ipa-symbols.html">a post&lt;/a> about rendering IPA symbols properly regardless of the output format of the R Markdown document. I implemented the ideas into an R package, &lt;strong>linguisticsdown&lt;/strong>. &lt;/p>
&lt;p>&lt;strong>linguisticsdown&lt;/strong> provides a Shiny interface to facilitate inserting IPA symbols in R Markdown. See a quick demo of the current feature of &lt;strong>linguisticsdown&lt;/strong> in the gif at the end of the post.&lt;/p>
&lt;p>A &lt;a href="https://liao961120.shinyapps.io/IPA-Easily-Written/">live demo&lt;/a> is hosted on shinyapps.io. For more details, visit &lt;a href="https://liao961120.github.io/linguisticsdown/">&lt;strong>linguisticsdown&lt;/strong>&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://liao961120.github.io/linguisticsdown/man/figs/features.gif" />&lt;/p>
&lt;p style="text-align:right;font-size:7px;margin-top:0px;margin-bottom:0px;padding-top:0px;padding-bottom:1px">
Last updated: 2019-03-07
&lt;/p></description><category>Linguistics</category><category>R Markdown</category><category>R</category><category>R-bloggers</category></item><item><title>Rendering IPA Symbols in R Markdown</title><link>https://yongfu.name/2018/09/06/ipa-symbols/</link><pubDate>Thu, 06 Sep 2018 00:00:00 +0000</pubDate><guid>https://yongfu.name/2018/09/06/ipa-symbols/</guid><description>
&lt;p>I was thinking about promoting reproducible research in Linguistics, or more precisely, how to attract people with no programming skills to have incentives to learn at least a bit programming, so that they have the ability to make their research more reproducible. &lt;/p>
&lt;p>I arrived at the solution: start by adopting R Markdown to write articles (see &lt;a href="#obstacles-to-adopting-a-reproducible-workflow">the last section&lt;/a> for details), but making R Markdown more friendly to novices in a particular field of academia is crucial to enhance their incentives to learn programming.&lt;/p>
&lt;div id="tasks-specific-to-linguistics" class="section level2">
&lt;h2>Tasks Specific to Linguistics&lt;/h2>
&lt;p>I came out with some common tasks related to document writing in Linguistics (I will thank you if you tell me other tasks I missed):&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>Typing IPA symbols.&lt;/li>
&lt;li>Drawing syntax trees.&lt;/li>
&lt;/ol>
&lt;p>To enhance R Markdown’s ability to do these tasks without compromising one of it’s great feature: render nicely to both HTML and PDF with the same source, one needs to consider the incompatiblity of LaTeX and HTML code.&lt;/p>
&lt;p>Solving the first problem (IPA symbol) is easy, draing syntax trees is hard and I haven’t have a solution yet&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>.&lt;/p>
&lt;/div>
&lt;div id="typing-ipa-symbols" class="section level2">
&lt;h2>Typing IPA Symbols&lt;/h2>
&lt;p>There are two problems to be solved in order to facilitate using IPA symbols in R Markdown:&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>Input method&lt;/li>
&lt;li>Font support (only related to PDF output)&lt;/li>
&lt;/ol>
&lt;p>The first one is essentially about mapping some combination of keys to unicode strings. This post demenstates how to solve the second, which is more fundamental.&lt;/p>
&lt;p>After doing a little research, I came out with a quick solution which stems from the combination of &lt;a href="http://www.languagebits.com/phonetics-english/ipa-symbols-in-r/">IPA Symbols in R&lt;/a>, &lt;a href="https://tex.stackexchange.com/questions/25249/how-do-i-use-a-particular-font-for-a-small-section-of-text-in-my-document">How do I use a particular font for a small section of text in my document?&lt;/a>, and &lt;a href="https://github.com/rstudio/bookdown/issues/168">Conditional compilation of book chunks to ensure compatibility with both HTML and XeLaTeX&lt;/a>.&lt;/p>
&lt;p>The solution is very simple: define a new font family that supports IPA symbols in LaTeX and use conditional compilation to render the document: when compiled to HTML, use raw unicode string; when compiled to PDF, wrap LaTeX code around IPA unicode strings.&lt;/p>
&lt;p>To define a new font family for IPA symbols, set &lt;code>header.tex&lt;/code> and include it by setting the yaml header of R Markdown document:&lt;/p>
&lt;pre class="yaml">&lt;code>output:
bookdown::pdf_document2:
includes:
in_header: header.tex&lt;/code>&lt;/pre>
&lt;p>Here’s &lt;code>header.tex&lt;/code>:&lt;/p>
&lt;pre class="latex">&lt;code>% Set font size
\usepackage[fontsize=12pt]{scrextend}
% Set font family
\usepackage{xeCJK}
\usepackage{fontspec}
\setmainfont{Calibri}
\setCJKmainfont[
BoldFont={HanWangHeiHeavy}
]{HanWangHeiLight}
% IPA font
\newfontfamily\ipa{Doulos SIL}
\DeclareTextFontCommand{\ipatext}{\ipa}&lt;/code>&lt;/pre>
&lt;p>The font, &lt;a href="https://software.sil.org/doulos/">Doulos SIL&lt;/a>, which supports IPA symbols can be freely dowloaded.&lt;/p>
&lt;p>The code chunk below is for conditional compilation:&lt;/p>
&lt;pre>&lt;code class="r">ipa &amp;lt;- c('e\u026A', 'a\u026A', '\u0254\u026A')
if (knitr::opts_knit$get('rmarkdown.pandoc.to') == &amp;quot;latex&amp;quot;) {
ipa &amp;lt;- paste0(&amp;quot;\\ipatext{&amp;quot;, ipa, &amp;quot;}&amp;quot;)
}&lt;/code>&lt;/pre>
&lt;p>The IPA symbols are set in the variable &lt;code>ipa&lt;/code> and can be access inline in R Markdown with, e.g., &lt;code>r ipa&lt;/code> or &lt;code>r ipa[3]&lt;/code>, which renders to &lt;strong>eɪ, aɪ, ɔɪ&lt;/strong> and &lt;strong>ɔɪ&lt;/strong>, respectively.&lt;/p>
&lt;p>The source of this post is in my &lt;a href="https://github.com/liao961120/blog/tree/master/post_source/ipa-symbols">GitHub repo&lt;/a>. You can reproduce it locally to see the differnce between HTML and PDF output of this post.&lt;/p>
&lt;/div>
&lt;div id="obstacles-to-adopting-a-reproducible-workflow" class="section level2">
&lt;h2>Obstacles to Adopting a Reproducible Workflow&lt;/h2>
&lt;p>&lt;em>Skip this section if you’re tired of stuff about reproducibility and R Markdown.&lt;/em>&lt;/p>
&lt;p>Reproducible research not only enhance scientific progress but also saves researchers a great deal of time, by automating repetitive and error-prone tasks in research. So if there are good reasons to adopt a reproducible workflow in research, saving time (in the long run) might be a good one.&lt;/p>
&lt;p>Programming skill is fundamental to automating repetitive tasks, which saves one’s time. However, learning programming to save time makes no sense to many people, since it is terrifying, hard, and time consumming&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a>. So the problem now becomes:&lt;/p>
&lt;blockquote>
&lt;p>How to reinforce the incentive to learn programming?&lt;/p>
&lt;/blockquote>
&lt;p>Again, by showing people how to save time, but this time, programming skill is not required.&lt;/p>
&lt;p>I think R Markdown is a very promising starting point, since writing is necessary for researcheres, and one can use RStudio without any knowledge of R. When becoming familiar with R Markdown, one begins to adopt a reproducible workflow and might notice the capability of R language, hence gaining more incentive to learn R.&lt;/p>
&lt;p>Many people in academia uses Microsoft Word to write articles and papers. However, R Markdown has several advantages over MS Word:&lt;/p>
&lt;ul>
&lt;li>Easy to inserting images and tables in documents.&lt;/li>
&lt;li>Values of variables (e.g. values in tables or &lt;em>p&lt;/em>-values) are automatically updated when raw data changes.&lt;/li>
&lt;li>Easy citation using citation keys (&lt;a href="https://www.zotero.org/">Zotero&lt;/a> + &lt;a href="https://github.com/retorquere/zotero-better-bibtex">Better BibTeX&lt;/a> greatly facilitates this).&lt;/li>
&lt;li>Mutiple output format, e.g. LaTeX, PDF, Web Page, Book, etc.&lt;/li>
&lt;li>&lt;a href="https://github.com/rstudio/rticles">Template support&lt;/a> for Journel articles, such as Elsevier, Sage, Springer, so no formatting is needed.&lt;/li>
&lt;/ul>
&lt;p>But I think all benefits about R Markdown mentioned above aren’t enough to persuade people into giving up MS Word, since people are conservative in adoping new things.&lt;/p>
&lt;p>If using R Markdown (or R) has benefits specific to the field related to the researcher, it greatly enhances the chance of adopting R Markdown. Hence, if I want to persuade people to use R Markdown, I can first build R packages that enhances the ability of R Markdown in that field.&lt;/p>
&lt;/div>
&lt;div class="footnotes">
&lt;ol>
&lt;li id="fn1">&lt;p>There are LaTeX packages supporting drawing syntax tree, but LaTeX package is not compatible with HTML output.&lt;a href="#fnref1" class="footnote-back">↩&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>I actually stared and gave up learning programming languages three times (C++, C, and then Python) before I successfully learned R.&lt;a href="#fnref2" class="footnote-back">↩&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div>
&lt;p style="text-align:right;font-size:7px;margin-top:0px;margin-bottom:0px;padding-top:0px;padding-bottom:1px">
Last updated: 2019-03-07
&lt;/p></description><category>Linguistics</category><category>R Markdown</category><category>R</category><category>R-bloggers</category></item><item><title>jieba 自訂詞庫斷詞</title><link>https://yongfu.name/2018/07/31/jieba-dict/</link><pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate><guid>https://yongfu.name/2018/07/31/jieba-dict/</guid><description>&lt;p>這邊將使用 &lt;a href="https://github.com/qinwf/jiebaR">jiebaR&lt;/a>，介紹使用自訂詞庫的斷詞方式，並提供自訂詞庫的製作方式。&lt;/p>
&lt;div class="section level2">
&lt;h2>示範語料&lt;/h2>
&lt;p>這裡使用金庸&lt;strong>&lt;a href="https://zh.wikipedia.org/wiki/%E7%A5%9E%E9%B5%B0%E4%BF%A0%E4%BE%B6">神雕俠侶&lt;/a>第三十二回 — 情是何物&lt;/strong>作為斷詞的文本。武俠小說在此是個很好的例子，因為裡面有許多人物名稱和專有名詞。&lt;/p>
&lt;p>因為著作權問題&lt;a href="#fn1" class="footnoteRef" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>，語料的原始檔(&lt;code>032.txt&lt;/code>)將不會出現在本文的 &lt;a href="https://github.com/liao961120/blog/tree/master/post_source/jieba-dict">GitHub repo&lt;/a> 中。&lt;/p>
&lt;/div>
&lt;div class="section level2">
&lt;h2>製作自訂詞庫&lt;/h2>
&lt;p>取得小說這類文本的角色名稱與特殊名詞乍看之下可能非常耗工耗時，但有些時候其實相當容易，尤其是著名的小說。這要歸功於&lt;a href="https://en.wikipedia.org/wiki/Main_Page">維基百科&lt;/a>，因為越是著名的小說，其越有可能有詳盡的維基百科頁面，而&lt;strong>維基百科對製作詞庫最重要的特色在於其頁面的超連結&lt;/strong>，因為通常只有&lt;strong>專有名詞才會成為一個維基頁面上的超連結&lt;/strong>。&lt;/p>
&lt;p>這邊使用維基百科的&lt;a href="https://zh.wikipedia.org/wiki/%E7%A5%9E%E9%B5%B0%E4%BF%A0%E4%BE%B6%E8%A7%92%E8%89%B2%E5%88%97%E8%A1%A8">神鵰俠侶角色列表&lt;/a>作為詞庫的來源。以下使用&lt;code>rvest&lt;/code>套件清理此頁面：&lt;/p>
&lt;pre>&lt;code class="r">library(rvest)
library(dplyr)
library(magrittr)
library(knitr)
path &amp;lt;- &amp;quot;神鵰俠侶角色列表.html&amp;quot;
# 這裡已先行下載網頁，若無可直接使用網址
data &amp;lt;- read_html(path) %&amp;gt;%
html_nodes(&amp;quot;ul&amp;quot;) %&amp;gt;% html_nodes(&amp;quot;li&amp;quot;) %&amp;gt;%
html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;% html_text()&lt;/code>&lt;/pre>
&lt;p>觀察頁面後，可發現多數與小說相關的詞彙都位在 unordered list 下的連結內文(&amp;lt;a&amp;gt; tag)，因此透過 3 個&lt;code>html_nodes()&lt;/code>取得連結，並用&lt;code>html_text()&lt;/code>擷取連結內文。&lt;/p>
&lt;p>接著看看擷取的詞彙，可以發現這些詞彙依照順序大致可區分成三個來源：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>自維基頁面的&lt;strong>目錄&lt;/strong>擷取之連結&lt;/li>
&lt;li>內文的連結(這是我們要的)&lt;/li>
&lt;li>其它連結
&lt;ul>
&lt;li>對應至頁面最下方，與小說有關但並非小說主要內容的連結，如，「射雕英雄传角色列表」。另外，也包含維基百科頁面的固定連結，如「編輯」、「討論」、「下載為PDF」等。&lt;/li>
&lt;/ul>&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="r">data &amp;lt;- unique(data)
data[1:3]&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;1 主角&amp;quot; &amp;quot;2 桃花島&amp;quot; &amp;quot;2.1 「北丐」門派&amp;quot;&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="r">data[21:25]&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;楊過&amp;quot; &amp;quot;射鵰英雄傳&amp;quot; &amp;quot;楊康&amp;quot; &amp;quot;穆念慈&amp;quot; &amp;quot;全真教&amp;quot; &lt;/code>&lt;/pre>
&lt;pre>&lt;code class="r">data[207:211]&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;射雕英雄传角色列表&amp;quot; &amp;quot;倚天屠龙记角色列表&amp;quot; &amp;quot;查&amp;quot;
[4] &amp;quot;论&amp;quot; &amp;quot;编&amp;quot; &lt;/code>&lt;/pre>
&lt;p>我們要的內容介在&lt;code>data[21]&lt;/code>(楊過)至&lt;code>data[206]&lt;/code>(樊一翁)之間。此外，亦可手動加入連結中沒有的詞彙：&lt;/p>
&lt;pre>&lt;code class="r">data &amp;lt;- as_data_frame(data[21:206]) %&amp;gt;%
rbind(&amp;quot;過兒&amp;quot;, &amp;quot;靖哥哥&amp;quot;) # 手動額外輸入
head(data, 4) %&amp;gt;% kable(&amp;quot;markdown&amp;quot;, align=&amp;quot;c&amp;quot;)&lt;/code>&lt;/pre>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th align="center">value&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="center">楊過&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">射鵰英雄傳&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="center">楊康&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">穆念慈&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>最後，將&lt;code>data&lt;/code>存成&lt;code>.csv&lt;/code>檔，方便未來使用：&lt;/p>
&lt;pre>&lt;code class="r">readr::write_csv(data, &amp;quot;sdxl_wordlist.csv&amp;quot;)&lt;/code>&lt;/pre>
&lt;/div>
&lt;div id="jiebar-" class="section level2">
&lt;h2>jiebaR 斷詞&lt;/h2>
&lt;p>準備好自訂詞庫後，要開始對文本進行斷詞。&lt;/p>
&lt;p>jiebaR 斷詞可以選擇外來檔案或將檔案讀入後在進行斷詞，這邊將文本檔案讀入再斷詞：&lt;/p>
&lt;pre>&lt;code class="r">library(stringr)
raw_text &amp;lt;- readr::read_file(&amp;quot;032.txt&amp;quot;)
raw_text %&amp;gt;% str_trunc(80)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;第三十二回　情是何物\r\n\r\n　　當黃蓉、一燈、郭芙等被困大廳之時，楊過和小龍女正在花前並肩共語。不久程英和陸無雙到來。小龍女見程英溫雅靦腆，甚是投緣，拉住...&amp;quot;&lt;/code>&lt;/pre>
&lt;div class="section level3">
&lt;h3>無自訂詞庫&lt;/h3>
&lt;p>首先，我們可以看看沒有自訂詞庫的斷詞效果：&lt;/p>
&lt;pre>&lt;code class="r">library(jiebaR)
stop_words &amp;lt;- readr::read_table2(&amp;quot;stop-zh-tw-withpunc&amp;quot;,
col_names = F) %&amp;gt;%
rbind(&amp;quot;\n&amp;quot;, &amp;quot;\r&amp;quot;) %&amp;gt;%
set_names(&amp;quot;word&amp;quot;)
seg &amp;lt;- worker(bylines = F, symbol = T)
segment(raw_text, seg) %&amp;gt;%
as_data_frame() %&amp;gt;%
anti_join(stop_words, by=c(&amp;quot;value&amp;quot;=&amp;quot;word&amp;quot;)) %&amp;gt;%
count(value) %&amp;gt;%
arrange(desc(n)) %&amp;gt;%
head() %&amp;gt;% kable(&amp;quot;markdown&amp;quot;, align=&amp;quot;c&amp;quot;)&lt;/code>&lt;/pre>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th align="center">value&lt;/th>
&lt;th align="center">n&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="center">道&lt;/td>
&lt;td align="center">156&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">小龍女&lt;/td>
&lt;td align="center">115&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="center">楊&lt;/td>
&lt;td align="center">91&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">公孫止&lt;/td>
&lt;td align="center">86&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="center">楊過&lt;/td>
&lt;td align="center">76&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">黃&lt;/td>
&lt;td align="center">65&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>可以看到有些斷詞是正確的，如「公孫止」。但某些似乎常常斷錯，例如，「黃蓉」、「楊過」(某些似乎斷錯，導致有許多單獨的「楊」)。&lt;/p>
&lt;/div>
&lt;div class="section level3">
&lt;h3>使用自訂詞庫&lt;/h3>
&lt;p>在&lt;code>jiebaR::worker()&lt;/code>中設定自訂詞庫的位置：&lt;code>user = &amp;quot;sdxl_wordlist.csv&amp;quot;&lt;/code>，即可在斷詞系統中新增字典：&lt;/p>
&lt;pre>&lt;code class="r">seg &amp;lt;- worker(bylines = F, symbol = T,
user = &amp;quot;sdxl_wordlist.csv&amp;quot;)
segment(raw_text, seg) %&amp;gt;%
as_data_frame() %&amp;gt;%
anti_join(stop_words, by=c(&amp;quot;value&amp;quot;=&amp;quot;word&amp;quot;)) %&amp;gt;%
count(value) %&amp;gt;%
arrange(desc(n)) %&amp;gt;%
head() %&amp;gt;% kable(&amp;quot;markdown&amp;quot;, align=&amp;quot;c&amp;quot;)&lt;/code>&lt;/pre>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th align="center">value&lt;/th>
&lt;th align="center">n&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="center">楊過&lt;/td>
&lt;td align="center">187&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">道&lt;/td>
&lt;td align="center">150&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="center">小龍女&lt;/td>
&lt;td align="center">119&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">公孫止&lt;/td>
&lt;td align="center">104&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="center">黃蓉&lt;/td>
&lt;td align="center">95&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">李莫愁&lt;/td>
&lt;td align="center">59&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>可以看到使用自訂詞庫後，斷詞變得有意義多了。&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="footnotes">
&lt;ol>
&lt;li id="fn1">&lt;p>本文目的僅在促進教育與學術，並無營利企圖。且本文僅顯示極少的小說內容，應屬合理使用。若有侵犯著作權的疑慮，麻煩透過 &lt;a href="mailto:liaomovie2@gmail.com">Email&lt;/a> 與我聯絡。&lt;a href="#fnref1">↩&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div>
&lt;p style="text-align:right;font-size:7px;margin-top:0px;margin-bottom:0px;padding-top:0px;padding-bottom:1px">
Last updated: 2018-11-10
&lt;/p></description><category>R</category><category>linguistics</category><category>中文</category></item><item><title>Text Mining 前處理</title><link>https://yongfu.name/2018/07/28/quanteda-tutorial/</link><pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate><guid>https://yongfu.name/2018/07/28/quanteda-tutorial/</guid><description>&lt;div class="section level2">
&lt;h2>流程&lt;/h2>
&lt;img src="https://img.yongfu.name/blog/mermaid2.svg" alt="" style="width:100%">
&lt;div class="mermaid">
graph LR
html("HTML")
html -.->|"rvest"| df0
subgraph 前處理
df1("斷詞 data_frame")
df0("data_frame")
df0 -.->|"&lt;br> jiebaR &lt;br> (保留標點)&lt;br>"| df1
df1 -.->|"ropencc &lt;br> 簡轉繁"| df1
end
corp("Corpus")
token("Tokens")
subgraph quanteda
df1 -.->|"quanteda &lt;br> corpus()"| corp
corp -.->|"quanteda &lt;br> tokenize()"| token
end
html -.- bls(" ")
style bls fill:none,stroke:none
style html fill:#ccbdb9
style df1 fill:#92ff7f
linkStyle 5 stroke-width:0px,fill:none;
&lt;/div>
&lt;/div>
&lt;div class="section level2">
&lt;h2>資料爬取&lt;/h2>
&lt;p>這邊使用 &lt;a href="https://www.rstudio.com/">RStudio&lt;/a> 軟體工程師 &lt;a href="https://yihui.name/en/about/">Yihui&lt;/a> 的&lt;a href="https://yihui.name/cn/">中文部落格&lt;/a>文章作為練習素材。首先需要取得文章的網址，因此先到部落格的文章列表頁面(&lt;a href="https://yihui.name/cn/" class="uri">https://yihui.name/cn/&lt;/a>)，使用瀏覽器的&lt;a href="https://developers.google.com/web/tools/chrome-devtools/?hl=zh-tw">開發者工具&lt;/a>(按&lt;code>Ctrl + Shift + I&lt;/code>開啟)進行&lt;strong>觀察&lt;/strong>。&lt;/p>
&lt;p>接著使用&lt;a href="https://github.com/hadley/rvest">&lt;code>rvest&lt;/code>&lt;/a>套件擷取網頁中所有文章的連結，並將文章網址儲存成&lt;code>list_of_post.txt&lt;/code>：&lt;/p>
&lt;pre>&lt;code class="r">library(dplyr)
library(rvest)
list_of_posts &amp;lt;- read_html(&amp;quot;https://yihui.name/cn/&amp;quot;) %&amp;gt;%
html_nodes(&amp;quot;.archive&amp;quot;) %&amp;gt;% # 列表在 div.archive 之下
html_nodes(&amp;quot;p&amp;quot;) %&amp;gt;% # 文章標題在 &amp;lt;div&amp;gt; 下之 &amp;lt;p&amp;gt;
html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;% html_attr(&amp;quot;href&amp;quot;) # 文章連結在 &amp;lt;p&amp;gt; 下之 &amp;lt;a&amp;gt;
readr::write_lines(list_of_posts, &amp;quot;yihui/list_of_post.txt&amp;quot;)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="r">head(list_of_posts, 2)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;/cn/2018/10/middle-school-teachers/&amp;quot;
[2] &amp;quot;/cn/2018/10/potato-pancake/&amp;quot; &lt;/code>&lt;/pre>
&lt;pre>&lt;code class="r">tail(list_of_posts, 2)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;/cn/2005/01/rtx/&amp;quot; &amp;quot;/cn/2005/01/20-13-00/&amp;quot;&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="r">length(list_of_posts)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] 1097&lt;/code>&lt;/pre>
&lt;p>可以看到總共有 1097 篇文章，時間從 2005 年到今年七月都有發文的紀錄。&lt;/p>
&lt;p>由於文章數量相當多，因此之後僅會下載部分文章，&lt;strong>避免造成伺服器負擔過大&lt;/strong>。下載網頁時，可以在 R 中直接使用&lt;code>rvest&lt;/code>(見下文&lt;strong>資料前處理&lt;/strong>)，但我比較建議使用 Bash&lt;a href="#fn1" class="footnoteRef" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>的&lt;code>wget&lt;/code>指令，才不會因為重複下載網頁造成伺服器負擔。&lt;/p>
&lt;p>在下載前，需先決定目標文章的網址&lt;code>sub_list&lt;/code>：&lt;/p>
&lt;pre>&lt;code class="r">library(stringr)
set.seed(2018) # 設隨機種子 固定隨機函數的結果
idx &amp;lt;- str_detect(list_of_posts, &amp;quot;2018|2015|2010&amp;quot;)
sub_list &amp;lt;- list_of_posts[idx]
sub_list &amp;lt;- sub_list[sample(seq_along(sub_list), 20)] %&amp;gt;% # 抽出 20 篇
str_replace_all(pattern = &amp;quot;^/&amp;quot;, # 將站內連結改為完整 url
replacement = &amp;quot;https://yihui.name/&amp;quot;) %&amp;gt;%
str_replace_all(pattern = &amp;quot;/$&amp;quot;, &amp;quot;/index.html&amp;quot;)
readr::write_lines(sub_list, &amp;quot;yihui/sublist.txt&amp;quot;)
# 給 Bash 用的
sub_list %&amp;gt;%
str_replace_all(&amp;quot;https://yihui.name/cn/&amp;quot;, &amp;quot;&amp;quot;) %&amp;gt;%
str_replace_all(&amp;quot;/index.html&amp;quot;, &amp;quot;&amp;quot;) %&amp;gt;%
str_replace_all(&amp;quot;/&amp;quot;, &amp;quot;-&amp;quot;) %&amp;gt;%
str_replace_all(&amp;quot;-$&amp;quot;, &amp;quot;&amp;quot;) %&amp;gt;%
readr::write_lines(&amp;quot;yihui/sublist_name.txt&amp;quot;)&lt;/code>&lt;/pre>
&lt;div id="bash-" class="section level3">
&lt;h3>Bash 指令下載網頁&lt;/h3>
&lt;blockquote>
&lt;p>無法使用 bash 指令者，可跳過此節&lt;/p>
&lt;/blockquote>
&lt;p>為了自動化下載網頁，我寫了一個簡單的 Bash script &lt;code>wget_list&lt;/code>，用法如下:&lt;/p>
&lt;ul>
&lt;li>&lt;code>wget_list &amp;lt;網址文字檔&amp;gt; &amp;lt;檔名文字檔&amp;gt;&lt;/code>&lt;a href="#fn2" class="footnoteRef" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a>
&lt;ul>
&lt;li>&lt;code>&amp;lt;網址文字檔&amp;gt;&lt;/code>： 每一列(row)由一個網址組成&lt;/li>
&lt;li>&lt;code>&amp;lt;檔名文字檔&amp;gt;&lt;/code>： 每一列由一個名稱組成，每個名稱與&lt;code>&amp;lt;網址文字檔&amp;gt;&lt;/code>的網址對應&lt;/li>
&lt;/ul>&lt;/li>
&lt;/ul>
&lt;!--FOOTNOTE START-->
&lt;p>在這裡，執行下列指令即可下載網頁&lt;/p>
&lt;pre>&lt;code class="bash">cd yihui/html
wget_list ../sublist.txt ../sublist_name.txt
cd -&lt;/code>&lt;/pre>
&lt;p>&lt;strong>&lt;code>wget_list&lt;/code>&lt;/strong>:&lt;/p>
&lt;pre>&lt;code class="bash">#!/bin/bash
#&amp;lt;&amp;lt;&amp;lt; wget_list: dowload webpages listed in a file &amp;gt;&amp;gt;&amp;gt;#
### Argument 1 is the file of links, 1 url per row ###
### Argument 2 is the file of names, 1 name per row ###
file1=$1
file2=$2
## Get the number of lines in the link list
num_lines=$(wc -l $file1 | egrep -o '^[0-9]*')
## loop over the lines in file1, dowload the the file &amp;amp; name them as listed in file2
for (( i=1; i&amp;lt;=${num_lines}; ++i )); do
wget &amp;quot;$(sed -n ${i}p $file1)&amp;quot; \
-O &amp;quot;$(sed -n ${i}p $file2)&amp;quot;
done&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="section level2">
&lt;h2>資料前處理&lt;/h2>
&lt;p>在清理資料之前，需先剖析網頁結構(就如同之前剖析文章列表頁面一樣)。 這邊觀察&lt;a href="https://yihui.name/cn/2015/11/peer-review/">這篇文章&lt;/a>，大致可以找出這些資訊：&lt;/p>
&lt;pre>&lt;code class="r">path &amp;lt;- &amp;quot;https://yihui.name/cn/2015/11/peer-review/&amp;quot;
all &amp;lt;- read_html(path) %&amp;gt;%
html_nodes(&amp;quot;article&amp;quot;)
header &amp;lt;- all %&amp;gt;% html_nodes(&amp;quot;header&amp;quot;)
title &amp;lt;- header %&amp;gt;% # 文章標題
html_nodes(&amp;quot;h1&amp;quot;) %&amp;gt;% html_text()
post_date &amp;lt;- header %&amp;gt;% # 發文日期
html_node(&amp;quot;h3&amp;quot;) %&amp;gt;% html_text() %&amp;gt;%
str_extract(&amp;quot;201[0-9]-[0-9]{2}-[0-9]{2}&amp;quot;)
article &amp;lt;- all %&amp;gt;% # 內文
html_nodes(&amp;quot;p&amp;quot;) %&amp;gt;%
html_text() %&amp;gt;% paste(collapse = &amp;quot;\n&amp;quot;)
# 這裡將 chr vector collapse 至 1 個字串，
# 簡化資料結構，並以分行符號保留段落資訊
num_sec &amp;lt;- all %&amp;gt;% # 內文段落數
html_nodes(&amp;quot;p&amp;quot;) %&amp;gt;% length
links &amp;lt;- all %&amp;gt;% html_nodes(&amp;quot;p&amp;quot;) %&amp;gt;% # 內文連結
html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;% html_attr(&amp;quot;href&amp;quot;)
link_text &amp;lt;- all %&amp;gt;% html_nodes(&amp;quot;p&amp;quot;) %&amp;gt;% # 內文連結標題
html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;% html_text()&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="r">library(tibble)
df &amp;lt;- data_frame(title = title,
date = post_date,
content = article,
num_sec = num_sec,
links = list(links),
link_text = list(link_text)
)
df %&amp;gt;%
mutate(title = str_trunc(title, 8),
content = str_trunc(content, 8),
links = str_trunc(links, 8),
link_text = str_trunc(link_text, 8)) %&amp;gt;%
kable(&amp;quot;markdown&amp;quot;, align = &amp;quot;c&amp;quot;)&lt;/code>&lt;/pre>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th align="center">title&lt;/th>
&lt;th align="center">date&lt;/th>
&lt;th align="center">content&lt;/th>
&lt;th align="center">num_sec&lt;/th>
&lt;th align="center">links&lt;/th>
&lt;th align="center">link_text&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="center">同行评审&lt;/td>
&lt;td align="center">2015-11-11&lt;/td>
&lt;td align="center">看到这么一…&lt;/td>
&lt;td align="center">8&lt;/td>
&lt;td align="center">c(“ht…&lt;/td>
&lt;td align="center">c(“一则…&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>我們可以將上面的程式碼改寫成函數&lt;code>post_data()&lt;/code>，自動讀取文章並輸出 data frame：&lt;/p>
&lt;pre>&lt;code class="r">post_data &amp;lt;- function (path) {
all &amp;lt;- read_html(path) %&amp;gt;%
html_nodes(&amp;quot;article&amp;quot;)
header &amp;lt;- all %&amp;gt;% html_nodes(&amp;quot;header&amp;quot;)
title &amp;lt;- header %&amp;gt;% # 文章標題
html_nodes(&amp;quot;h1&amp;quot;) %&amp;gt;% html_text()
post_date &amp;lt;- header %&amp;gt;% # 發文日期
html_node(&amp;quot;h3&amp;quot;) %&amp;gt;% html_text() %&amp;gt;%
str_extract(&amp;quot;201[0-9]-[0-9]{2}-[0-9]{2}&amp;quot;)
article &amp;lt;- all %&amp;gt;% # 內文
html_nodes(&amp;quot;p&amp;quot;) %&amp;gt;%
html_text() %&amp;gt;% paste(collapse = &amp;quot;\n&amp;quot;)
# 這裡將 chr vector collapse 至 1 個字串，
# 簡化資料結構，並以分行符號保留段落資訊
num_sec &amp;lt;- all %&amp;gt;% # 內文段落數
html_nodes(&amp;quot;p&amp;quot;) %&amp;gt;% length
links &amp;lt;- all %&amp;gt;% html_nodes(&amp;quot;p&amp;quot;) %&amp;gt;% # 內文連結
html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;% html_attr(&amp;quot;href&amp;quot;)
link_text &amp;lt;- all %&amp;gt;% # 內文連結標題
html_nodes(&amp;quot;p&amp;quot;) %&amp;gt;%
html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;% html_text()
df &amp;lt;- tibble::data_frame(title = title,
date = post_date,
content = article,
num_sec = num_sec,
links = list(links),
link_text = list(link_text)
)
}&lt;/code>&lt;/pre>
&lt;p>接著，將所有文章讀取至一個 data frame &lt;code>all_post&lt;/code>：&lt;/p>
&lt;pre>&lt;code class="r">library(dplyr)
library(tidyr)
html_list &amp;lt;- list.files(&amp;quot;yihui/html/&amp;quot;) # 列出資料夾下的檔案
all_post &amp;lt;- vector(&amp;quot;list&amp;quot;, length(html_list))
for (i in seq_along(html_list)) {
path &amp;lt;- paste0(&amp;quot;yihui/html/&amp;quot;, html_list[i])
all_post[[i]] &amp;lt;- post_data(path)
}
all_post &amp;lt;- bind_rows(all_post) %&amp;gt;% arrange(desc(date))
head(all_post) %&amp;gt;%
mutate(title = str_trunc(title, 8),
content = str_trunc(content, 8),
links = str_trunc(links, 8),
link_text = str_trunc(link_text, 8)) %&amp;gt;%
kable(&amp;quot;markdown&amp;quot;, align = &amp;quot;c&amp;quot;)&lt;/code>&lt;/pre>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th align="center">title&lt;/th>
&lt;th align="center">date&lt;/th>
&lt;th align="center">content&lt;/th>
&lt;th align="center">num_sec&lt;/th>
&lt;th align="center">links&lt;/th>
&lt;th align="center">link_text&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="center">修辞还是真实&lt;/td>
&lt;td align="center">2018-06-21&lt;/td>
&lt;td align="center">说两封让我…&lt;/td>
&lt;td align="center">12&lt;/td>
&lt;td align="center">chara…&lt;/td>
&lt;td align="center">chara…&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">花椒香料&lt;/td>
&lt;td align="center">2018-05-31&lt;/td>
&lt;td align="center">古人似乎喜…&lt;/td>
&lt;td align="center">2&lt;/td>
&lt;td align="center">/cn/2…&lt;/td>
&lt;td align="center">去年的花椒&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="center">CSS 的…&lt;/td>
&lt;td align="center">2018-05-14&lt;/td>
&lt;td align="center">CSS 中…&lt;/td>
&lt;td align="center">15&lt;/td>
&lt;td align="center">c(“ht…&lt;/td>
&lt;td align="center">c(“查阅…&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">毛姆的文学回忆录&lt;/td>
&lt;td align="center">2018-05-04&lt;/td>
&lt;td align="center">前段时间看…&lt;/td>
&lt;td align="center">14&lt;/td>
&lt;td align="center">c(“/c…&lt;/td>
&lt;td align="center">c(“职业…&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="center">距离的组织&lt;/td>
&lt;td align="center">2018-05-03&lt;/td>
&lt;td align="center">前面《闲情…&lt;/td>
&lt;td align="center">5&lt;/td>
&lt;td align="center">/cn/2…&lt;/td>
&lt;td align="center">闲情赋&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">语言圣战的终结？&lt;/td>
&lt;td align="center">2018-04-19&lt;/td>
&lt;td align="center">一直以来我…&lt;/td>
&lt;td align="center">3&lt;/td>
&lt;td align="center">c(“ht…&lt;/td>
&lt;td align="center">c(“惊天…&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;div class="section level3">
&lt;h3>直接從網路讀取&lt;/h3>
&lt;p>如果無法使用 Bash 指令下載網頁，可將上面程式碼的&lt;code>html_list&lt;/code>改為讀取&lt;code>sublist.txt&lt;/code>中的 url，並修改&lt;code>for&lt;/code>迴圈中的&lt;code>path&lt;/code>：&lt;/p>
&lt;pre>&lt;code class="r">html_list &amp;lt;- read_lines(&amp;quot;yihui/sublist.txt&amp;quot;) # 讀取 url
all_post &amp;lt;- vector(&amp;quot;list&amp;quot;, length(html_list))
for (i in seq_along(html_list)) {
path &amp;lt;- html_list[i]
all_post[[i]] &amp;lt;- post_data(path)
}
all_post &amp;lt;- bind_rows(all_post) %&amp;gt;% arrange(desc(date))&lt;/code>&lt;/pre>
&lt;/div>
&lt;div class="section level3">
&lt;h3>斷詞&lt;/h3>
&lt;p>在處理中文、日語等文本資料，需先經過斷詞處理，因為其不像英語等歐洲語言的文本，以空格表示字詞的界線。&lt;/p>
&lt;p>我們將使用&lt;code>jiebaR&lt;/code>套件的&lt;code>segment()&lt;/code>進行斷詞。由&lt;code>?segment()&lt;/code>查看其 documentation 可知&lt;strong>&lt;code>segment()&lt;/code>只吃文字檔或 一個句子&lt;/strong>，因此需先搞清楚&lt;code>all_post&lt;/code>的結構才能進行斷詞：&lt;/p>
&lt;p>&lt;code>all_post&lt;/code>: 20*5 的&lt;code>data_frame&lt;/code>，每列(row)為一篇文章 - $title: 每列為 1 個值 - $date: 每列為 1 個值 - $content: 每列為 1 個值，段落資訊藏在字串中的&lt;code>\n&lt;/code>符號 - $links: 每列為 1 個 list - $link_text: 每列為 1 個 list&lt;/p>
&lt;p>&lt;code>all_post$content&lt;/code>的結構相當簡單(一篇文章一個字串)，因此不須經過額外處理。其它變項不須斷詞處理，因此在此不加細談。&lt;/p>
&lt;div id="jiebarsegment" class="section level4">
&lt;h4>jiebaR::segment&lt;/h4>
&lt;p>因為&lt;code>all_post$content&lt;/code>簡單的結構符合&lt;code>jiebaR&lt;/code>套件的預設需求，但有時資料會比較複雜，因此記錄下來供未來參考。&lt;/p>
&lt;p>前面提到&lt;code>jiebaR::segment&lt;/code>只吃一個句子(一個字串)或文字檔，那如果丟一個 vector 給它會怎樣？答案是看&lt;code>worker()&lt;/code>的設定：&lt;/p>
&lt;pre>&lt;code class="r">library(jiebaR)
seg &amp;lt;- worker(symbol = T, bylines = F)
segment(c(&amp;quot;妳很漂亮&amp;quot;, &amp;quot;我不喜歡你&amp;quot;), seg)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;妳&amp;quot; &amp;quot;很漂亮&amp;quot; &amp;quot; &amp;quot; &amp;quot;我&amp;quot; &amp;quot;不&amp;quot; &amp;quot;喜歡&amp;quot; &amp;quot;你&amp;quot; &lt;/code>&lt;/pre>
&lt;pre>&lt;code class="r">seg &amp;lt;- worker(symbol = T, bylines = T)
segment(c(&amp;quot;妳很漂亮&amp;quot;, &amp;quot;我不喜歡你&amp;quot;), seg)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[[1]]
[1] &amp;quot;妳&amp;quot; &amp;quot;很漂亮&amp;quot;
[[2]]
[1] &amp;quot;我&amp;quot; &amp;quot;不&amp;quot; &amp;quot;喜歡&amp;quot; &amp;quot;你&amp;quot; &lt;/code>&lt;/pre>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;p>&lt;code>bylines = F&lt;/code>：回傳 1 個 chr vector，其每個元素為 1 個詞。&lt;/p>&lt;/li>
&lt;li>&lt;p>&lt;code>bylines = T&lt;/code>：回傳 1 個 list，其長度(元素的數量)等於輸入之 vector 的長度，每個元素為一個 chr vector。&lt;/p>&lt;/li>
&lt;/ol>
&lt;p>&lt;code>bylines = F&lt;/code>的設定在此符合我們的需求，並且為配合&lt;code>quanteda&lt;/code>套件的特性而將斷詞結果以一個字串(以空格分開字詞)而非一個 chr vector 的形式儲存。 以下&lt;strong>對第一篇文章進行斷詞&lt;/strong>：&lt;/p>
&lt;pre>&lt;code class="r">library(jiebaR)
all_post_seg &amp;lt;- all_post
seg &amp;lt;- worker(symbol = T, bylines = F)
all_post_seg$content[1] &amp;lt;- all_post$content[1] %&amp;gt;%
segment(seg) %&amp;gt;% paste(collapse = &amp;quot; &amp;quot;)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="r">all_post$content[1] %&amp;gt;% str_trunc(20)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;说两封让我感到“我天，给亲友的书信...&amp;quot;&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="r">all_post_seg$content[1] %&amp;gt;% str_trunc(30)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;说 两封 让 我 感到 “ 我 天 ， 给 亲友 的 ...&amp;quot;&lt;/code>&lt;/pre>
&lt;p>要處理所有文章，僅需外包一個 for loop：&lt;/p>
&lt;pre>&lt;code class="r">all_post_seg &amp;lt;- all_post
seg &amp;lt;- worker(symbol = T, bylines = F)
idx &amp;lt;- seq_along(all_post$content)
for (i in idx){
all_post_seg$content[i] &amp;lt;- all_post$content[i] %&amp;gt;%
segment(seg) %&amp;gt;% paste(collapse = &amp;quot; &amp;quot;)
}
head(all_post$content, 3) %&amp;gt;% str_trunc(20)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;说两封让我感到“我天，给亲友的书信...&amp;quot;
[2] &amp;quot;古人似乎喜欢把花椒当香料用。在《古...&amp;quot;
[3] &amp;quot;CSS 中的位置（position...&amp;quot; &lt;/code>&lt;/pre>
&lt;pre>&lt;code class="r">head(all_post_seg$content, 3) %&amp;gt;% str_trunc(30)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;说 两封 让 我 感到 “ 我 天 ， 给 亲友 的 ...&amp;quot;
[2] &amp;quot;古人 似乎 喜欢 把 花椒 当 香料 用 。 在 《 ...&amp;quot;
[3] &amp;quot;CSS 中 的 位置 （ position ） 属...&amp;quot; &lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="section level3">
&lt;h3>簡轉繁&lt;/h3>
&lt;p>&lt;a href="https://github.com/BYVoid/OpenCC">OpenCC&lt;/a> 是一個簡體字與繁體字轉換的專案，非常優秀，因為其不僅是單純字轉字，甚至處理了地區性的用法(如「軟體」vs.「软件」)。因此，其簡繁轉換的選項有非常多：&lt;/p>
&lt;ul>
&lt;li>&lt;code>s2t.json&lt;/code> Simplified Chinese to Traditional Chinese 簡體到繁體&lt;/li>
&lt;li>&lt;code>t2s.json&lt;/code> Traditional Chinese to Simplified Chinese 繁體到簡體&lt;/li>
&lt;li>&lt;code>s2tw.json&lt;/code> Simplified Chinese to Traditional Chinese (Taiwan Standard) 簡體到臺灣正體&lt;/li>
&lt;li>&lt;code>tw2s.json&lt;/code> Traditional Chinese (Taiwan Standard) to Simplified Chinese 臺灣正體到簡體&lt;/li>
&lt;li>&lt;code>s2hk.json&lt;/code> Simplified Chinese to Traditional Chinese (Hong Kong Standard) 簡體到香港繁體（香港小學學習字詞表標準）&lt;/li>
&lt;li>&lt;code>hk2s.json&lt;/code> Traditional Chinese (Hong Kong Standard) to Simplified Chinese 香港繁體（香港小學學習字詞表標準）到簡體&lt;/li>
&lt;li>&lt;code>s2twp.json&lt;/code> Simplified Chinese to Traditional Chinese (Taiwan Standard) with Taiwanese idiom 簡體到繁體（臺灣正體標準）並轉換爲臺灣常用詞彙&lt;/li>
&lt;li>&lt;code>tw2sp.json&lt;/code> Traditional Chinese (Taiwan Standard) to Simplified Chinese with Mainland Chinese idiom 繁體（臺灣正體標準）到簡體並轉換爲中國大陸常用詞彙&lt;/li>
&lt;li>&lt;code>t2tw.json&lt;/code> Traditional Chinese (OpenCC Standard) to Taiwan Standard 繁體（OpenCC 標準）到臺灣正體&lt;/li>
&lt;li>&lt;code>t2hk.json&lt;/code> Traditional Chinese (OpenCC Standard) to Hong Kong Standard 繁體（OpenCC 標準）到香港繁體（香港小學學習字詞表標準）&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://github.com/qinwf/ropencc">&lt;code>ropencc&lt;/code>&lt;/a>套件是 OpenCC 的 R 語言接口，其不在 CRAN 上，需以&lt;code>devtools&lt;/code>從 GitHub 下載：&lt;/p>
&lt;pre>&lt;code class="r">devtools::install_github(&amp;quot;qinwf/ropencc&amp;quot;)&lt;/code>&lt;/pre>
&lt;p>使用上非常容易：&lt;/p>
&lt;pre>&lt;code class="r">library(ropencc)
trans &amp;lt;- converter(TW2SP) # 臺灣用法轉大陸用法
run_convert(trans, &amp;quot;開放中文轉換軟體&amp;quot;)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;开放中文转换软件&amp;quot;&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="r">trans &amp;lt;- converter(T2S) # 單純繁轉簡
run_convert(trans, &amp;quot;開放中文轉換軟體&amp;quot;)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;开放中文转换软体&amp;quot;&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="r">trans &amp;lt;- converter(S2TWP) # 簡轉臺灣用法
run_convert(trans, &amp;quot;开放中文转换软件&amp;quot;)&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="nohighlight">[1] &amp;quot;開放中文轉換軟體&amp;quot;&lt;/code>&lt;/pre>
&lt;p>在此我使用&lt;code>S2TWP&lt;/code>轉換&lt;code>$content&lt;/code>；&lt;code>S2T&lt;/code>轉換&lt;code>$title&lt;/code>：&lt;/p>
&lt;pre>&lt;code class="r">library(ropencc)
all_post_seg$content &amp;lt;- run_convert(converter(S2TWP),
all_post_seg$content)
all_post_seg$title &amp;lt;- run_convert(converter(S2T),
all_post_seg$title)
head(all_post_seg) %&amp;gt;%
mutate(title = str_trunc(title, 8),
content = str_trunc(content, 8),
links = str_trunc(links, 8),
link_text = str_trunc(link_text, 8)) %&amp;gt;%
kable(&amp;quot;markdown&amp;quot;, align = &amp;quot;c&amp;quot;)&lt;/code>&lt;/pre>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th align="center">title&lt;/th>
&lt;th align="center">date&lt;/th>
&lt;th align="center">content&lt;/th>
&lt;th align="center">num_sec&lt;/th>
&lt;th align="center">links&lt;/th>
&lt;th align="center">link_text&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="center">修辭還是真實&lt;/td>
&lt;td align="center">2018-06-21&lt;/td>
&lt;td align="center">說 兩封 …&lt;/td>
&lt;td align="center">12&lt;/td>
&lt;td align="center">chara…&lt;/td>
&lt;td align="center">chara…&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">花椒香料&lt;/td>
&lt;td align="center">2018-05-31&lt;/td>
&lt;td align="center">古人 似乎…&lt;/td>
&lt;td align="center">2&lt;/td>
&lt;td align="center">/cn/2…&lt;/td>
&lt;td align="center">去年的花椒&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="center">CSS 的…&lt;/td>
&lt;td align="center">2018-05-14&lt;/td>
&lt;td align="center">CSS …&lt;/td>
&lt;td align="center">15&lt;/td>
&lt;td align="center">c(“ht…&lt;/td>
&lt;td align="center">c(“查阅…&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">毛姆的文學回憶錄&lt;/td>
&lt;td align="center">2018-05-04&lt;/td>
&lt;td align="center">前段時間 …&lt;/td>
&lt;td align="center">14&lt;/td>
&lt;td align="center">c(“/c…&lt;/td>
&lt;td align="center">c(“职业…&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="center">距離的組織&lt;/td>
&lt;td align="center">2018-05-03&lt;/td>
&lt;td align="center">前面 《 …&lt;/td>
&lt;td align="center">5&lt;/td>
&lt;td align="center">/cn/2…&lt;/td>
&lt;td align="center">闲情赋&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">語言聖戰的終結？&lt;/td>
&lt;td align="center">2018-04-19&lt;/td>
&lt;td align="center">一直 以來…&lt;/td>
&lt;td align="center">3&lt;/td>
&lt;td align="center">c(“ht…&lt;/td>
&lt;td align="center">c(“惊天…&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/div>
&lt;/div>
&lt;div id="quanteda" class="section level2">
&lt;h2>quanteda&lt;/h2>
&lt;p>我們前面進行的資料前處理，已經將資料整理成符合&lt;a href="https://tutorials.quanteda.io/basic-operations/corpus/corpus/">&lt;code>quanteda::corpus()&lt;/code>輸入的格式&lt;/a>：&lt;/p>
&lt;blockquote>
&lt;p>A data frame consisting of a character vector for documents, and additional vectors for document-level variables&lt;/p>
&lt;/blockquote>
&lt;p>因此，依以下指令即可將&lt;code>all_post_seg&lt;/code>轉換成&lt;code>corpus&lt;/code>物件：&lt;/p>
&lt;pre>&lt;code class="r">library(quanteda)
corp &amp;lt;- corpus(all_post_seg,
docid_field = &amp;quot;title&amp;quot;,
text_field = &amp;quot;content&amp;quot;)
corp %&amp;gt;% summary() %&amp;gt;% as_data_frame() %&amp;gt;%
head(3) %&amp;gt;%
mutate(links = str_trunc(links, 8),
link_text = str_trunc(link_text, 8)) %&amp;gt;%
kable(&amp;quot;markdown&amp;quot;, align = &amp;quot;c&amp;quot;)&lt;/code>&lt;/pre>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th align="center">Text&lt;/th>
&lt;th align="center">Types&lt;/th>
&lt;th align="center">Tokens&lt;/th>
&lt;th align="center">Sentences&lt;/th>
&lt;th align="center">date&lt;/th>
&lt;th align="center">num_sec&lt;/th>
&lt;th align="center">links&lt;/th>
&lt;th align="center">link_text&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="center">修辭還是真實&lt;/td>
&lt;td align="center">217&lt;/td>
&lt;td align="center">375&lt;/td>
&lt;td align="center">15&lt;/td>
&lt;td align="center">2018-06-21&lt;/td>
&lt;td align="center">12&lt;/td>
&lt;td align="center">chara…&lt;/td>
&lt;td align="center">chara…&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="center">花椒香料&lt;/td>
&lt;td align="center">149&lt;/td>
&lt;td align="center">246&lt;/td>
&lt;td align="center">9&lt;/td>
&lt;td align="center">2018-05-31&lt;/td>
&lt;td align="center">2&lt;/td>
&lt;td align="center">/cn/2…&lt;/td>
&lt;td align="center">去年的花椒&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="center">CSS 的位置屬性以及如何居中對齊超寬元素&lt;/td>
&lt;td align="center">347&lt;/td>
&lt;td align="center">805&lt;/td>
&lt;td align="center">23&lt;/td>
&lt;td align="center">2018-05-14&lt;/td>
&lt;td align="center">15&lt;/td>
&lt;td align="center">c(“ht…&lt;/td>
&lt;td align="center">c(“查阅…&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>有了&lt;code>corpus&lt;/code>的資料結構後，即進入了下圖&lt;code>quanteda&lt;/code>的分析架構，也結束了資料前處理的階段，開始進入 EDA 的階段。&lt;/p>
&lt;img src="https://img.yongfu.name/blog/mermaid.svg" alt="">
&lt;div class="mermaid">
graph TD
C(Corpus)
token(Tokens)
AP["Positional analysis"]
AN["Non-positional analysis"]
dfm(DFM)
tidy("Tidy Text Format")
vis("Visualize")
C --> token
token --> dfm
token -.-> AP
dfm -.-> AN
tidy -->|"cast_dfm()"| dfm
dfm -->|"tidy()"| tidy
dfm -.- vis
tidy -.-> vis
AP -.- vis
style C stroke-width:0px,fill:#6bbcff
style token stroke-width:0px,fill:#6bbcff
style dfm stroke-width:0px,fill:#6bbcff
style tidy stroke-width:0px,fill:orange
linkStyle 6 stroke-width:0px,fill:none;
linkStyle 8 stroke-width:0px,fill:none;
&lt;/div>
&lt;p>&lt;a href="https://quanteda.io/">quanteda&lt;/a> 有相當完整的&lt;a href="https://tutorials.quanteda.io/">教學資源&lt;/a>，且有很多有用的函數。同時，&lt;a href="https://github.com/juliasilge/tidytext">&lt;code>tidytext&lt;/code>&lt;/a> 套件也能輕易與 &lt;code>quanteda&lt;/code> 配合，在 &lt;code>document-feature matrix&lt;/code> 與&lt;code>tidytext&lt;/code>所提倡的 &lt;strong>tidy data frame&lt;/strong>(one-token-per-document-per-row) 兩種資料結構間自由轉換。&lt;strong>tidy data frame&lt;/strong> 的格式與&lt;a href="https://github.com/tidyverse/ggplot2">&lt;code>ggplot2&lt;/code>&lt;/a>相吻合，有助於資料視覺化的進行。&lt;/p>
&lt;p>這裡選擇以&lt;code>quanteda&lt;/code>而非&lt;code>tidytext&lt;/code>作為主要架構的原因在於&lt;code>tidytext&lt;/code>的架構僅容許 &lt;strong>bag-of-words&lt;/strong> 的架構，但&lt;code>quanteda&lt;/code>除了 &lt;strong>bag-of-words&lt;/strong> 之外，還保有 &lt;strong>Positional analysis&lt;/strong> 的潛力。&lt;/p>
&lt;p>由於篇幅有限，這裡不多加細談&lt;code>quanteda&lt;/code>套件&lt;a href="#fn3" class="footnoteRef" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a>。關於&lt;code>quanteda&lt;/code>的使用，可以參考 &lt;a href="https://tutorials.quanteda.io/">quanteda tutorial&lt;/a>，內容非常詳盡。&lt;/p>
&lt;/div>
&lt;div id="reproduce" class="section level2">
&lt;h2>Reproduce&lt;/h2>
&lt;p>這篇文章的原始碼在我的 &lt;a href="https://github.com/liao961120/blog/tree/master/post_source/quanteda-chinese">GitHub&lt;/a>，歡迎下載至自己的電腦執行。&lt;/p>
&lt;/div>
&lt;div class="section level2 unnumbered">
&lt;h2>參考資料&lt;/h2>
&lt;div id="refs" class="references">
&lt;div id="ref-silge2017">
&lt;p>Silge, Julia, and David Robinson. 2017. &lt;em>Text Mining with R: A Tidy Approach&lt;/em>. 1st ed. O’Reilly Media, Inc.&lt;/p>
&lt;/div>
&lt;div id="ref-watanabe2018">
&lt;p>Watanabe, Kohei, and Stefan Müller. 2018. “Quanteda Tutorials.” &lt;em>Quanteda Tutorials&lt;/em>. https://tutorials.quanteda.io/.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="footnotes">
&lt;ol>
&lt;li id="fn1">&lt;p>Mac 和 Linux 內建有 Bash，但 Windows 沒有。&lt;a href="#fnref1">↩&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>要能直接執行&lt;code>wget_list&lt;/code>需先給予其執行的權限，因此需設置&lt;code>chmod 755 &amp;lt;path to wget_list&amp;gt;&lt;/code>，並且將&lt;code>wget_list&lt;/code>置於 shell 會自動搜尋程式的地方(如&lt;code>/usr/bin/&lt;/code>)。&lt;/p>
&lt;p>另一個方法是不設置權限，直接執行&lt;code>wget_list&lt;/code>：&lt;br />
&lt;code>bash &amp;lt;path to wget_list&amp;gt; &amp;lt;file1&amp;gt; &amp;lt;file2&amp;gt;&lt;/code> &lt;!--FOOTNOTE END-->&lt;a href="#fnref2">↩&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>未來可能會發一篇續作。&lt;a href="#fnref3">↩&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div>
&lt;p style="text-align:right;font-size:7px;margin-top:0px;margin-bottom:0px;padding-top:0px;padding-bottom:1px">
Last updated: 2018-11-10
&lt;/p>
&lt;style>
div.mermaid {
display:none;
}
&lt;/style></description><category>R</category><category>linguistics</category><category>中文</category></item></channel></rss>
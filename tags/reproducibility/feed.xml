<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>reproducibility on Yongfu's Blog</title><link>https://yongfu.name/tags/reproducibility/</link><description>Recent content in reproducibility on Yongfu's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 25 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://yongfu.name/tags/reproducibility/feed.xml" rel="self" type="application/rss+xml"/><item><title>Demystifying Item Response Theory (1/4)</title><link>https://yongfu.name/2023/02/25/irt1/</link><pubDate>Sat, 25 Feb 2023 00:00:00 +0000</pubDate><guid>https://yongfu.name/2023/02/25/irt1/</guid><description>&lt;figure>
&lt;img src="irt.jpg" style="width:70.0%"
alt="Okay, so these are the item characteristic curves. What then?" />
&lt;figcaption aria-hidden="true">&lt;em>Okay, so these are the &lt;a
href="https://www.researchgate.net/figure/Item-characteristic-curves-Item-Response-Theory-IRT-1PL-model_fig1_342560715">item
characteristic curves&lt;/a>. What then?&lt;/em>&lt;/figcaption>
&lt;/figure>
&lt;h2 id="mysterious-item-response-theory">Mysterious Item Response Theory&lt;/h2>
&lt;p>&lt;strong>Item response theory is &lt;em>mysterious&lt;/em> and intimidating to students.&lt;/strong>
It is mysterious in the way it is presented in textbooks, at least in
introductory ones. The text often starts with an ambitious conceptual
introduction to IRT, which most students would be able to follow, but
with some confusion. Curious students might bear with the confusion and
expect it to resolve in the following text, only to find themselves
disappointed. At the point where the underlying statistical model should
be further elaborated, the text abruptly stops and tries to convince the
readers to trust the results from black-box IRT software packages.&lt;/p>
&lt;p>It isn’t that I have trust issues with black-box software, and I also
agree that certain details of IRT model estimation should be hidden from
the readers. The problem is that there’s a huge gap here, between where
textbooks stopped explaining and where the confusing details of
statistics should be hidden. Hence, students would be tricked into
believing that they have a &lt;em>sufficient degree of understanding&lt;/em>, but in
reality, it’s just blind faith.&lt;/p>
&lt;p>A sufficient degree of understanding should allow the student to deploy
the learned skills to new situations. Therefore, a sufficient degree of
understanding of IRT models should allow students to extend and apply
the models to analyses of, for instance, &lt;a href="https://en.wikipedia.org/wiki/Differential_item_functioning">differential item functioning
(DIF)&lt;/a> or
&lt;strong>differential rater functioning (DRF)&lt;/strong>.&lt;/p>
&lt;p>I’m arguing here that there is a basic granularity of understanding,
somewhat similar to the concept of &lt;a href="https://en.wikipedia.org/wiki/Basic_category">basic-level
category&lt;/a>, that when
reached, allows a student to smoothly adapt the learned skills to a wide
variety of situations, modifying and extending the skills on demand. And
I believe that item response theory is &lt;em>&lt;strong>too hard&lt;/strong>&lt;/em> for a student to
learn and reach this basic level of understanding, given its
conventional presentation and historical development&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>There is still hope however, thanks to the development of a very general
set of statistical models known as the &lt;a href="https://en.wikipedia.org/wiki/Generalized_linear_model">Generalized Linear Models
(GLM)&lt;/a>. Item
response models could be understood in terms of the GLM and its
extensions
(&lt;a href="https://en.wikipedia.org/wiki/Generalized_linear_mixed_model">GLMM&lt;/a>
and non-linear form of the GLM/GLMM). To be too particular about the
details, the results from IRT software packages and the GLMs/GLMMs would
be very similar but not identical, since they utilize different
estimation methods. The strengths of the GLM, however, lie in its
conceptual simplicity and extensibility. Through GLM, IRT and other
models such as the T-test, ANOVA, and linear regression, are all placed
together into the same conceptual framework. Furthermore, software
packages implementing GLMs are widely available. Users can thus
experiment with them—simulate a set of data based on known parameters,
construct the model and feed it the data, and see if the fitted model
correctly recovers the parameters. This technique of learning statistics
is probably the only effective way for students to understand &lt;em>&lt;strong>a
mysterious statistical model&lt;/strong>&lt;/em>.&lt;/p>
&lt;p>In this series of posts, I will walk you through the path of
understanding item response theory, with the help of simulations and
generalized linear models. No need to worry if you don’t know GLMs yet.
We have another ally—&lt;a href="https://www.r-project.org">R&lt;/a>, in which we will be
simulating artificial data and fitting statistical models along the way.
Although it might seem intimidating at first, coding simulations and
models in fact provide scaffolding for learning. When feeling unsure or
confused, you can always resort to these simulation-based experiments to
resolve the issues at hand. In this very first post, I will start by
teaching you &lt;em>&lt;strong>simulations&lt;/strong>&lt;/em>.&lt;/p>
&lt;h2 id="just-enough-theory-to-get-started">Just Enough Theory to Get Started&lt;/h2>
&lt;p>Jargons aside, the concept behind item response theory is fairly simple.
Consider the case where 80 testees are taking a 20-item English
proficiency test. Under this situation, what are the &lt;em>&lt;strong>factors&lt;/strong>&lt;/em> that
influence whether an item is correctly solved by a testee?
Straightforward right? If an item is easy and if a testee is proficient
in English, he/she would probably get the item correct. Here, &lt;em>&lt;strong>two
factors jointly influence the result&lt;/strong>&lt;/em>:&lt;/p>
&lt;ol>
&lt;li>how difficult (or easy) the item is&lt;/li>
&lt;li>the English ability of the testee&lt;/li>
&lt;/ol>
&lt;p>We can express these variables and the relations between them in the
graphs below. Let’s focus on the left one first. Here, $A$ represents
the &lt;strong>ability&lt;/strong> of the testee, $D$ represents the &lt;strong>difficulty&lt;/strong> of the
item, and $R$ represents the &lt;strong>item response&lt;/strong>, or &lt;strong>score&lt;/strong> on the
item. A response for an item is coded as &lt;code>1&lt;/code> ($R=1$) if it is solved
correctly. Otherwise, it is coded as &lt;code>0&lt;/code> ($R=0$). The arrows
$A \rightarrow R$ and $D \rightarrow R$ indicate the direction of
influence. The arrows enter $R$ since item difficulty and testee ability
influence the score on the item (not the other way around). $A$ and $D$
are drawn as a circled node to indicate that they are &lt;strong>unobserved&lt;/strong> (or
&lt;strong>latent&lt;/strong>, if you prefer a fancier term), whereas uncircled nodes
represent directly observable variables (i.e., stuff that gets recorded
during data collection). This graphical representation of the variables
and their relationships is known as a &lt;a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">Directed Acyclic Graph
(DAG)&lt;/a>.&lt;/p>
&lt;img src="dag.svg" style="max-height:150px" />
&lt;p>The DAGs laid out here represent the concept behind the simplest kind of
item response models, known as the &lt;strong>1-parameter logistic (1PL) model&lt;/strong>
(or the Rasch Model). In more formal terms, this model posits that the
&lt;strong>probability&lt;/strong> of correctly answering an item is determined by the
&lt;strong>difference&lt;/strong> between testee ability and item difficulty. So a more
precise DAG representation for this model would be the one shown on the
right above. Here, $P$ is the probability of correctly answering the
item, which cannot be directly observed. However, $P$ directly
influences the item score $R$, hence the arrow $P \rightarrow R$.&lt;/p>
&lt;p>Believe it or not, the things we have learned so far could get us
started. So let’s simulate some data, based on what we’ve learned about
item response theory!&lt;/p>
&lt;h2 id="simulating-item-responses">Simulating Item Responses&lt;/h2>
&lt;figure>
&lt;img src="tenet2.gif" style="width:85.0%"
alt="Simulation is playing god in a small world. Similar to model fitting, but in reverse direction." />
&lt;figcaption aria-hidden="true">Simulation is &lt;em>playing god&lt;/em> in a
small world. Similar to model fitting, but in &lt;em>reverse&lt;/em>
direction.&lt;/figcaption>
&lt;/figure>
&lt;p>Consider the scenario where 3 students (Rob, Tom, and Joe) took a math
test with 2 items (A and B). Since we play gods during simulations, we
know the math ability of the students and the difficulty of the items.
These ability/difficulty levels can range from positive to negative
numbers, unbounded. Larger numbers indicate higher levels of
difficulty/ability. In addition, the levels of difficulty and ability
sit on a common scale and hence could be directly compared. Also, each
student responds to every item, so we get responses from all 6 (3x2)
combinations of students and items. Let’s code this in R below. The
function &lt;code>expand.grid()&lt;/code> would pair up the 6 combinations for us.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>D &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">c&lt;/span>( A&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.4&lt;/span>, B&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.1&lt;/span> ) &lt;span style="color:#75715e"># Difficulty of item&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>A &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">c&lt;/span>( R&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.5&lt;/span>, T&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.1&lt;/span>, J&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">-0.4&lt;/span> ) &lt;span style="color:#75715e"># Ability of student (R:Rob, T:Tom, J:Joe)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4&lt;/span>&lt;span>dat &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">expand.grid&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5&lt;/span>&lt;span> I &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">c&lt;/span>( &lt;span style="color:#e6db74">&amp;#34;A&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;B&amp;#34;&lt;/span> ), &lt;span style="color:#75715e"># Item index&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6&lt;/span>&lt;span> T &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">c&lt;/span>( &lt;span style="color:#e6db74">&amp;#34;R&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;T&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;J&amp;#34;&lt;/span> ) &lt;span style="color:#75715e"># Testee index&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7&lt;/span>&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8&lt;/span>&lt;span>dat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code># A tibble: 6 x 2
I T
&amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;
1 A R
2 B R
3 A T
4 B T
5 A J
6 B J
&lt;/code>&lt;/pre>
&lt;p>After having all possible combinations of the students and the items, we
could collect the values of student ability and item difficulty into the
data frame.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>dat&lt;span style="color:#f92672">$&lt;/span>A &lt;span style="color:#f92672">=&lt;/span> A[ dat&lt;span style="color:#f92672">$&lt;/span>T ] &lt;span style="color:#75715e"># map ability to df by testee index T&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>dat&lt;span style="color:#f92672">$&lt;/span>D &lt;span style="color:#f92672">=&lt;/span> D[ dat&lt;span style="color:#f92672">$&lt;/span>I ] &lt;span style="color:#75715e"># map difficulty to df by item index I&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3&lt;/span>&lt;span>dat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code># A tibble: 6 x 4
I T A D
&amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
1 A R 0.5 0.4
2 B R 0.5 0.1
3 A T 0.1 0.4
4 B T 0.1 0.1
5 A J -0.4 0.4
6 B J -0.4 0.1
&lt;/code>&lt;/pre>
&lt;p>Now, we’ve got all the data needed for simulation, the only thing left
is to precisely lay out the &lt;strong>rules for generating the response data
$R$&lt;/strong>—the scores (zeros and ones) on the items solved by the students.
We are two steps away.&lt;/p>
&lt;h3 id="generating-probabilities">Generating Probabilities&lt;/h3>
&lt;p>When IRT is introduced in the previous section, I mention that the
probability of successfully solving an item is determined by the
&lt;strong>difference between testee ability and item difficulty&lt;/strong>. It is
straightforward to get this difference: simply subtract $D$ from $A$ in
the data. This would give us a new variable $\mu$. I save the values of
$\mu$ to column &lt;code>Mu&lt;/code> in the data frame.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>dat&lt;span style="color:#f92672">$&lt;/span>Mu &lt;span style="color:#f92672">=&lt;/span> dat&lt;span style="color:#f92672">$&lt;/span>A &lt;span style="color:#f92672">-&lt;/span> dat&lt;span style="color:#f92672">$&lt;/span>D
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>dat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code># A tibble: 6 x 5
I T A D Mu
&amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
1 A R 0.5 0.4 0.1
2 B R 0.5 0.1 0.4
3 A T 0.1 0.4 -0.3
4 B T 0.1 0.1 0
5 A J -0.4 0.4 -0.8
6 B J -0.4 0.1 -0.5
&lt;/code>&lt;/pre>
&lt;p>From the way $\mu$ is calculated ($A$ - $D$), we can see that, for a
particular observation, if $\mu$ is positive and large, the testee’s
ability will be much greater than the item’s difficulty, and he would
probably succeed on this item. On the other hand, if $\mu$ is negative
and small, the item difficulty would be much greater in this case, and
the testee would likely fail on this item. Hence, $\mu$ should be
directly related to probability, in that $\mu$ of large values result in
high probabilities of success on the items, whereas $\mu$ of small
values result in low probabilities of success. But how exactly is $\mu$
linked to probability? How can we map $\mu$ to probability in a
principled manner? The solution is to take advantage of the &lt;a href="https://en.wikipedia.org/wiki/Logistic_function">logistic
function&lt;/a>.&lt;/p>
&lt;p>$$
\text{logistic}( x ) = \frac{ 1 }{ 1 + e^{-x} }
$$&lt;/p>
&lt;p>The &lt;em>&lt;strong>logistic&lt;/strong>&lt;/em> is a function that maps a real number $x$ to a
probability $p$. In other words, the logistic function transforms the
input $x$ and constrains it to a value between zero and one. Note that
the transformation is &lt;strong>monotonic increasing&lt;/strong>, meaning that a smaller
$x$ would be mapped onto a smaller $p$, and a larger $x$ would be mapped
onto a larger $p$. The ranks of the values before and after the
transformation stay the same. To have a feel of what the logistic
function does, let’s transform some values with the logistic.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>&lt;span style="color:#75715e"># Set plot margins # (b, l, t, r)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>&lt;span style="color:#a6e22e">par&lt;/span>(oma&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#a6e22e">c&lt;/span>(&lt;span style="color:#ae81ff">0&lt;/span>,&lt;span style="color:#ae81ff">0&lt;/span>,&lt;span style="color:#ae81ff">0&lt;/span>,&lt;span style="color:#ae81ff">0&lt;/span>)) &lt;span style="color:#75715e"># Outer margin&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3&lt;/span>&lt;span>&lt;span style="color:#a6e22e">par&lt;/span>(mar&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#a6e22e">c&lt;/span>(&lt;span style="color:#ae81ff">4.5&lt;/span>, &lt;span style="color:#ae81ff">4.5&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>) ) &lt;span style="color:#75715e"># margin&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5&lt;/span>&lt;span>logistic &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">function&lt;/span>(x) &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">/&lt;/span> ( &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">exp&lt;/span>(&lt;span style="color:#f92672">-&lt;/span>x) )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6&lt;/span>&lt;span>x &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">seq&lt;/span>( &lt;span style="color:#ae81ff">-5&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>, by&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.1&lt;/span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7&lt;/span>&lt;span>p &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">logistic&lt;/span>( x )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8&lt;/span>&lt;span>&lt;span style="color:#a6e22e">plot&lt;/span>( x, p )
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="part1_files/figure-commonmark/unnamed-chunk-4-1.svg"
style="width:100.0%" data-fig-align="center" />&lt;/p>
&lt;p>As the plot shows, the logistic transformation results in an S-shaped
curve. Since the transformed values (p) are bounded by 0 and 1, extreme
values on the poles of the x-axis would be “squeezed” after the
transformation. Real numbers with absolute values greater than 4, after
transformations, would have probabilities very close to the boundaries.&lt;/p>
&lt;h4 id="less-math-less-confusion">Less Math, Less Confusion&lt;/h4>
&lt;p>For many students, the mathematical form of the logistic function leads
to confusion. Staring at the math symbols hardly enables one to arrive
at any insightful interpretation of the logistic. A suggestion here is
to let go of the search for such an interpretation. The logistic
function is introduced not because it is loaded with some crucial
mathematical or statistical meaning. Instead, it is used here solely for
a practical reason: to monotonically map real numbers to probabilities.
You may well use another function here to achieve the same purpose
(e.g., the &lt;strong>cumulative distribution function&lt;/strong> of the standard normal).&lt;/p>
&lt;h3 id="generating-responses">Generating Responses&lt;/h3>
&lt;p>We have gone all the way from ability/difficulty levels to the
probabilities of success on the items. Since we cannot directly observe
probabilities in the real world, the final step is to link these
probabilities to observable outcomes. In the case here, the outcomes are
simply item responses of zeros and ones. How do we map probabilities to
zeros and ones? Coin flips, or &lt;a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli
distributions&lt;/a>,
will get us there.&lt;/p>
&lt;p>Every time a coin is flipped, either a tail or a head is observed. The
Bernoulli distribution is just a fancy way of describing this process.
Assume that we record tails as &lt;code>0&lt;/code>s and heads as &lt;code>1&lt;/code>s, and suppose that
the probability $p$ of observing a head equals 0.75 (since the coin is
imbalanced in some way that the head is more likely observed and we know
it somehow). Then, the distribution of the outcomes (zero and one) will
be a Bernoulli distribution with parameter $P=0.75$. In graphical terms,
the distribution is just two bars.&lt;/p>
&lt;p>&lt;img src="part1_files/figure-commonmark/unnamed-chunk-5-1.svg"
style="width:100.0%" data-fig-align="center" />&lt;/p>
&lt;p>We’ve got all we need by now. Let’s construct the remaining columns to
complete this simulation. In the code below, I compute the probabilities
(&lt;code>P&lt;/code>) from column &lt;code>Mu&lt;/code>. Column &lt;code>P&lt;/code> could then generate column &lt;code>R&lt;/code>, the
item responses, through the Bernoulli distribution.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>rbern &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">function&lt;/span>( p, n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#a6e22e">length&lt;/span>(p) )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span> &lt;span style="color:#a6e22e">rbinom&lt;/span>( n&lt;span style="color:#f92672">=&lt;/span>n, size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, prob&lt;span style="color:#f92672">=&lt;/span>p )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4&lt;/span>&lt;span>&lt;span style="color:#a6e22e">set.seed&lt;/span>(&lt;span style="color:#ae81ff">13&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5&lt;/span>&lt;span>dat&lt;span style="color:#f92672">$&lt;/span>P &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">logistic&lt;/span>( dat&lt;span style="color:#f92672">$&lt;/span>Mu )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6&lt;/span>&lt;span>dat&lt;span style="color:#f92672">$&lt;/span>R &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">rbern&lt;/span>( dat&lt;span style="color:#f92672">$&lt;/span>P ) &lt;span style="color:#75715e"># Generate 0/1 from Bernoulli distribution&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7&lt;/span>&lt;span>dat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code># A tibble: 6 x 7
I T A D Mu P R
&amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
1 A R 0.5 0.4 0.1 0.525 0
2 B R 0.5 0.1 0.4 0.599 1
3 A T 0.1 0.4 -0.3 0.426 0
4 B T 0.1 0.1 0 0.5 0
5 A J -0.4 0.4 -0.8 0.310 1
6 B J -0.4 0.1 -0.5 0.378 0
&lt;/code>&lt;/pre>
&lt;p>Now, we have a complete table of simulated item responses. A few things
to notice here. First, look at the fourth row of the data frame, where
the response of testee T (Tom) on item B is recorded. Column &lt;code>Mu&lt;/code> has a
value of zero since Tom’s ability level is identical to the difficulty
of item B. What does it mean to be “identical”? “Identical” implies that
Tom is neither more likely to succeed nor to fail on item B. Hence, you
can see that Tom has a 50% of getting item B correct in the $P$ column.
This is how the ability/difficulty levels and $\mu$ are interpreted.
They are on an abstract scale of real numbers. We need to convert them
to probabilities to make sense of them.&lt;/p>
&lt;p>The second thing to notice is column &lt;code>R&lt;/code>. This is the only column that
has &lt;em>&lt;strong>randomness&lt;/strong>&lt;/em> introduced. Every run of the simulation would
likely give different values of $R$ (unless a random seed is set, or the
&lt;code>P&lt;/code> column consists solely of zeros and ones). The outcomes are not
guaranteed, probability is at work.&lt;/p>
&lt;p>The presence of such randomness is the gist of simulations and
statistical models. We add uncertainty to the simulation, mimicking the
real world, to know that in the presence of such uncertainty, would it
still be possible to discover targets of interest with a statistical
model. Randomness, however, poses some challenges for coding. We need to
equip ourselves for those challenges.&lt;/p>
&lt;h2 id="coding-randomness">Coding Randomness&lt;/h2>
&lt;p>Randomness is inherent in simulations and statistical models, so it is
impossible to run away from it. It is everywhere. The problem with
randomness is that it introduces uncertainty in the outcome produced.
Thus, it would be hard to spot any errors just by &lt;strong>eyeballing the
results&lt;/strong>.&lt;/p>
&lt;p>Take &lt;code>rbern()&lt;/code> for instance. Given a parameter $P=0.5$, we can
repeatedly run &lt;code>rbern(0.5)&lt;/code> a couple of times to produce zeros and ones.
But these zeros and ones cannot tell us whether &lt;code>rbern(0.5)&lt;/code> is working
properly. &lt;code>rbern(0.5)&lt;/code> might be broken somehow, and instead generates
the ones with, say, $P=0.53$.&lt;/p>
&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/Law_of_large_numbers">law of large
numbers&lt;/a> can help us
here. Since &lt;code>rbern()&lt;/code> generates ones with probability $P$, if we run
&lt;code>rbern()&lt;/code> many times, the proportion of the ones in the outcomes should
converge to $P$. To achieve this, take a look at the second argument &lt;code>n&lt;/code>
in &lt;code>rbern()&lt;/code>, which is set here to repeatedly generate outcomes ten
thousand times. You can increase &lt;code>n&lt;/code> to see if the result comes even
closer to $0.5$.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>outcomes &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">rbern&lt;/span>( p&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.5&lt;/span>, n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1e4&lt;/span> ) &lt;span style="color:#75715e"># Run rbern with P=0.5 10,000 times&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>&lt;span style="color:#a6e22e">mean&lt;/span>(outcomes)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>[1] 0.4991
&lt;/code>&lt;/pre>
&lt;p>A more general way to rerun a chunk of code is through the for loop or
convenient wrappers such as the &lt;code>replicate()&lt;/code> function. I demonstrate
some of their uses below.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>outcomes &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">replicate&lt;/span>( n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1e4&lt;/span>, expr&lt;span style="color:#f92672">=&lt;/span>{ &lt;span style="color:#a6e22e">rbern&lt;/span>( p&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.5&lt;/span> ) } )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>&lt;span style="color:#a6e22e">mean&lt;/span>(outcomes)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>[1] 0.5027
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1&lt;/span>&lt;span>&lt;span style="color:#75715e"># See if several runs of rbern( p=0.5, n=1e4 ) give results around 0.5&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2&lt;/span>&lt;span>Ps &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">replicate&lt;/span>( n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100&lt;/span>, expr&lt;span style="color:#f92672">=&lt;/span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3&lt;/span>&lt;span> outcomes &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">rbern&lt;/span>( p&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.5&lt;/span>, n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1e4&lt;/span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4&lt;/span>&lt;span> &lt;span style="color:#a6e22e">mean&lt;/span>(outcomes)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5&lt;/span>&lt;span>})
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7&lt;/span>&lt;span>&lt;span style="color:#75715e"># Plot Ps to see if they scatter around 0.5&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8&lt;/span>&lt;span>&lt;span style="color:#a6e22e">plot&lt;/span>( &lt;span style="color:#ae81ff">1&lt;/span>, type&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;n&amp;#34;&lt;/span>, xlim&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#a6e22e">c&lt;/span>(&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">100&lt;/span>), ylim&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#a6e22e">c&lt;/span>(&lt;span style="color:#ae81ff">0.47&lt;/span>, &lt;span style="color:#ae81ff">0.53&lt;/span>), ylab&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;P&amp;#34;&lt;/span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9&lt;/span>&lt;span>&lt;span style="color:#a6e22e">abline&lt;/span>( h&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.5&lt;/span>, lty&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;dashed&amp;#34;&lt;/span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10&lt;/span>&lt;span>&lt;span style="color:#a6e22e">points&lt;/span>( Ps, pch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">19&lt;/span>, col&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span> )
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="part1_files/figure-commonmark/unnamed-chunk-9-1.svg"
style="width:100.0%" data-fig-align="center" />&lt;/p>
&lt;h3 id="randomness-in-models">Randomness in Models&lt;/h3>
&lt;p>The method described above works only for simple cases. What about
complex statistical models? How do we test that they are working as they
claim to? Guess what? &lt;em>&lt;strong>Simulation&lt;/strong>&lt;/em> is the key.&lt;/p>
&lt;p>We simulate data based on the assumptions of the statistical model and
see if it indeed returns what it claims to estimate. The simulation can
be repeated several times, each set to different values of parameters.
If the parameters are always recovered by the statistical model, we can
then be confident that the model is properly constructed and correctly
coded. So &lt;strong>simulation is really &lt;em>not an option&lt;/em> when doing
statistics&lt;/strong>. It is the only safety that helps us guard against bugs in
our statistical models, both programmatical and theoretical ones.
Without first testing the statistical model on simulated data, any
inferences about the empirical data are in doubt.&lt;/p>
&lt;h2 id="whats-next">What’s next?&lt;/h2>
&lt;p>In a real-world scenario of the example presented here, we would only
observe the score ($R$) of an item ($I$) taken by a testee ($T$). The
targets of interest are the unobserved item difficulty ($D$) and testee
ability ($A$). In &lt;a href="https://yongfu.name/irt2">Part 2&lt;/a>, we will work in reverse and fit
statistical models on simulated data. We will see how the models
discover the true $A$s and $D$s from the information of $R$, $I$, and
$T$. See you there!&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>I mean, what the hack is &lt;em>Joint and Conditional Maximum Likelihood
Estimation&lt;/em>? These are methods developed in the psychometric and
measurement literature and are hardly seen in other fields. Unless
obsessed with psychometrics, I don’t think one would be able to
understand these things.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description><category>r</category><category>stats</category><category>psychology</category><category>reproducibility</category></item><item><title>A Minimalist Structure for Snakemake</title><link>https://yongfu.name/2023/02/15/snakemake/</link><pubDate>Wed, 15 Feb 2023 00:00:00 +0000</pubDate><guid>https://yongfu.name/2023/02/15/snakemake/</guid><description>&lt;p>I have &lt;a href="https://kbroman.org/minimal_make">heard of&lt;/a> the use of &lt;a href="https://www.gnu.org/software/make/">GNU Make&lt;/a> for enhancing
reproducibility for some time. I did not incorporate Make into my work however,
since a simple build script written in Bash was sufficient. Everything was well
in control, and I could structure the workflow to my will.&lt;/p>
&lt;p>It was not until I started working in a company setting that I found most things
out of my control. Decades of conventions have been accumulating and passing on,
and personal workflows have to fit into existing ones. In order to fit into my
company&amp;rsquo;s conventions of data analysis (which pretty much just ignore analysis
reproducibility), the number of scripts grew exponentially and quickly fell out
of my control (see figure below, which is automatically generated by Snakemake).
I needed a way to document and track my workflow in a consistent and scalable
manner. This was when I picked up Prof. Broman&amp;rsquo;s &lt;a href="https://kbroman.org/minimal_make">great introductory post&lt;/a>
on GNU Make again. Everything seemed hopeful, but I was soon defeated by the
omnipresent Windows. Since it is required to work on Windows machines in my
company, and since &lt;a href="http://gnuwin32.sourceforge.net/packages/make.htm">Make for Windows&lt;/a> has difficulties dealing with
Chinese file paths, I had to give up on Make. &lt;a href="https://snakemake.github.io">Snakemake&lt;/a> came as my
savior.&lt;/p>
&lt;p>
&lt;figure>
&lt;img src="https://img.yongfu.name/posts/dag.png" alt="Data analysis workflow graph generated by Snakemake">
&lt;figcaption>Data analysis workflow graph generated by Snakemake&lt;/figcaption>
&lt;/figure>
&lt;/p>
&lt;h2 id="meeting-snakemake">Meeting Snakemake&lt;/h2>
&lt;p>Snakemake was inspired by, but way more complicated than, GNU Make. Since it is
backed by Python, cross-platform issues such as character encodings are
automatically resolved. Snakemake is a thoughtful project that was originally
developed to facilitate computational research and reproducibility. Thus, it may
take some time to get started since there are many concepts to pick up. It&amp;rsquo;s
totally worth it, however. Dealing with complex tasks requires a complicated
framework. Often, these complications make sense (and are appreciated) only
after we face real-world complexities. Going through &lt;a href="https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html">Snakemake&amp;rsquo;s
tutorial&lt;/a> and experimenting with it on the computer would be sufficient
to get an average user started. It is not as complicated as it seems at first
glance.&lt;/p>
&lt;h2 id="snakemake-recommended-workflow">Snakemake Recommended Workflow&lt;/h2>
&lt;p>A great thing about Snakemake is that it is &lt;a href="https://stackoverflow.com/a/82064">opinionated&lt;/a>. This means
that certain conventions&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> are proposed, and most users would benefit
from them since they spare the burden of planning and creating workflow
structures.&lt;/p>
&lt;p>For instance, Snakemake &lt;a href="https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#distribution-and-reproducibility">recommends&lt;/a> the directory structure listed
below for every Snakemake workflow. This structure is so simple that its genius
might not be obvious at first glance. There are four directories in the project
root&amp;mdash;&lt;code>workflow/&lt;/code>, &lt;code>config/&lt;/code>, &lt;code>results/&lt;/code>, and &lt;code>resources/&lt;/code>. &lt;code>workflow/&lt;/code> holds
the &lt;em>coding&lt;/em> stuff. Code for data analysis, computation, and reproducibility are
all found in this directory. &lt;code>config/&lt;/code> is for optional configuration and I would
skip it here (in my own project, I did not use config files since the
&lt;code>Snakefile&lt;/code> is sufficient for my purposes). &lt;code>results/&lt;/code> and &lt;code>resources/&lt;/code> are what
(I think) make this structure fantastic. &lt;code>resources/&lt;/code> holds all &lt;strong>raw data&lt;/strong>,
i.e., data that are not reproducible on your computer (e.g., manually annotated
data). All data resulting from the computation in the current project are
located in &lt;code>results/&lt;/code>. So ideally, you could delete &lt;code>results/&lt;/code> at any time
without worry. A single command &lt;code>snakmake -c&lt;/code> should generate all the results
from &lt;code>resources/&lt;/code>. The genius of this structure is that it eliminates the need
of worrying about where to place newly arrived data, as commonly encountered in
real-world situations (e.g., an analysis might require data that you did not
foresee).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1&lt;/span>&lt;span>├── .gitignore
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2&lt;/span>&lt;span>├── README.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3&lt;/span>&lt;span>├── workflow
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4&lt;/span>&lt;span>│ ├── rules
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5&lt;/span>&lt;span>| │ ├── module1.smk
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6&lt;/span>&lt;span>| │ └── module2.smk
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7&lt;/span>&lt;span>│ ├── scripts
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8&lt;/span>&lt;span>| │ ├── script1.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9&lt;/span>&lt;span>| │ └── script2.R
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10&lt;/span>&lt;span>| └── Snakefile
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11&lt;/span>&lt;span>├── config
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12&lt;/span>&lt;span>│ └── config.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13&lt;/span>&lt;span>├── results
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14&lt;/span>&lt;span>└── resources
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="an-enhanced-snakemake-workflow">An Enhanced Snakemake Workflow&lt;/h2>
&lt;p>I adopted the workflow above in my work. It was great, but I still found &lt;strong>two
annoying drawbacks&lt;/strong>.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Long directory names&lt;/strong>&lt;/p>
&lt;p>Since in a &lt;code>Snakefile&lt;/code>, file paths of inputs and outputs are always
repeated, it soon becomes annoying to type in paths starting with
&lt;code>resources/...&lt;/code> and &lt;code>results/...&lt;/code>. In addition, &amp;ldquo;resources&amp;rdquo; and &amp;ldquo;results&amp;rdquo;
have a common prefix, which often confuses me. It would be better off if the
two terms are more readily distinguished visually.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Confusing relative paths&lt;/strong>&lt;/p>
&lt;p>According to the &lt;a href="https://snakemake.readthedocs.io/en/latest/project_info/faq.html#how-does-snakemake-interpret-relative-paths">documentation&lt;/a>, relative paths in different
directives are &lt;strong>interpreted differently&lt;/strong>. To be short, relative paths in
&lt;code>input:&lt;/code>, &lt;code>output:&lt;/code>, and &lt;code>shell:&lt;/code> are interpreted relative to the working
directory (i.e., where you invoke the command &lt;code>snakemake -c&lt;/code>), whereas in
directives such as &lt;code>script:&lt;/code>, they are interpreted as relative to the
&lt;code>Snakefile&lt;/code>. So it would be cognitively demanding to switch back and forth
between the reference points of relative paths while writing the
&lt;code>Snakefile&lt;/code>. Why not have all paths relative to the project root?&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>To deal with the aforementioned problems, I modified the recommended directory
structure and arrived at the structure below:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>├── README.md
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>├── Snakefile
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3&lt;/span>&lt;span>├── made
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4&lt;/span>&lt;span>├── raw
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5&lt;/span>&lt;span>└── src
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol>
&lt;li>
&lt;p>&lt;strong>Simplified directory names&lt;/strong>&lt;/p>
&lt;p>&lt;code>resources/&lt;/code> is renamed as &lt;code>raw/&lt;/code>, and &lt;code>results/&lt;/code> is renamed as &lt;code>made/&lt;/code>. The
&lt;code>workflow/&lt;/code> directory is broken down into &lt;code>src/&lt;/code> (holding scripts) and the
&lt;code>Snakefile&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Consistent relative paths&lt;/strong>&lt;/p>
&lt;p>Since &lt;code>Snakefile&lt;/code> is now placed in the project root, the problem of
different relative paths for different directives is resolved, as long as
the user always invokes the command &lt;code>snakemake -c&lt;/code> in the project root.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>The source code of this Snakemake workflow can be found
&lt;a href="https://github.com/liao961120/minimal-snake">here on GitHub&lt;/a>.&lt;/p>
&lt;h2 id="some-notes-for-using-git-bash-as-shell">Some Notes for Using Git-Bash as Shell&lt;/h2>
&lt;p>The experience of using Snakemake on Windows is great overall. I ran into a
few problems, but the problems were usually solvable. There is one particular
problem that took me a while to solve. On Windows, the default shell executable
used in Snakemake (and Python) is Cmd (or maybe Powershell). But since I am more
familiar with Bash and Unix tools, it is a real inconvenience. I had set up
Git-Bash on the company&amp;rsquo;s Windows machine but then spent a long time figuring
out how to set Git-Bash as the default shell in Snakemake. The information for
Snakemake users on Windows is scarce. I guess Snakemake is just unpopular among
Windows users. After reading the &lt;a href="https://snakemake.readthedocs.io/en/v6.15.2/_modules/snakemake/shell.html">source code&lt;/a>, the solution turned
out to be quite simple. Just put the code below at the top of the &lt;code>Snakefile&lt;/code>
and place the path to Git-Bash executable in &lt;code>shell.executable()&lt;/code>. This will
allow the identical &lt;code>Snakefile&lt;/code> to be used on both Windows and Unix-like
computers without additional configurations.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>&lt;span style="color:#75715e"># Additional setup for running with git-bash on Windows&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>name &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#39;nt&amp;#39;&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3&lt;/span>&lt;span> &lt;span style="color:#f92672">from&lt;/span> snakemake.shell &lt;span style="color:#f92672">import&lt;/span> shell
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4&lt;/span>&lt;span> shell&lt;span style="color:#f92672">.&lt;/span>executable(&lt;span style="color:#e6db74">r&lt;/span>&lt;span style="color:#e6db74">&amp;#39;C:\Users\rd\AppData\Local\Programs\Git\bin\bash.exe&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>&amp;ldquo;Good&amp;rdquo; conventions here, as opposed to naturally-resulting conventions without the consideration of reproducibility.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description><category>r</category><category>python</category><category>reproducibility</category></item></channel></rss>
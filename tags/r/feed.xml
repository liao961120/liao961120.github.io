<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>R on Yongfu&#39;s Blog</title><link>https://yongfu.name/tags/r/</link><description>Recent content in R on Yongfu&#39;s Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 03 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://yongfu.name/tags/r/feed.xml" rel="self" type="application/rss+xml"/><item><title>我的 R 開放課程</title><link>https://yongfu.name/2021/06/03/my-r-course/</link><pubDate>Thu, 03 Jun 2021 00:00:00 +0000</pubDate><guid>https://yongfu.name/2021/06/03/my-r-course/</guid><description>這學期 (109-2) 第二次擔任課程助教，給大學部的同學們上 R 語言。第二次教學，在熱情上減了一半，在教材難度上增加了一半。大概是因為不喜歡重複做一樣的事，這次課程刻意補了上一次 (108-1) 懶得教1、沒時間教2、沒自信可以教3以及沒有能力教4的內容。有了這些新的內容，課程準備起來就比較提得起勁，畢竟知道在去年已經教過的內容上，現在的我實在很難超越當時的自己5。不過，在準備教材的同時，也可以看到自己這一陣子的轉變：對某些概念的認識更加地完整、思緒變得更複雜迅速有條理。能發現這些真的蠻開心的，至少腦袋還是有長一些。擴增教材的另一個目的，是為了補齊上一次未能 (學會然後) 教的缺憾，大概是一種想把圓畫完整的感覺，當然圓不可能畫得完美6，不過整體來說，完整的感覺還是大過缺憾許多，也蠻值得開心的。
這次的課程全部採取事前錄製影片的方式授課，表面上的目的是擔心遠距教學的情形再度出現 (結果真的出現了&amp;hellip;)，實際上的目的則是跟剛剛一樣：我不想要做同樣的事情 (實體授課)，而且這次實體授課大概也不會講得比上次好，所以不如換一種方式授課7。結果無心插柳，最後幾堂課因為突來的疫情改成遠距教學，對我反倒沒造成什麼影響，又是件值得開心的事情。
在經歷 12 個頗為漫長的週末，終於完成了這個算是完整的 R 語言課程。在這 12 堂課中，或許值得慶幸的一件事情是課程內容主題都不是 state-of-the-art。在能夠選擇時，選擇了去講比較穩定不變的東西、比較不會經過兩三年後就變成歷史名詞的技術或概念。這麼做或許可以讓課程的保鮮期變得比較長，也或許可以讓更多人從這個課程中受惠。這 12 堂課程的完整內容 (影片/簡報/講義/作業/程式碼) 可以在這個頁面取得，歡迎讀者自行使用、分享或是修改並應用於教學之中。
整個學期下來，雖然過得平淡、沒有第一次授課時那種短時間內大量成長的感覺，不過反倒是有種比較完整地完成了一件事情的感覺。這種感覺不會讓人大喜大悲、異常緊張或是過度興奮，但會讓心裡變得厚實舒坦，讓內心安穩一些，然後微微的喜悅就會從心底緩慢而持續地湧出。
最後，還要特別感謝 Andrea、Yulin、Mao-Chang 以及 Amber 在各個方面的協助，這門課的學生能有你們的照顧真的很幸運。
Lab01: 路徑、終端機、R101 (絕對與相對路徑 &amp;amp; Terminal) ↩ Lab12: 專案成果展示 (Shiny) ↩ Lab09: 文本與詞彙的向量表徵 (document-term matrix &amp;amp; latent semantic analysis) ↩ Lab06: Simulating Data with R (Causal inference 101) ↩ 那時多有熱情和自信啊！反觀現在真的很難被激勵，不過往好處想或許這代表掌握情緒的能力有所提昇？ ↩ 像是這次在教 Web API 時拿來示範用的 Public API 在我上傳教學影片之後就關閉服務了&amp;hellip; ↩ 這樣就不用和過去的自己硬碰硬比較，擔心自己退步了 (反正我有錄影片，觸及的人就是比較廣比較潮啦！108-1 的你輸了啦哈哈哈哈哈)。比較不見得會進步，但一定會帶來傷害，所以換個方式讓自己沒辦法去比較或許也不錯。 ↩</description></item><item><title>Getting Tabular Data Through JavaScript in Compiled R Markdown Documents</title><link>https://yongfu.name/2020/09/09/getable/</link><pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate><guid>https://yongfu.name/2020/09/09/getable/</guid><description>Recently, I have learned more about JavaScript and created a few JS web apps. This gave me the idea that we can separate the content and the data in an HTML document to make it more dynamic&amp;mdash;the content stays static while the data could be updated independently without rewriting or recompiling the HTML document. This could be done by utilizing JavaScript&amp;rsquo;s ability to asynchronously fetch data from the web and generate DOM elements based on these data.</description></item><item><title>ntuthesis</title><link>https://yongfu.name/2019/03/07/ntuthesis/</link><pubDate>Thu, 07 Mar 2019 00:00:00 +0000</pubDate><guid>https://yongfu.name/2019/03/07/ntuthesis/</guid><description>去年十月份的研究所甄試，實在找不到合乎主題的文章報告可以附在審查資料。想想自己可以拿來說嘴的大概只剩 R Markdown，於是寫了一篇 (硬是扯上語言學的) 文章交了上去。為了怕被面試老師問：「你在文章中說的可信嗎？文章中哪裡可看出你的研究能力？」便在文章中引用自己撰寫的套件1。由於還是害怕文章太過空泛，又將文章中的部份想法 &amp;ndash; R Markdown 模板，實作出來以備不時之需，ntuthesis 因而誕生了。結果 &amp;hellip; 面試時，老師們根本沒有問到有關 R Markdown 的問題。
緣起 這個用 R Markdown 寫論文的想法，其實在一年多前剛認識 R Markdown 時時就有了。當時還不太確定是否可行，僅覺得如果可行的話一定會很有趣。現在，我百分百確定這是可行的 、九成九確定它能幫你省下論文排版的功夫。
ntuthesis 原本僅是個 bookdown (R Markdown 的一個擴充) 論文模板，但為了讓其便於使用，我將它作成套件。ntuthesis 的目的只有一個 &amp;ndash; 讓作者能專注在論文內容的寫作。其它論文寫作的麻煩事：排版、口試委員審定書、目錄、圖目錄、表目錄、文獻引用格式、浮水印，全部都能自動生成。論文模板的概念並不新穎，且現存許多 LaTeX 論文模板。但撰寫 LaTeX 的過程非常辛苦，因為作者必須時時將注意力放在論文排版上。相對的，ntuthesis 讓作者能用 Markdown 撰寫論文，甚至可使用 R 語言直接在論文中動態產生結果 (如統計圖、數值與報表)。
總是需要跨出第一步 現在的問題是，臺灣還沒有人用過 ntuthesis 撰寫論文，而當「第一位」總是相當可怕的，更何況還要脫離自己習慣的寫作環境 (例如，MS Word)。作為 ntuthesis 的作者，我一定會用 ntuthesis 撰寫論文，但不會是在短期內 (我才剛錄取研究所)。所以這篇文章的目的基本上有兩個：
推銷 ntuthesis：
尋找願意使用 ntuthesis 撰寫論文的研究生
為 ntuthesis 擔保2：
你專心寫論文，我負責處理論文格式。
如果使用 ntuthesis 撰寫臺大3論文，你只要擔心論文的內容，任何套件相關的問題 (如排版設定不正確、bug、說明文件不清楚等) 我都會 (盡力) 協助解決 (不擺爛)。</description></item><item><title>Visualizing Language Loss in Taiwan</title><link>https://yongfu.name/2019/02/17/visualize-language-loss/</link><pubDate>Sun, 17 Feb 2019 00:00:00 +0000</pubDate><guid>https://yongfu.name/2019/02/17/visualize-language-loss/</guid><description>Taiwan Language Survey is a small project I worked on during May to June in 2018. The idea was to create a survey that continuously collects data and a web page that visualizes the collected data. The web page is updated weekly using Travis-CI.
The main purpose of this survey is to raise public awareness of language loss in Taiwan. Hence, the survey is designed to collect data that can provide valuable information about language loss, for example, some questions were asked to gain insight about the change of linguistic competence acoss generations in a family (i.</description></item><item><title>Inserting “Edit on GitHub” Buttons in a Single R Markdown Document</title><link>https://yongfu.name/2019/02/10/rmd_edit_btn/</link><pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate><guid>https://yongfu.name/2019/02/10/rmd_edit_btn/</guid><description>As the R Markdown ecosystem becomes larger, users now may encounter situations where they have to make decisions on which output format of R Markdown to use. One may found none of the formats suitable – the features essential to the output document one wants may scatter across different output formats of R Markdown.
Here is a real example I encountered. I wanted to create a document that:
supports bookdown syntax, e.</description></item><item><title>Create a Glossary in R Markdown</title><link>https://yongfu.name/2018/10/24/glossary-maker/</link><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid>https://yongfu.name/2018/10/24/glossary-maker/</guid><description>I was thinking about creating a glossary in bookdown and found out that there was already an issue about it. I like Yihui’s recommendation: use Pandoc’s definition lists. This was exactly what I had been doing, but I quickly found out that there was a major drawback – the definition lists won’t order alphabetically unless written in that way.
So I wrote an R function to reorder the definition lists written in R Markdown.</description></item><item><title>Easy Linguistics Document Writing with R Markdown</title><link>https://yongfu.name/2018/09/09/linguistics-down/</link><pubDate>Sun, 09 Sep 2018 00:00:00 +0000</pubDate><guid>https://yongfu.name/2018/09/09/linguistics-down/</guid><description>I’ve written a post about rendering IPA symbols properly regardless of the output format of the R Markdown document. I implemented the ideas into an R package, linguisticsdown. linguisticsdown provides a Shiny interface to facilitate inserting IPA symbols in R Markdown. See a quick demo of the current feature of linguisticsdown in the gif at the end of the post.
A live demo is hosted on shinyapps.io. For more details, visit linguisticsdown.</description></item><item><title>Rendering IPA Symbols in R Markdown</title><link>https://yongfu.name/2018/09/06/ipa-symbols/</link><pubDate>Thu, 06 Sep 2018 00:00:00 +0000</pubDate><guid>https://yongfu.name/2018/09/06/ipa-symbols/</guid><description>I was thinking about promoting reproducible research in Linguistics, or more precisely, how to attract people with no programming skills to have incentives to learn at least a bit programming, so that they have the ability to make their research more reproducible. I arrived at the solution: start by adopting R Markdown to write articles (see the last section for details), but making R Markdown more friendly to novices in a particular field of academia is crucial to enhance their incentives to learn programming.</description></item><item><title>jieba 自訂詞庫斷詞</title><link>https://yongfu.name/2018/07/31/jieba-dict/</link><pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate><guid>https://yongfu.name/2018/07/31/jieba-dict/</guid><description>在進行中文 Text Mining 前處理時，必須先經過斷詞處理。社群當中存在相當好的斷詞處理工具，如 jieba。但斷詞時常遇到一個問題：文本中重要的詞彙因為不常見於其它地方而被斷開，像是人物角色名稱。要處理這個問題，需將自訂詞庫提供給斷詞套件，才不會將重要詞彙斷開。 這邊將使用 jiebaR，介紹使用自訂詞庫的斷詞方式，並提供自訂詞庫的製作方式。
示範語料 這裡使用金庸神雕俠侶第三十二回 — 情是何物作為斷詞的文本。武俠小說在此是個很好的例子，因為裡面有許多人物名稱和專有名詞。
因為著作權問題1，語料的原始檔(032.txt)將不會出現在本文的 GitHub repo 中。
製作自訂詞庫 取得小說這類文本的角色名稱與特殊名詞乍看之下可能非常耗工耗時，但有些時候其實相當容易，尤其是著名的小說。這要歸功於維基百科，因為越是著名的小說，其越有可能有詳盡的維基百科頁面，而維基百科對製作詞庫最重要的特色在於其頁面的超連結，因為通常只有專有名詞才會成為一個維基頁面上的超連結。
這邊使用維基百科的神鵰俠侶角色列表作為詞庫的來源。以下使用rvest套件清理此頁面：
library(rvest) library(dplyr) library(magrittr) library(knitr) path &amp;lt;- &amp;quot;神鵰俠侶角色列表.html&amp;quot; # 這裡已先行下載網頁，若無可直接使用網址 data &amp;lt;- read_html(path) %&amp;gt;% html_nodes(&amp;quot;ul&amp;quot;) %&amp;gt;% html_nodes(&amp;quot;li&amp;quot;) %&amp;gt;% html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;% html_text() 觀察頁面後，可發現多數與小說相關的詞彙都位在 unordered list 下的連結內文(&amp;lt;a&amp;gt; tag)，因此透過 3 個html_nodes()取得連結，並用html_text()擷取連結內文。
接著看看擷取的詞彙，可以發現這些詞彙依照順序大致可區分成三個來源：
自維基頁面的目錄擷取之連結 內文的連結(這是我們要的) 其它連結 對應至頁面最下方，與小說有關但並非小說主要內容的連結，如，「射雕英雄传角色列表」。另外，也包含維基百科頁面的固定連結，如「編輯」、「討論」、「下載為PDF」等。 data &amp;lt;- unique(data) data[1:3] [1] &amp;quot;1 主角&amp;quot; &amp;quot;2 桃花島&amp;quot; &amp;quot;2.1 「北丐」門派&amp;quot; data[21:25] [1] &amp;quot;楊過&amp;quot; &amp;quot;射鵰英雄傳&amp;quot; &amp;quot;楊康&amp;quot; &amp;quot;穆念慈&amp;quot; &amp;quot;全真教&amp;quot; data[207:211] [1] &amp;quot;射雕英雄传角色列表&amp;quot; &amp;quot;倚天屠龙记角色列表&amp;quot; &amp;quot;查&amp;quot; [4] &amp;quot;论&amp;quot; &amp;quot;编&amp;quot; 我們要的內容介在data[21](楊過)至data[206](樊一翁)之間。此外，亦可手動加入連結中沒有的詞彙：</description></item><item><title>Text Mining 前處理</title><link>https://yongfu.name/2018/07/28/quanteda-tutorial/</link><pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate><guid>https://yongfu.name/2018/07/28/quanteda-tutorial/</guid><description>中文 Text Mining 的前處理比起其它以拉丁字母為主的文本困難許多，參考資源也相對龐雜不全。 這裡以較晚近出現的quanteda套件為根據，依其需求進行中文文本前處理。
選擇quanteda而非其它較流行的套件如tm的原因是因為其多語言支持較佳，譬如其內建的 tokenizer 能直接對中文進行斷詞。然而，由於 jieba的社群資源以及斷詞效果較佳，此文還是以jiebaR進行斷詞。
此外，因為使用的語料是簡體字，這裡也提到簡體、繁體轉換處理的相關資源。 我希望這篇文章能整理出一套中文文本前處理的架構，試圖減輕未來可能遇到的問題。
流程 graph LR html(&#34;HTML&#34;) html -.-|&#34;rvest&#34;| df0 subgraph 前處理 df1(&#34;斷詞 data_frame&#34;) df0(&#34;data_frame&#34;) df0 -.-|&#34;
jiebaR (保留標點)
&#34;| df1 df1 -.-|&#34;ropencc 簡轉繁&#34;| df1 end corp(&#34;Corpus&#34;) token(&#34;Tokens&#34;) subgraph quanteda df1 -.-|&#34;quanteda corpus()&#34;| corp corp -.-|&#34;quanteda tokenize()&#34;| token end html -.- bls(&#34; &#34;) style bls fill:none,stroke:none style html fill:#ccbdb9 style df1 fill:#92ff7f linkStyle 5 stroke-width:0px,fill:none; 資料爬取 這邊使用 RStudio 軟體工程師 Yihui 的中文部落格文章作為練習素材。首先需要取得文章的網址，因此先到部落格的文章列表頁面(https://yihui.</description></item><item><title>我的 R 學習歷程</title><link>https://yongfu.name/2018/01/31/rlearningpath/</link><pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate><guid>https://yongfu.name/2018/01/31/rlearningpath/</guid><description>接觸 R 的時間大約五個月了，從原本對電腦、程式一竅不通到現在能有效率的 debug、寫出簡潔有條理的 R code、甚至用 R 與 Markdown 架站寫部落格。算一算，我每週通常至少 3 天會用到 R，不是督促自己熟悉 R，是因為它太有魅力了。
學 R 語言很有趣1，但也相當耗時耗力。我在學習 R 上花了大量的時間，若不是運氣好找到對的方向，我不可能花費那麼多力氣去學 R，甚至可能直接放棄。雖然如此，我還是感到有點可惜，若能更早知道有效率的學習方式，就不必花費如此大量的時間 (及紙張) 在學習上。因此，我希望將學習 R 的心路歷程寫下，給想學 R 的人做為參考，或許可以減短學習初期耗費精神的時期。接下來，我將說明：
我學習 R 的動力來源
R 學習路徑：若從頭來過，我會如何學習 R、挑選哪些資源，讓自己更有效率地學習。
為何我能持續學習 R 而未放棄？其實現在我比較頭大的問題是：要怎麼克制自己不要一直打開 Rstudio？正是因為我學 R 的過程如同打電動一樣歡樂，所以放棄這個問題根本不存在。但事實上，剛開始學 R 時並不如何歡樂，直到上了課才越來越喜歡 R。
課程回顧 106學年上學期，我最喜歡、也意外收穫最多的課是謝舒凱老師開設的 R 語言與資料科學導論，或許會是我大學生涯最喜歡的課吧。
起初是抱著學好 R 語言 (加上通識快修不完) 的心情去加簽這門課的，但課堂上 R 語言的語法卻教得不多。然正是這種不聚焦在程式語法的課程安排，讓我把 R 學得非常好。如果課程從頭到尾都在教 R 語言，到期末我一定會受不了越顯複雜的語法，最後便隨意敷衍了事。我在這門課收穫最大的，反而不是課堂學到的技巧，而是老師、助教們傳達的一些概念與想法，以及自己探索這些概念想法的樂趣與收穫：
Open Source2 以及 R 的生態圈3
資料科學與 Story telling: Coding 於資料科學中的應用，不僅是傳統所強調的功能性，Coding 亦於美觀及呈現上扮演重要的角色。資料科學透過 Coding 處理、分析資料；同時也透過 Coding 作圖將資料視覺化，好將資料科學上的發現說成故事給其他人聽。</description></item><item><title>Constructing Life Tables with R</title><link>https://yongfu.name/2017/12/11/life_tables/</link><pubDate>Mon, 11 Dec 2017 00:00:00 +0000</pubDate><guid>https://yongfu.name/2017/12/11/life_tables/</guid><description>I have been using the package dplyr to handle with data for a while, and I thought I can use it with ease until I was stuck with my homework on contructing a life table. I found spreadsheets (either Excel or Google Spreadsheets) easy for handling this task, but had a hard time dealing with it in R. I think it was due to my unfamiliarity with the built-in functions and insufficient practice in R.</description></item></channel></rss>
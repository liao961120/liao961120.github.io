<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>stats on Yongfu's Blog</title><link>https://yongfu.name/tags/stats/</link><description>Recent content in stats on Yongfu's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 25 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://yongfu.name/tags/stats/feed.xml" rel="self" type="application/rss+xml"/><item><title>Demystifying Item Response Theory (Part I)</title><link>https://yongfu.name/2023/02/25/irt1/</link><pubDate>Sat, 25 Feb 2023 00:00:00 +0000</pubDate><guid>https://yongfu.name/2023/02/25/irt1/</guid><description>&lt;figure>
&lt;img src="irt.jpg" style="width:70.0%"
alt="Ok I know it’s the item characteristic curve of the 1PL model. What then? [img src]" />
&lt;figcaption aria-hidden="true">&lt;em>Ok I know it’s the item
characteristic curve of the 1PL model. What then?&lt;/em> &lt;sub>&lt;a
href="https://www.researchgate.net/figure/Item-characteristic-curves-Item-Response-Theory-IRT-1PL-model_fig1_342560715">[img
src]&lt;/a>&lt;/sub>&lt;/figcaption>
&lt;/figure>
&lt;h2 id="mysterious-item-response-theory">Mysterious Item Response Theory&lt;/h2>
&lt;p>&lt;strong>Item response theory is &lt;em>mysterious&lt;/em> and intimidating to students
first encountering it.&lt;/strong> It is mysterious in the way it is presented in
textbooks, at least in introductory ones. The text often starts with an
ambitious conceptual introduction to IRT, which most students would be
able to follow, but with some confusion. Curious students might bear
with the confusion and expect it to resolve in the following text, only
to find themselves disappointed. At the point where the underlying
statistical model should be further elaborated, the text abruptly stops
and tries to convince readers to trust the results from black-box IRT
software packages. It is fine to leave the model details to domain
experts and computers.&lt;/p>
&lt;p>It isn’t that I have trust issues with black-box software, and I would
also agree that it is impractical to understand all the details of model
estimation in IRT. Doing so would be similar to coding an IRT program
from scratch. The issue is that there is a huge gap here, between where
textbooks stopped explaining and where the confusing details of
statistical models should be hidden. Hence, students would be tricked
into believing that they have a &lt;em>sufficient degree of understanding&lt;/em>,
but in reality, it is just blind faith.&lt;/p>
&lt;p>A sufficient degree of understanding should allow the student to deploy
the learned skill to new situations. Therefore, a sufficient degree of
understanding of IRT models, for instance, should allow students to
extend and apply the models to analyses of &lt;a href="https://en.wikipedia.org/wiki/Differential_item_functioning">differential item
functioning
(DIF)&lt;/a> and
&lt;strong>differential rater functioning (DRF)&lt;/strong>.&lt;/p>
&lt;p>I’m arguing here that there is a basic granularity of understanding,
somewhat similar to the concept of &lt;a href="https://en.wikipedia.org/wiki/Basic_category">basic-level
category&lt;/a>, that when
reached, allows a student to smoothly adapt the learned skill to a wide
variety of situations, modifying and extending the skill on demand. And
I believe that item response theory is &lt;em>&lt;strong>too hard&lt;/strong>&lt;/em> for a student to
learn and reach this basic level of understanding, due to how it is
often presented and its historical development&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>There is still hope however, thanks to the development of a very general
set of statistical models known as the &lt;a href="https://en.wikipedia.org/wiki/Generalized_linear_model">Generalized Linear Models
(GLM)&lt;/a>. Item
response models could be understood in terms of the GLM and its
extensions
(&lt;a href="https://en.wikipedia.org/wiki/Generalized_linear_mixed_model">GLMM&lt;/a>
and non-linear form of GLM/GLMM). To be too particular about the
details, the results from IRT software packages and GLMs/GLMMs would be
very close but not identical, since they utilize different estimation
methods. The strengths of GLM, however, lie in its conceptual simplicity
and extensibility. Through GLM, IRT and other models such as the T-test,
ANOVA, and linear regression, are all placed together into the same
conceptual framework. Furthermore, software packages implementing GLMs
are widely available. Users can thus experiment with them—simulate a set
of data based on known parameters, construct the model and feed it the
data, and see if the fitted model correctly recovers the parameters.
This technique of learning statistics is probably the only effective way
for students to understand &lt;em>&lt;strong>a mysterious statistical model&lt;/strong>&lt;/em>.&lt;/p>
&lt;p>In this series of posts, I will walk the readers through the path of
understanding item response theory, with help from simulations and
generalized linear models. No need to worry if you don’t know GLMs yet.
We have another ally—&lt;a href="https://www.r-project.org">R&lt;/a>, in which we will be
simulating artificial data and fitting statistical models along the way.
Although it might seem intimidating at first, coding simulations and
models in fact provides scaffolding for learning. When feeling unsure or
confused, you can always resort to these simulation-based experiments to
resolve the issues at hand. In this very first post, I will start by
teaching you &lt;em>&lt;strong>simulations&lt;/strong>&lt;/em>.&lt;/p>
&lt;h2 id="just-enough-theory-to-get-started">Just Enough Theory to Get Started&lt;/h2>
&lt;p>Jargons aside, the concept behind item response theory is fairly simple.
Consider the case where 80 testees are taking a 20-item English
proficiency test. Under this situation, what are the &lt;em>&lt;strong>factors&lt;/strong>&lt;/em> that
influence whether an item is correctly answered by a testee?
Straightforward right? If an item is easy and if a testee is proficient
in English, he/she would probably get the item correct. Here, &lt;em>&lt;strong>two
factors jointly influence the result&lt;/strong>&lt;/em>:&lt;/p>
&lt;ol>
&lt;li>how difficult (or easy) an item is&lt;/li>
&lt;li>the English ability of a testee&lt;/li>
&lt;/ol>
&lt;p>We can express these variables and the relations between them in the
graphs below. Let’s first put our focus on the left one. Here, $A$
represents the &lt;strong>ability&lt;/strong> of the testee, $D$ represents the
&lt;strong>difficulty&lt;/strong> of the item, and $R$ represents the &lt;strong>item response&lt;/strong>, or
&lt;strong>score&lt;/strong> on the item. A response for an item is coded as &lt;code>1&lt;/code> ($R=1$) if
it is correctly answered. Otherwise, it is coded as &lt;code>0&lt;/code> ($R=0$). The
arrows $A$ → $R$ and $D$ → $R$ indicate the direction of influence. The
arrows enter $R$ since item difficulty and testee ability influence the
score on the item (not the other way around). $A$ and $D$ are drawn as a
circled node to indicate that they are &lt;strong>unobserved&lt;/strong> (or &lt;strong>latent&lt;/strong>, if
you prefer a fancier term), whereas uncircled nodes represent directly
observable variables (i.e., stuff that gets recorded during data
collection). This graphical representation of the variable and their
relationships is known as a &lt;a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">Directed Acyclic Graph
(DAG)&lt;/a>.&lt;/p>
&lt;div class="goat svg-container ">
&lt;svg
xmlns="http://www.w3.org/2000/svg"
font-family="Menlo,Lucida Console,monospace"
viewBox="0 0 328 137"
>
&lt;g transform='translate(8,16)'>
&lt;path d='M 256,16 L 280,16' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 24,80 L 40,48' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 200,80 L 216,48' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 72,48 L 88,80' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 248,48 L 264,80' fill='none' stroke='currentColor'>&lt;/path>
&lt;polygon points='52.000000,48.000000 40.000000,42.400002 40.000000,53.599998' fill='currentColor' transform='rotate(300.000000, 40.000000, 48.000000)'>&lt;/polygon>
&lt;polygon points='84.000000,48.000000 72.000000,42.400002 72.000000,53.599998' fill='currentColor' transform='rotate(240.000000, 72.000000, 48.000000)'>&lt;/polygon>
&lt;path d='M 216,48 L 224,32' fill='none' stroke='currentColor'>&lt;/path>
&lt;polygon points='234.000000,48.000000 222.000000,42.400002 222.000000,53.599998' fill='currentColor' transform='rotate(300.000000, 216.000000, 48.000000)'>&lt;/polygon>
&lt;path d='M 240,32 L 248,48' fill='none' stroke='currentColor'>&lt;/path>
&lt;polygon points='266.000000,48.000000 254.000000,42.400002 254.000000,53.599998' fill='currentColor' transform='rotate(240.000000, 248.000000, 48.000000)'>&lt;/polygon>
&lt;polygon points='288.000000,16.000000 276.000000,10.400000 276.000000,21.600000' fill='currentColor' transform='rotate(0.000000, 280.000000, 16.000000)'>&lt;/polygon>
&lt;path d='M 232,0 A 16,16 0 0,0 216,16' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 232,0 A 16,16 0 0,1 248,16' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 216,16 A 16,16 0 0,0 232,32' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 248,16 A 16,16 0 0,1 232,32' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 16,80 A 16,16 0 0,0 0,96' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 16,80 A 16,16 0 0,1 32,96' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 96,80 A 16,16 0 0,0 80,96' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 96,80 A 16,16 0 0,1 112,96' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 192,80 A 16,16 0 0,0 176,96' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 192,80 A 16,16 0 0,1 208,96' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 272,80 A 16,16 0 0,0 256,96' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 272,80 A 16,16 0 0,1 288,96' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 0,96 A 16,16 0 0,0 16,112' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 32,96 A 16,16 0 0,1 16,112' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 80,96 A 16,16 0 0,0 96,112' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 112,96 A 16,16 0 0,1 96,112' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 176,96 A 16,16 0 0,0 192,112' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 208,96 A 16,16 0 0,1 192,112' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 256,96 A 16,16 0 0,0 272,112' fill='none' stroke='currentColor'>&lt;/path>
&lt;path d='M 288,96 A 16,16 0 0,1 272,112' fill='none' stroke='currentColor'>&lt;/path>
&lt;text text-anchor='middle' x='16' y='100' fill='currentColor' style='font-size:1em'>A&lt;/text>
&lt;text text-anchor='middle' x='56' y='20' fill='currentColor' style='font-size:1em'>R&lt;/text>
&lt;text text-anchor='middle' x='96' y='100' fill='currentColor' style='font-size:1em'>D&lt;/text>
&lt;text text-anchor='middle' x='192' y='100' fill='currentColor' style='font-size:1em'>A&lt;/text>
&lt;text text-anchor='middle' x='232' y='20' fill='currentColor' style='font-size:1em'>P&lt;/text>
&lt;text text-anchor='middle' x='272' y='100' fill='currentColor' style='font-size:1em'>D&lt;/text>
&lt;text text-anchor='middle' x='304' y='20' fill='currentColor' style='font-size:1em'>R&lt;/text>
&lt;/g>
&lt;/svg>
&lt;/div>
&lt;p>The DAGs laid out here represent the concept behind the simplest kinds
of item response models, known as the &lt;strong>1-parameter logistic (1PL)
model&lt;/strong> (or Rasch Model). In more formal terms, this model posits that
the &lt;strong>probability&lt;/strong> of correctly answering an item is determined by the
&lt;strong>difference&lt;/strong> between testee ability and item difficulty. So a more
precise DAG representation for this model would be the one shown on the
right above. Here, $P$ is the probability of correctly answering the
item, which cannot be directly observed. However, $P$ directly
influences the item score $R$, hence the arrow $P$ → $R$.&lt;/p>
&lt;p>Believe it or not, the things we have learned so far could get us
started. So let’s simulate some data, based on what we know about item
response theory!&lt;/p>
&lt;h2 id="simulating-item-responses">Simulating Item Responses&lt;/h2>
&lt;p>
&lt;figure>
&lt;img src="tenet.gif" alt="Simulation is &amp;lt;em&amp;gt;playing god&amp;lt;/em&amp;gt; in a small world. It is similar to model
fitting, but in &amp;lt;em&amp;gt;reverse&amp;lt;/em&amp;gt; direction.">
&lt;figcaption>Simulation is &lt;em>playing god&lt;/em> in a small world. It is similar to model
fitting, but in &lt;em>reverse&lt;/em> direction.&lt;/figcaption>
&lt;/figure>
&lt;/p>
&lt;p>Consider the scenario where 3 students (Rob, Tom, and Joe) took a math
test with 2 items (A and B). Since we play gods during simulations, we
know the math ability of the students and the difficulty of the items.
These ability/difficulty levels can range from positive to negative
numbers, unbounded. Larger numbers indicate higher levels of
difficulty/ability. In addition, the levels of difficulty and ability
sit on a common scale, and hence could be directly compared. Also, each
student answers every item, so we get responses from all 6 (3x2)
combinations of students and items. Let’s code this in R. The function
&lt;code>expand.grid()&lt;/code> would pair up the 6 combinations for us.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>D &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">c&lt;/span>( A&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.4&lt;/span>, B&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.1&lt;/span> ) &lt;span style="color:#75715e"># Difficulty of item&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>A &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">c&lt;/span>( R&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.5&lt;/span>, T&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.1&lt;/span>, J&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">-0.4&lt;/span> ) &lt;span style="color:#75715e"># Ability of student (R:Rob, T:Tom, J:Joe)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4&lt;/span>&lt;span>dat &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">expand.grid&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5&lt;/span>&lt;span> I &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">c&lt;/span>( &lt;span style="color:#e6db74">&amp;#34;A&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;B&amp;#34;&lt;/span> ), &lt;span style="color:#75715e"># Item index&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6&lt;/span>&lt;span> T &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">c&lt;/span>( &lt;span style="color:#e6db74">&amp;#34;R&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;T&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;J&amp;#34;&lt;/span> ) &lt;span style="color:#75715e"># Testee index&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7&lt;/span>&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8&lt;/span>&lt;span>dat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code># A tibble: 6 × 2
I T
&amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;
1 A R
2 B R
3 A T
4 B T
5 A J
6 B J
&lt;/code>&lt;/pre>
&lt;p>After having all possible combinations of the students and the items, we
could collect the values of student ability and item difficulty into the
data frame.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>dat&lt;span style="color:#f92672">$&lt;/span>A &lt;span style="color:#f92672">=&lt;/span> A[ dat&lt;span style="color:#f92672">$&lt;/span>T ] &lt;span style="color:#75715e"># map ability to df by testee index T&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>dat&lt;span style="color:#f92672">$&lt;/span>D &lt;span style="color:#f92672">=&lt;/span> D[ dat&lt;span style="color:#f92672">$&lt;/span>I ] &lt;span style="color:#75715e"># map difficulty to df by item index I&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3&lt;/span>&lt;span>dat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code># A tibble: 6 × 4
I T A D
&amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
1 A R 0.5 0.4
2 B R 0.5 0.1
3 A T 0.1 0.4
4 B T 0.1 0.1
5 A J -0.4 0.4
6 B J -0.4 0.1
&lt;/code>&lt;/pre>
&lt;p>Now, we’ve got all the data needed for simulation, the only thing left
is to precisely lay out the &lt;strong>rules for generating the response data
$R$&lt;/strong>—the scores (zeros and ones) on the items answered by the students.
We are two steps away.&lt;/p>
&lt;h3 id="generating-probabilities">Generating Probabilities&lt;/h3>
&lt;p>When IRT is introduced in the previous section, I mention that the
probability of success on an item is determined by the &lt;strong>difference
between testee ability and item difficulty&lt;/strong>. It is straightforward to
get this difference: simply subtract $D$ from $A$ in the data. This
would give us a new variable $\mu$. I save the values of $\mu$ to column
&lt;code>Mu&lt;/code> in the data frame.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>dat&lt;span style="color:#f92672">$&lt;/span>Mu &lt;span style="color:#f92672">=&lt;/span> dat&lt;span style="color:#f92672">$&lt;/span>A &lt;span style="color:#f92672">-&lt;/span> dat&lt;span style="color:#f92672">$&lt;/span>D
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>dat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code># A tibble: 6 × 5
I T A D Mu
&amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
1 A R 0.5 0.4 0.1
2 B R 0.5 0.1 0.4
3 A T 0.1 0.4 -0.3
4 B T 0.1 0.1 0
5 A J -0.4 0.4 -0.8
6 B J -0.4 0.1 -0.5
&lt;/code>&lt;/pre>
&lt;p>From the way $\mu$ is calculated ($A$ - $D$), we can infer that, for a
particular observation, if $\mu$ is positive and large, the testee’s
ability will be much greater than the item’s difficulty, and he would
probably succeed on this item. On the other hand, if $\mu$ is negative
and small, the item difficulty would be much greater in this case, and
the testee would likely fail on this item. Hence, $\mu$ is directly
related to probability, in that $\mu$ of large values result in high
probabilities of success on the items, whereas $\mu$ of small values
result in low probabilities of success. Since $\mu$ can range from
positive infinity to negative infinity, how could we link $\mu$ to
probability in a principled manner? The solution is to take advantage of
the &lt;a href="https://en.wikipedia.org/wiki/Logistic_function">logistic
function&lt;/a>.&lt;/p>
&lt;p>$$
logistic( x ) = \frac{ 1 }{ 1 + e^{-x} }
$$&lt;/p>
&lt;p>The &lt;em>&lt;strong>logistic&lt;/strong>&lt;/em> is a function that maps a real number $x$ to a
probability $p$. In other words, the logistic function transforms the
input $x$ and constrains it to a value between zero and one. Note that
the transformation is &lt;strong>monotonic increasing&lt;/strong>, meaning that a smaller
$x$ would be mapped onto a smaller $p$, and a larger $x$ would be mapped
onto a larger $p$. The ranks of the values before and after the
transformation stay the same. To have a feel of what the logistic
function does, let’s transform some values with the logistic.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>&lt;span style="color:#75715e"># Set plot margins # (b, l, t, r)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>&lt;span style="color:#a6e22e">par&lt;/span>(oma&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#a6e22e">c&lt;/span>(&lt;span style="color:#ae81ff">0&lt;/span>,&lt;span style="color:#ae81ff">0&lt;/span>,&lt;span style="color:#ae81ff">0&lt;/span>,&lt;span style="color:#ae81ff">0&lt;/span>)) &lt;span style="color:#75715e"># Outer margin&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3&lt;/span>&lt;span>&lt;span style="color:#a6e22e">par&lt;/span>(mar&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#a6e22e">c&lt;/span>(&lt;span style="color:#ae81ff">4.5&lt;/span>, &lt;span style="color:#ae81ff">4.5&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>) ) &lt;span style="color:#75715e"># margin&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5&lt;/span>&lt;span>logistic &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">function&lt;/span>(x) &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">/&lt;/span> ( &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">exp&lt;/span>(&lt;span style="color:#f92672">-&lt;/span>x) )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6&lt;/span>&lt;span>x &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">seq&lt;/span>( &lt;span style="color:#ae81ff">-5&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>, by&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.1&lt;/span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7&lt;/span>&lt;span>p &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">logistic&lt;/span>( x )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8&lt;/span>&lt;span>&lt;span style="color:#a6e22e">plot&lt;/span>( x, p )
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="part1_files/figure-commonmark/unnamed-chunk-4-1.png"
style="width:100.0%" data-fig-align="center" />&lt;/p>
&lt;p>As the plot shows, the logistic transformation results in an S-shaped
curve. Since the transformed values (p) are bounded by 0 and 1, extreme
values on the poles of the x-axis would be “squeezed” after the
transformation. Real numbers with absolute values greater than 4, after
transformations, would have probabilities very close to the boundaries.&lt;/p>
&lt;h4 id="less-math-less-confusion">Less Math, Less Confusion&lt;/h4>
&lt;p>For many students, the mathematical form of the logistic function leads
to confusion. Staring at the math symbols hardly enables one to arrive
at any insightful interpretation of the logistic. A suggestion here is
to let go of the search for such an interpretation. The logistic
function is introduced not because it is loaded with some crucial
mathematical or statistical meaning. Instead, it is used here solely for
a practical reason: to monotonically map real numbers to probabilities.
You may well use another function&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> here to achieve the same purpose.&lt;/p>
&lt;h3 id="generating-responses">Generating Responses&lt;/h3>
&lt;p>We have gone all the way from ability/difficulty levels to the
probabilities of success on the items. Since we cannot directly observe
probabilities in the real world, the final step is to link these
probabilities to observable outcomes. In the case here, the outcomes are
simply item responses of zeros and ones. How do we map probabilities to
zeros and ones? Coin flips, or &lt;a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli
distributions&lt;/a>,
will get us there.&lt;/p>
&lt;p>Every time a coin is flipped, either a tail or a head is observed. The
Bernoulli distribution is just a fancy way of describing this process.
Assume that we record tails as &lt;code>0&lt;/code>s and heads as &lt;code>1&lt;/code>s, and suppose that
the probability $p$ of observing a head equals 0.75 (since the coin is
imbalanced in some way that the head is more likely observed and we know
it somehow). Then the distribution of the outcomes (zero and one) is
distributed as a Bernoulli distribution with parameter $P=0.75$. In
graphical terms, the distribution is just two bars.&lt;/p>
&lt;p>&lt;img src="part1_files/figure-commonmark/unnamed-chunk-5-1.png"
style="width:100.0%" data-fig-align="center" />&lt;/p>
&lt;p>We have got all we need, let’s construct all the remaining columns to
complete this simulation. I will compute the probabilities (&lt;code>P&lt;/code>) from
column &lt;code>Mu&lt;/code>. Column &lt;code>P&lt;/code> could then generate column &lt;code>R&lt;/code>, the item
responses, through the Bernoulli distribution.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1&lt;/span>&lt;span>&lt;span style="color:#75715e"># Generating 0/1 from Bernoulli distribution with given probabilites&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2&lt;/span>&lt;span>rbern &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">function&lt;/span>( p, n&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#a6e22e">length&lt;/span>(p) )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3&lt;/span>&lt;span> &lt;span style="color:#a6e22e">rbinom&lt;/span>( n&lt;span style="color:#f92672">=&lt;/span>n, size&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, prob&lt;span style="color:#f92672">=&lt;/span>p )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4&lt;/span>&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5&lt;/span>&lt;span>&lt;span style="color:#a6e22e">set.seed&lt;/span>(&lt;span style="color:#ae81ff">13&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6&lt;/span>&lt;span>dat&lt;span style="color:#f92672">$&lt;/span>P &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">logistic&lt;/span>( dat&lt;span style="color:#f92672">$&lt;/span>Mu )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7&lt;/span>&lt;span>dat&lt;span style="color:#f92672">$&lt;/span>R &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">rbern&lt;/span>( dat&lt;span style="color:#f92672">$&lt;/span>P )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8&lt;/span>&lt;span>dat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code># A tibble: 6 × 7
I T A D Mu P R
&amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
1 A R 0.5 0.4 0.1 0.525 0
2 B R 0.5 0.1 0.4 0.599 1
3 A T 0.1 0.4 -0.3 0.426 0
4 B T 0.1 0.1 0 0.5 0
5 A J -0.4 0.4 -0.8 0.310 1
6 B J -0.4 0.1 -0.5 0.378 0
&lt;/code>&lt;/pre>
&lt;p>Now, we have a complete table of simulated item responses. A few things
to note here. First, look at the fourth row of the data frame, where the
response of testee T (Tom) on item B is recorded. Column &lt;code>Mu&lt;/code> has a
value of zero since Tom’s ability level is identical to the difficulty
of item B. What does it mean to be “identical”? “Identical” implies that
Tom is neither more likely to succeed nor to fail on item B. Hence, you
can see that Tom has a 50% of getting item B correct in the $P$ column.
This is how the ability/difficulty levels and $\mu$ are interpreted.
They are on an abstract scale of real numbers. We need to convert them
to probabilities to make sense of them.&lt;/p>
&lt;p>The second thing to note is column &lt;code>R&lt;/code>. This is the only column that is
&lt;em>&lt;strong>stochastic&lt;/strong>&lt;/em> in the table. Every run of the simulation would likely
give different values of $R$ (unless a random seed is set, or the &lt;code>P&lt;/code>
column consists solely of zeros and ones). Probability does not
guarantee the observation of a particular outcome, since it is the exact
reason why probability is invented—to quantify &lt;em>&lt;strong>uncertainty&lt;/strong>&lt;/em>. The
presence of such uncertainty is the gist of a simulation. We add
uncertainty to the simulation, mimicking the real world, to know that in
the presence of such uncertainty, would it still be possible to discover
targets of interest with a statistical model.&lt;/p>
&lt;h2 id="whats-next">What’s next?&lt;/h2>
&lt;p>In a real-world scenario of the example presented here, we would only
observe the score ($R$) of an item ($I$) taken by a testee ($T$). The
targets of interest are the unobserved item difficulty ($D$) and testee
ability ($A$). In the next post, we will work in reverse and fit
statistical models on simulated data. We will see how the models
discover the true $A$s and $D$s from the information of $R$, $I$, and
$T$. See you there!&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>I mean, what the hack is &lt;em>Joint/Conditional Maximum Likelihood
Estimation&lt;/em>? These are methods developed in psychometrics and are
hardly seen in other fields. Unless obsessed with psychometrics, I
don’t think one would be able to understand these things.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>Such as the &lt;strong>cumulative distribution function&lt;/strong> for the normal
distribution.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description><category>stats</category><category>irt</category><category>Psychology</category></item></channel></rss>
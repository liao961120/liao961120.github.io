<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="About Learning"><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/fonts.css><link rel=stylesheet href=/css/custom.css><title>Text Mining 前處理 |
Yongfu&#39;s Blog</title></head><body><div class=header><div class=header_title><span class=logo><!doctype html><svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="346pt" height="346pt" viewBox="0 0 346 346"><g transform="translate(0.000000,346.000000) scale(0.100000,-0.100000)" fill="#000" stroke="none"><path d="M1484 3328c8-40 19-53 84-94 36-24 52-40 50-52-2-10-12-16-23-15-173 21-208 16-293-38-17-12-66-30-108-40-117-29-354-149-354-178 0-5 20-6 45-3 28 3 45 1 45-6 0-6-32-32-70-57-98-65-105-78-90-162 7-38 20-88 30-113 21-50 17-65-33-117-23-25-32-46-38-93-7-49-17-70-50-112-39-50-41-55-33-98 4-25 8-95 8-156 1-104 3-113 29-151 15-22 41-52 58-67 16-14 29-33 29-41 0-33 71-189 122-267 30-46 82-113 116-149 56-60 60-67 47-85-27-39-155-291-155-305 1-8 45-43 99-79l97-64-7-47c-4-25-22-73-40-104-33-59-38-93-31-205 2-43-13-179-23-202-4-10-10-16-14-14-16 10-39-21-34-47 5-23 9-26 32-20 41 12 94 9 98-4 7-21-131-17-152 3-12 13-19 14-30 4-8-7-15-19-15-26 0-12 68-14 405-14 263 0 405 3 405 10 0 6-83 10-230 10h-230l-11 27c-7 20-6 28 3 35 24 15 136 8 272-17 167-31 201-31 351 0 123 25 190 30 283 18 47-5 53-8 50-27-3-21-8-21-235-24-198-2-233-5-233-17 0-13 54-15 409-15 406 0 409 0 404 20-7 27-43 48-43 25 0-22-34-19-56 6-15 17-16 22-4 29 9 6 17 5 22-3 4-6 10-8 14-4 4 4-1 16-11 27-14 16-21 18-28 8-6-9-7-8-3 5 3 10 0 20-9 23-7 3-11 12-8 20 3 8 0 21-7 29-20 24-30 87-17 103 6 8 11 44 11 82-1 53-8 82-32 136-28 60-58 163-50 168 2 1 41 19 88 40 47 21 89 42 94 46 17 17-80 244-135 314l-20 25-44-30c-48-32-188-1e2-245-118-19-6-83-27-142-46-116-39-236-53-303-37-39 10-38 10 27 11 37 1 102 7 145 13l78 13-140 6c-209 10-363 60-526 169-192 130-358 370-403 587l-7 31 78 7c43 3 90 8 104 11l26 5 17-148c11-91 23-157 33-172 15-24 16-24 147-18 203 9 528 54 544 75 11 13 13 54 10 179-4 165-3 173 33 173 5 0 9-30 9-67 0-87 18-240 30-263 16-29 99-34 392-23 222 8 270 12 292 26l26 17v160 160h28c16 0 63 3 104 6l75 7 7-42c6-40 3-47-49-122-31-43-51-79-45-79 6 0 37 13 69 30 64 32 73 47 87 140 9 63 36 112 84 152 45 39 49 52 20 68-11 6-38 35-61 66-39 51-42 60-50 144-5 49-15 106-24 126-14 35-14 39 4 58 27 29 35 69 21 110-8 26-24 42-63 64-58 33-81 55-95 93-15 37 17 103 63 130 19 12 35 25 35 30 0 17-68 9-147-16-42-13-79-22-81-20-12 11 33 56 80 82l52 28-34 3c-22 2-52-6-92-27-32-17-65-31-73-31-25 0-108 46-155 85-57 48-142 85-192 85-46 0-57 5-163 76-81 54-192 94-262 94-21 0-54 15-99 45-36 25-69 45-72 45-2 0-2-14 2-32zm-143-641c-13-16-43-98-38-104 2-2 20 11 40 29 20 18 56 44 79 56l43 24-48-48c-31-30-64-79-94-138l-45-91 59 61c45 48 84 75 178 124 66 34 130 70 143 79 32 23 183 11 261-21 50-20 72-23 204-23 143 0 149 1 166 23l17 24 19-44c23-51 167-203 279-295 48-39 81-73 82-86 2-12 12-62 22-112 11-49 18-91 17-93-4-4-199 50-208 58-4 4-9 45-11 91l-3 84-83-1c-82-1-83-1-112 32-42 48-124 84-191 84-49 0-66-7-186-76-90-52-130-81-127-90 4-10-2-14-19-14-24 0-24-2-27-92-3-87-4-93-25-96-20-3-22 2-28 75-3 43-8 83-10 90-3 9-79 10-307 6-167-3-334-8-373-12-80-7-75 2-61-121l7-66-93-38c-51-21-99-41-107-44-12-4-13 5-8 49 4 30 14 76 23 102 14 42 23 51 68 74 30 15 88 63 142 117 70 71 106 118 162 212 58 1e2 82 130 134 172 65 53 78 62 59 39zm897-336c20-10 48-30 61-44l23-25-43-7c-71-9-389-41-389-39 0 7 120 94 155 112 53 28 142 29 193 3zm216-399c4-152 4-285 1-294-4-9-14-19-23-23-9-4-143-9-298-12-248-5-281-4-287 10-7 18-24 241-31 413l-6 122 113 12c61 6 184 20 272 30 88 9 181 18 206 19l46 1 7-278zm-810 171c16-80 37-505 26-516-17-16-580-71-593-58-5 5-10 28-13 52-2 31-1 37 4 19 5-16 17-26 32-28 23-4 421 34 469 44 13 3 21 7 18 10-2 3-114-7-247-21-134-14-247-22-251-18-10 11-53 448-45 468 5 13 42 15 265 15 181 0 262 3 267 11 5 8-65 10-260 7-217-3-268-6-280-18-12-13-13-33-1-150 8-74 14-151 13-170-1-40-23 141-34 277l-7 93 169 3c93 1 235 4 316 5l146 2 6-27zm-587-455c-2-13-4-3-4 22 0 25 2 35 4 23 2-13 2-33 0-45zM975 191c3-5 1-12-5-16-5-3-10 1-10 9 0 18 6 21 15 7zm210-59c-9-9-25 19-24 43 0 16 2 15 15-8 9-16 13-32 9-35zm-55 9c0-11-4-9-14 4-8 11-12 24-9 28 7 11 23-12 23-32zm1108 17c-2-6-10-14-16-16-7-2-10 2-6 12 7 18 28 22 22 4zm44-10c-7-7-12-8-12-2 0 14 12 26 19 19 2-3-1-11-7-17zm83 2c4-6-5-10-20-10-15 0-24 4-20 10 3 6 12 10 20 10 8 0 17-4 20-10z"/><path d="M1260 2374c-42-23-1e2-75-1e2-89 0-4 16 7 35 24 56 49 95 65 155 65 66 0 115-23 214-1e2 71-57 90-63 121-40 16 12 6 20-116 90-131 74-137 76-199 75-49 0-76-7-110-25z"/><path d="M2070 2158c-102-11-189-25-195-30-7-7 2-9 30-4 104 16 474 48 489 43 15-6 16-32 14-244l-3-238-247-3c-141-1-248-6-248-11 0-9 469-4 498 5 10 3 12 58 10 251l-3 248-80 2c-44 0-163-8-265-19z"/><path d="M1969 1961c-62-62-20-171 66-171 27 0 44 8 66 29 62 62 20 171-66 171-27 0-44-8-66-29z"/><path d="M1414 1940c-60-24-73-112-25-161 39-38 87-39 130-3 26 22 31 33 31 71 0 77-65 122-136 93z"/><path d="M1512 1343c2-10 32-33 67-52 91-48 176-54 255-18 52 24 77 49 62 64-3 3-29-6-57-21-76-42-149-39-243 8-81 41-89 43-84 19z"/><path d="M933 693c15-2 39-2 55 0 15 2 2 4-28 4-30 0-43-2-27-4z"/><path d="M2388 673c6-2 18-2 25 0 6 3 1 5-13 5-14 0-19-2-12-5z"/><path d="M870 155c-6-8-10-19-8-24 1-6 8 1 15 14 13 28 11 31-7 10z"/><path d="M2546 157c3-10 9-15 12-12 3 3 0 11-7 18-10 9-11 8-5-6z"/></g></svg></span><span>Yongfu&#39;s Blog</span></div><div class=site_nav><span class=nav_link><a href=/>Home</a></span>
<span class=nav_link><a href=/post/>Posts</a></span>
<span class=nav_link><a href=/about/>About</a></span>
<span class=nav_link><a href=/feed.xml>Subscribe</a></span></div></div><div class=main><article class=post><div class=article_header><div class=titles><h1>Text Mining 前處理</h1><p class=subtitle>中文、R 與 quanteda</p></div><div class=meta><div class=tags><a href="/post/?tag=text-mining">text mining</a>
<a href="/post/?tag=r">r</a>
<a href="/post/?tag=bash">bash</a>
<a href="/post/?tag=%25E4%25B8%25AD%25E6%2596%2587">中文</a></div><div class=date><span class=inline-icon><svg aria-hidden="true" focusable="false" data-prefix="far" data-icon="calendar-alt" class="svg-inline--fa fa-calendar-alt fa-w-14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="rgb(95, 95, 95)" d="M148 288h-40c-6.6.0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h48c26.5.0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3.0 6-2.7 6-6z"/></svg></span><span class=str>Jul 28, 2018</span></div></div></div><div class=article_content><p>中文 Text Mining 的前處理比起其它以拉丁字母為主的文本困難許多，參考資源也相對龐雜不全。 這裡以較晚近出現的<a href=https://quanteda.io/><code>quanteda</code></a>套件為根據，依其需求進行中文文本前處理。</p><p>選擇<code>quanteda</code>而非其它較流行的套件如<code>tm</code>的原因是因為其<a href=https://github.com/quanteda/stopwords>多語言支持</a>較佳，譬如其內建的 tokenizer 能<a href="https://koheiw.net/?p=339">直接對中文進行斷詞</a>。然而，由於 <a href=https://github.com/fxsjy/jieba><code>jieba</code></a>的社群資源以及斷詞效果較佳，此文還是以<a href=https://github.com/qinwf/jiebaR><code>jiebaR</code></a>進行斷詞。</p><p>此外，因為使用的語料是簡體字，這裡也提到簡體、繁體轉換處理的相關資源。 我希望這篇文章能整理出一套中文文本前處理的架構，試圖減輕未來可能遇到的問題。</p><div class="section level2"><h2>流程</h2><img src=https://img.yongfu.name/blog/mermaid2.svg alt style=width:100%><div class=mermaid>graph LR
html("HTML")
html -.->|"rvest"| df0
subgraph 前處理
df1("斷詞 data_frame")
df0("data_frame")
df0 -.->|"<br>jiebaR<br>(保留標點)<br>"| df1
df1 -.->|"ropencc<br>簡轉繁"| df1
end
corp("Corpus")
token("Tokens")
subgraph quanteda
df1 -.->|"quanteda<br>corpus()"| corp
corp -.->|"quanteda<br>tokenize()"| token
end
html -.- bls(" ")
style bls fill:none,stroke:none
style html fill:#ccbdb9
style df1 fill:#92ff7f
linkStyle 5 stroke-width:0px,fill:none;</div></div><div class="section level2"><h2>資料爬取</h2><p>這邊使用 <a href=https://www.rstudio.com/>RStudio</a> 軟體工程師 <a href=https://yihui.name/en/about/>Yihui</a> 的<a href=https://yihui.name/cn/>中文部落格</a>文章作為練習素材。首先需要取得文章的網址，因此先到部落格的文章列表頁面(<a href=https://yihui.name/cn/ class=uri>https://yihui.name/cn/</a>)，使用瀏覽器的<a href="https://developers.google.com/web/tools/chrome-devtools/?hl=zh-tw">開發者工具</a>(按<code>Ctrl + Shift + I</code>開啟)進行<strong>觀察</strong>。</p><p>接著使用<a href=https://github.com/hadley/rvest><code>rvest</code></a>套件擷取網頁中所有文章的連結，並將文章網址儲存成<code>list_of_post.txt</code>：</p><pre><code class=r>library(dplyr)
library(rvest)

list_of_posts &lt;- read_html(&quot;https://yihui.name/cn/&quot;) %&gt;% 
    html_nodes(&quot;.archive&quot;) %&gt;% # 列表在 div.archive 之下
    html_nodes(&quot;p&quot;) %&gt;% # 文章標題在 &lt;div&gt; 下之 &lt;p&gt;
    html_nodes(&quot;a&quot;) %&gt;% html_attr(&quot;href&quot;) # 文章連結在 &lt;p&gt; 下之 &lt;a&gt; 

readr::write_lines(list_of_posts, &quot;yihui/list_of_post.txt&quot;)</code></pre><pre><code class=r>head(list_of_posts, 2)</code></pre><pre><code class=nohighlight>[1] &quot;/cn/2018/10/middle-school-teachers/&quot;
[2] &quot;/cn/2018/10/potato-pancake/&quot;        </code></pre><pre><code class=r>tail(list_of_posts, 2)</code></pre><pre><code class=nohighlight>[1] &quot;/cn/2005/01/rtx/&quot;      &quot;/cn/2005/01/20-13-00/&quot;</code></pre><pre><code class=r>length(list_of_posts)</code></pre><pre><code class=nohighlight>[1] 1097</code></pre><p>可以看到總共有 1097 篇文章，時間從 2005 年到今年七月都有發文的紀錄。</p><p>由於文章數量相當多，因此之後僅會下載部分文章，<strong>避免造成伺服器負擔過大</strong>。下載網頁時，可以在 R 中直接使用<code>rvest</code>(見下文<strong>資料前處理</strong>)，但我比較建議使用 Bash<a href=#fn1 class=footnoteRef id=fnref1><sup>1</sup></a>的<code>wget</code>指令，才不會因為重複下載網頁造成伺服器負擔。</p><p>在下載前，需先決定目標文章的網址<code>sub_list</code>：</p><pre><code class=r>library(stringr)
set.seed(2018) # 設隨機種子 固定隨機函數的結果

idx &lt;- str_detect(list_of_posts, &quot;2018|2015|2010&quot;)
sub_list &lt;- list_of_posts[idx]
sub_list &lt;- sub_list[sample(seq_along(sub_list), 20)]  %&gt;% # 抽出 20 篇
    str_replace_all(pattern = &quot;^/&quot;, # 將站內連結改為完整 url
                    replacement = &quot;https://yihui.name/&quot;) %&gt;%
    str_replace_all(pattern = &quot;/$&quot;, &quot;/index.html&quot;)

readr::write_lines(sub_list, &quot;yihui/sublist.txt&quot;)

# 給 Bash 用的
sub_list %&gt;%
    str_replace_all(&quot;https://yihui.name/cn/&quot;, &quot;&quot;) %&gt;%
    str_replace_all(&quot;/index.html&quot;, &quot;&quot;) %&gt;%
    str_replace_all(&quot;/&quot;, &quot;-&quot;) %&gt;% 
    str_replace_all(&quot;-$&quot;, &quot;&quot;) %&gt;%
    readr::write_lines(&quot;yihui/sublist_name.txt&quot;)</code></pre><div id=bash- class="section level3"><h3>Bash 指令下載網頁</h3><blockquote><p>無法使用 bash 指令者，可跳過此節</p></blockquote><p>為了自動化下載網頁，我寫了一個簡單的 Bash script <code>wget_list</code>，用法如下:</p><ul><li><code>wget_list &lt;網址文字檔&gt; &lt;檔名文字檔&gt;</code><a href=#fn2 class=footnoteRef id=fnref2><sup>2</sup></a><ul><li><code>&lt;網址文字檔&gt;</code>： 每一列(row)由一個網址組成</li><li><code>&lt;檔名文字檔&gt;</code>： 每一列由一個名稱組成，每個名稱與<code>&lt;網址文字檔&gt;</code>的網址對應</li></ul></li></ul><p>在這裡，執行下列指令即可下載網頁</p><pre><code class=bash>cd yihui/html
wget_list ../sublist.txt ../sublist_name.txt
cd -</code></pre><p><strong><code>wget_list</code></strong>:</p><pre><code class=bash>#!/bin/bash

#&lt;&lt;&lt; wget_list: dowload webpages listed in a file &gt;&gt;&gt;#
### Argument 1 is the file of links, 1 url per row   ###
### Argument 2 is the file of names, 1 name per row  ###

file1=$1
file2=$2

## Get the number of lines in the link list
num_lines=$(wc -l $file1 | egrep -o '^[0-9]*')

## loop over the lines in file1, dowload the the file &amp; name them as listed in file2
for (( i=1; i&lt;=${num_lines}; ++i )); do
     wget &quot;$(sed -n ${i}p $file1)&quot; \
         -O &quot;$(sed -n ${i}p $file2)&quot;
done</code></pre></div></div><div class="section level2"><h2>資料前處理</h2><p>在清理資料之前，需先剖析網頁結構(就如同之前剖析文章列表頁面一樣)。 這邊觀察<a href=https://yihui.name/cn/2015/11/peer-review/>這篇文章</a>，大致可以找出這些資訊：</p><pre><code class=r>path &lt;- &quot;https://yihui.name/cn/2015/11/peer-review/&quot;
all &lt;- read_html(path) %&gt;%
    html_nodes(&quot;article&quot;)
header &lt;- all %&gt;% html_nodes(&quot;header&quot;)

title &lt;- header %&gt;%      # 文章標題
    html_nodes(&quot;h1&quot;) %&gt;% html_text()

post_date &lt;- header %&gt;%  # 發文日期
    html_node(&quot;h3&quot;) %&gt;% html_text() %&gt;%
    str_extract(&quot;201[0-9]-[0-9]{2}-[0-9]{2}&quot;)

article &lt;- all %&gt;%       # 內文
    html_nodes(&quot;p&quot;) %&gt;% 
    html_text() %&gt;% paste(collapse = &quot;\n&quot;) 
    # 這裡將 chr vector collapse 至 1 個字串，
    # 簡化資料結構，並以分行符號保留段落資訊

num_sec &lt;- all %&gt;%      # 內文段落數
    html_nodes(&quot;p&quot;) %&gt;% length

links &lt;- all %&gt;% html_nodes(&quot;p&quot;) %&gt;% # 內文連結  
    html_nodes(&quot;a&quot;) %&gt;% html_attr(&quot;href&quot;)
link_text &lt;- all %&gt;% html_nodes(&quot;p&quot;) %&gt;% # 內文連結標題
    html_nodes(&quot;a&quot;) %&gt;% html_text()</code></pre><pre><code class=r>library(tibble)
df &lt;- data_frame(title = title,
           date = post_date,
           content = article,
           num_sec = num_sec,
           links = list(links),
           link_text = list(link_text)
           )
df %&gt;%
    mutate(title = str_trunc(title, 8),
           content = str_trunc(content, 8),
           links = str_trunc(links, 8),
           link_text = str_trunc(link_text, 8)) %&gt;%
    kable(&quot;markdown&quot;, align = &quot;c&quot;)</code></pre><table><thead><tr class=header><th align=center>title</th><th align=center>date</th><th align=center>content</th><th align=center>num_sec</th><th align=center>links</th><th align=center>link_text</th></tr></thead><tbody><tr class=odd><td align=center>同行评审</td><td align=center>2015-11-11</td><td align=center>看到这么一…</td><td align=center>8</td><td align=center>c(“ht…</td><td align=center>c(“一则…</td></tr></tbody></table><p>我們可以將上面的程式碼改寫成函數<code>post_data()</code>，自動讀取文章並輸出 data frame：</p><pre><code class=r>post_data &lt;- function (path) {
    all &lt;- read_html(path) %&gt;%
        html_nodes(&quot;article&quot;)
    header &lt;- all %&gt;% html_nodes(&quot;header&quot;)
    
    title &lt;- header %&gt;%      # 文章標題
        html_nodes(&quot;h1&quot;) %&gt;% html_text()
    
    post_date &lt;- header %&gt;%  # 發文日期
        html_node(&quot;h3&quot;) %&gt;% html_text() %&gt;%
        str_extract(&quot;201[0-9]-[0-9]{2}-[0-9]{2}&quot;)
    
    article &lt;- all %&gt;%       # 內文
        html_nodes(&quot;p&quot;) %&gt;% 
        html_text() %&gt;% paste(collapse = &quot;\n&quot;)
        # 這裡將 chr vector collapse 至 1 個字串，
        # 簡化資料結構，並以分行符號保留段落資訊
        
    num_sec &lt;- all %&gt;%      # 內文段落數
        html_nodes(&quot;p&quot;) %&gt;% length
    
    links &lt;- all %&gt;% html_nodes(&quot;p&quot;) %&gt;% # 內文連結  
        html_nodes(&quot;a&quot;) %&gt;% html_attr(&quot;href&quot;)
    link_text &lt;- all %&gt;%     # 內文連結標題
        html_nodes(&quot;p&quot;) %&gt;% 
        html_nodes(&quot;a&quot;) %&gt;% html_text()
    
    df &lt;- tibble::data_frame(title = title,
                             date = post_date,
                             content = article,
                             num_sec = num_sec,
                             links = list(links),
                             link_text = list(link_text)
                             )
}</code></pre><p>接著，將所有文章讀取至一個 data frame <code>all_post</code>：</p><pre><code class=r>library(dplyr)
library(tidyr)

html_list &lt;- list.files(&quot;yihui/html/&quot;) # 列出資料夾下的檔案
all_post &lt;- vector(&quot;list&quot;, length(html_list))

for (i in seq_along(html_list)) {
    path &lt;- paste0(&quot;yihui/html/&quot;, html_list[i])
    all_post[[i]] &lt;- post_data(path)
}

all_post &lt;- bind_rows(all_post) %&gt;% arrange(desc(date))

head(all_post) %&gt;%
    mutate(title = str_trunc(title, 8),
           content = str_trunc(content, 8),
           links = str_trunc(links, 8),
           link_text = str_trunc(link_text, 8)) %&gt;%
    kable(&quot;markdown&quot;, align = &quot;c&quot;)</code></pre><table><thead><tr class=header><th align=center>title</th><th align=center>date</th><th align=center>content</th><th align=center>num_sec</th><th align=center>links</th><th align=center>link_text</th></tr></thead><tbody><tr class=odd><td align=center>修辞还是真实</td><td align=center>2018-06-21</td><td align=center>说两封让我…</td><td align=center>12</td><td align=center>chara…</td><td align=center>chara…</td></tr><tr class=even><td align=center>花椒香料</td><td align=center>2018-05-31</td><td align=center>古人似乎喜…</td><td align=center>2</td><td align=center>/cn/2…</td><td align=center>去年的花椒</td></tr><tr class=odd><td align=center>CSS 的…</td><td align=center>2018-05-14</td><td align=center>CSS 中…</td><td align=center>15</td><td align=center>c(“ht…</td><td align=center>c(“查阅…</td></tr><tr class=even><td align=center>毛姆的文学回忆录</td><td align=center>2018-05-04</td><td align=center>前段时间看…</td><td align=center>14</td><td align=center>c(“/c…</td><td align=center>c(“职业…</td></tr><tr class=odd><td align=center>距离的组织</td><td align=center>2018-05-03</td><td align=center>前面《闲情…</td><td align=center>5</td><td align=center>/cn/2…</td><td align=center>闲情赋</td></tr><tr class=even><td align=center>语言圣战的终结？</td><td align=center>2018-04-19</td><td align=center>一直以来我…</td><td align=center>3</td><td align=center>c(“ht…</td><td align=center>c(“惊天…</td></tr></tbody></table><div class="section level3"><h3>直接從網路讀取</h3><p>如果無法使用 Bash 指令下載網頁，可將上面程式碼的<code>html_list</code>改為讀取<code>sublist.txt</code>中的 url，並修改<code>for</code>迴圈中的<code>path</code>：</p><pre><code class=r>html_list &lt;- read_lines(&quot;yihui/sublist.txt&quot;) # 讀取 url 
all_post &lt;- vector(&quot;list&quot;, length(html_list))

for (i in seq_along(html_list)) {
    path &lt;- html_list[i]
    all_post[[i]] &lt;- post_data(path)
}

all_post &lt;- bind_rows(all_post) %&gt;% arrange(desc(date))</code></pre></div><div class="section level3"><h3>斷詞</h3><p>在處理中文、日語等文本資料，需先經過斷詞處理，因為其不像英語等歐洲語言的文本，以空格表示字詞的界線。</p><p>我們將使用<code>jiebaR</code>套件的<code>segment()</code>進行斷詞。由<code>?segment()</code>查看其 documentation 可知<strong><code>segment()</code>只吃文字檔或 一個句子</strong>，因此需先搞清楚<code>all_post</code>的結構才能進行斷詞：</p><p><code>all_post</code>: 20*5 的<code>data_frame</code>，每列(row)為一篇文章 - $title: 每列為 1 個值 - $date: 每列為 1 個值 - $content: 每列為 1 個值，段落資訊藏在字串中的<code>\n</code>符號 - $links: 每列為 1 個 list - $link_text: 每列為 1 個 list</p><p><code>all_post$content</code>的結構相當簡單(一篇文章一個字串)，因此不須經過額外處理。其它變項不須斷詞處理，因此在此不加細談。</p><div id=jiebarsegment class="section level4"><h4>jiebaR::segment</h4><p>因為<code>all_post$content</code>簡單的結構符合<code>jiebaR</code>套件的預設需求，但有時資料會比較複雜，因此記錄下來供未來參考。</p><p>前面提到<code>jiebaR::segment</code>只吃一個句子(一個字串)或文字檔，那如果丟一個 vector 給它會怎樣？答案是看<code>worker()</code>的設定：</p><pre><code class=r>library(jiebaR)
seg &lt;- worker(symbol = T, bylines = F)
segment(c(&quot;妳很漂亮&quot;, &quot;我不喜歡你&quot;), seg)</code></pre><pre><code class=nohighlight>[1] &quot;妳&quot;     &quot;很漂亮&quot; &quot; &quot;      &quot;我&quot;     &quot;不&quot;     &quot;喜歡&quot;   &quot;你&quot;    </code></pre><pre><code class=r>seg &lt;- worker(symbol = T, bylines = T)
segment(c(&quot;妳很漂亮&quot;, &quot;我不喜歡你&quot;), seg)</code></pre><pre><code class=nohighlight>[[1]]
[1] &quot;妳&quot;     &quot;很漂亮&quot;

[[2]]
[1] &quot;我&quot;   &quot;不&quot;   &quot;喜歡&quot; &quot;你&quot;  </code></pre><ol style=list-style-type:decimal><li><p><code>bylines = F</code>：回傳 1 個 chr vector，其每個元素為 1 個詞。</p></li><li><p><code>bylines = T</code>：回傳 1 個 list，其長度(元素的數量)等於輸入之 vector 的長度，每個元素為一個 chr vector。</p></li></ol><p><code>bylines = F</code>的設定在此符合我們的需求，並且為配合<code>quanteda</code>套件的特性而將斷詞結果以一個字串(以空格分開字詞)而非一個 chr vector 的形式儲存。 以下<strong>對第一篇文章進行斷詞</strong>：</p><pre><code class=r>library(jiebaR)
all_post_seg &lt;- all_post
seg &lt;- worker(symbol = T, bylines = F)

all_post_seg$content[1] &lt;- all_post$content[1] %&gt;%
    segment(seg) %&gt;% paste(collapse = &quot; &quot;)</code></pre><pre><code class=r>all_post$content[1] %&gt;% str_trunc(20)</code></pre><pre><code class=nohighlight>[1] &quot;说两封让我感到“我天，给亲友的书信...&quot;</code></pre><pre><code class=r>all_post_seg$content[1] %&gt;% str_trunc(30)</code></pre><pre><code class=nohighlight>[1] &quot;说 两封 让 我 感到 “ 我 天 ， 给 亲友 的 ...&quot;</code></pre><p>要處理所有文章，僅需外包一個 for loop：</p><pre><code class=r>all_post_seg &lt;- all_post
seg &lt;- worker(symbol = T, bylines = F)

idx &lt;- seq_along(all_post$content)
for (i in idx){
    all_post_seg$content[i] &lt;- all_post$content[i] %&gt;%
        segment(seg) %&gt;% paste(collapse = &quot; &quot;)
}

head(all_post$content, 3) %&gt;% str_trunc(20)</code></pre><pre><code class=nohighlight>[1] &quot;说两封让我感到“我天，给亲友的书信...&quot; 
[2] &quot;古人似乎喜欢把花椒当香料用。在《古...&quot;
[3] &quot;CSS 中的位置（position...&quot;            </code></pre><pre><code class=r>head(all_post_seg$content, 3) %&gt;% str_trunc(30)</code></pre><pre><code class=nohighlight>[1] &quot;说 两封 让 我 感到 “ 我 天 ， 给 亲友 的 ...&quot;  
[2] &quot;古人 似乎 喜欢 把 花椒 当 香料 用 。 在 《 ...&quot;
[3] &quot;CSS   中 的 位置 （ position ） 属...&quot;         </code></pre></div></div><div class="section level3"><h3>簡轉繁</h3><p><a href=https://github.com/BYVoid/OpenCC>OpenCC</a> 是一個簡體字與繁體字轉換的專案，非常優秀，因為其不僅是單純字轉字，甚至處理了地區性的用法(如「軟體」vs.「软件」)。因此，其簡繁轉換的選項有非常多：</p><ul><li><code>s2t.json</code> Simplified Chinese to Traditional Chinese 簡體到繁體</li><li><code>t2s.json</code> Traditional Chinese to Simplified Chinese 繁體到簡體</li><li><code>s2tw.json</code> Simplified Chinese to Traditional Chinese (Taiwan Standard) 簡體到臺灣正體</li><li><code>tw2s.json</code> Traditional Chinese (Taiwan Standard) to Simplified Chinese 臺灣正體到簡體</li><li><code>s2hk.json</code> Simplified Chinese to Traditional Chinese (Hong Kong Standard) 簡體到香港繁體（香港小學學習字詞表標準）</li><li><code>hk2s.json</code> Traditional Chinese (Hong Kong Standard) to Simplified Chinese 香港繁體（香港小學學習字詞表標準）到簡體</li><li><code>s2twp.json</code> Simplified Chinese to Traditional Chinese (Taiwan Standard) with Taiwanese idiom 簡體到繁體（臺灣正體標準）並轉換爲臺灣常用詞彙</li><li><code>tw2sp.json</code> Traditional Chinese (Taiwan Standard) to Simplified Chinese with Mainland Chinese idiom 繁體（臺灣正體標準）到簡體並轉換爲中國大陸常用詞彙</li><li><code>t2tw.json</code> Traditional Chinese (OpenCC Standard) to Taiwan Standard 繁體（OpenCC 標準）到臺灣正體</li><li><code>t2hk.json</code> Traditional Chinese (OpenCC Standard) to Hong Kong Standard 繁體（OpenCC 標準）到香港繁體（香港小學學習字詞表標準）</li></ul><p><a href=https://github.com/qinwf/ropencc><code>ropencc</code></a>套件是 OpenCC 的 R 語言接口，其不在 CRAN 上，需以<code>devtools</code>從 GitHub 下載：</p><pre><code class=r>devtools::install_github(&quot;qinwf/ropencc&quot;)</code></pre><p>使用上非常容易：</p><pre><code class=r>library(ropencc)
trans &lt;- converter(TW2SP) # 臺灣用法轉大陸用法
run_convert(trans, &quot;開放中文轉換軟體&quot;)</code></pre><pre><code class=nohighlight>[1] &quot;开放中文转换软件&quot;</code></pre><pre><code class=r>trans &lt;- converter(T2S)   # 單純繁轉簡
run_convert(trans, &quot;開放中文轉換軟體&quot;)</code></pre><pre><code class=nohighlight>[1] &quot;开放中文转换软体&quot;</code></pre><pre><code class=r>trans &lt;- converter(S2TWP) # 簡轉臺灣用法
run_convert(trans, &quot;开放中文转换软件&quot;)</code></pre><pre><code class=nohighlight>[1] &quot;開放中文轉換軟體&quot;</code></pre><p>在此我使用<code>S2TWP</code>轉換<code>$content</code>；<code>S2T</code>轉換<code>$title</code>：</p><pre><code class=r>library(ropencc)
all_post_seg$content &lt;- run_convert(converter(S2TWP),
                                    all_post_seg$content)
all_post_seg$title &lt;- run_convert(converter(S2T),
                                  all_post_seg$title)

head(all_post_seg) %&gt;%
    mutate(title = str_trunc(title, 8),
           content = str_trunc(content, 8),
           links = str_trunc(links, 8),
           link_text = str_trunc(link_text, 8)) %&gt;%
    kable(&quot;markdown&quot;, align = &quot;c&quot;)</code></pre><table><thead><tr class=header><th align=center>title</th><th align=center>date</th><th align=center>content</th><th align=center>num_sec</th><th align=center>links</th><th align=center>link_text</th></tr></thead><tbody><tr class=odd><td align=center>修辭還是真實</td><td align=center>2018-06-21</td><td align=center>說 兩封 …</td><td align=center>12</td><td align=center>chara…</td><td align=center>chara…</td></tr><tr class=even><td align=center>花椒香料</td><td align=center>2018-05-31</td><td align=center>古人 似乎…</td><td align=center>2</td><td align=center>/cn/2…</td><td align=center>去年的花椒</td></tr><tr class=odd><td align=center>CSS 的…</td><td align=center>2018-05-14</td><td align=center>CSS …</td><td align=center>15</td><td align=center>c(“ht…</td><td align=center>c(“查阅…</td></tr><tr class=even><td align=center>毛姆的文學回憶錄</td><td align=center>2018-05-04</td><td align=center>前段時間 …</td><td align=center>14</td><td align=center>c(“/c…</td><td align=center>c(“职业…</td></tr><tr class=odd><td align=center>距離的組織</td><td align=center>2018-05-03</td><td align=center>前面 《 …</td><td align=center>5</td><td align=center>/cn/2…</td><td align=center>闲情赋</td></tr><tr class=even><td align=center>語言聖戰的終結？</td><td align=center>2018-04-19</td><td align=center>一直 以來…</td><td align=center>3</td><td align=center>c(“ht…</td><td align=center>c(“惊天…</td></tr></tbody></table></div></div><div id=quanteda class="section level2"><h2>quanteda</h2><p>我們前面進行的資料前處理，已經將資料整理成符合<a href=https://tutorials.quanteda.io/basic-operations/corpus/corpus/><code>quanteda::corpus()</code>輸入的格式</a>：</p><blockquote><p>A data frame consisting of a character vector for documents, and additional vectors for document-level variables</p></blockquote><p>因此，依以下指令即可將<code>all_post_seg</code>轉換成<code>corpus</code>物件：</p><pre><code class=r>library(quanteda)
corp &lt;- corpus(all_post_seg, 
               docid_field = &quot;title&quot;, 
               text_field = &quot;content&quot;) 

corp %&gt;% summary() %&gt;% as_data_frame() %&gt;% 
    head(3) %&gt;%
    mutate(links = str_trunc(links, 8),
           link_text = str_trunc(link_text, 8)) %&gt;%
    kable(&quot;markdown&quot;, align = &quot;c&quot;)</code></pre><table><thead><tr class=header><th align=center>Text</th><th align=center>Types</th><th align=center>Tokens</th><th align=center>Sentences</th><th align=center>date</th><th align=center>num_sec</th><th align=center>links</th><th align=center>link_text</th></tr></thead><tbody><tr class=odd><td align=center>修辭還是真實</td><td align=center>217</td><td align=center>375</td><td align=center>15</td><td align=center>2018-06-21</td><td align=center>12</td><td align=center>chara…</td><td align=center>chara…</td></tr><tr class=even><td align=center>花椒香料</td><td align=center>149</td><td align=center>246</td><td align=center>9</td><td align=center>2018-05-31</td><td align=center>2</td><td align=center>/cn/2…</td><td align=center>去年的花椒</td></tr><tr class=odd><td align=center>CSS 的位置屬性以及如何居中對齊超寬元素</td><td align=center>347</td><td align=center>805</td><td align=center>23</td><td align=center>2018-05-14</td><td align=center>15</td><td align=center>c(“ht…</td><td align=center>c(“查阅…</td></tr></tbody></table><p>有了<code>corpus</code>的資料結構後，即進入了下圖<code>quanteda</code>的分析架構，也結束了資料前處理的階段，開始進入 EDA 的階段。</p><img src=https://img.yongfu.name/blog/mermaid.svg alt><div class=mermaid>graph TD
C(Corpus)
token(Tokens)
AP["Positional analysis"]
AN["Non-positional analysis"]
dfm(DFM)
tidy("Tidy Text Format")
vis("Visualize")
C --> token
token --> dfm
token -.-> AP
dfm -.-> AN
tidy -->|"cast_dfm()"| dfm
dfm -->|"tidy()"| tidy
dfm -.- vis
tidy -.-> vis
AP -.- vis
style C stroke-width:0px,fill:#6bbcff
style token stroke-width:0px,fill:#6bbcff
style dfm stroke-width:0px,fill:#6bbcff
style tidy stroke-width:0px,fill:orange
linkStyle 6 stroke-width:0px,fill:none;
linkStyle 8 stroke-width:0px,fill:none;</div><p><a href=https://quanteda.io/>quanteda</a> 有相當完整的<a href=https://tutorials.quanteda.io/>教學資源</a>，且有很多有用的函數。同時，<a href=https://github.com/juliasilge/tidytext><code>tidytext</code></a> 套件也能輕易與 <code>quanteda</code> 配合，在 <code>document-feature matrix</code> 與<code>tidytext</code>所提倡的 <strong>tidy data frame</strong>(one-token-per-document-per-row) 兩種資料結構間自由轉換。<strong>tidy data frame</strong> 的格式與<a href=https://github.com/tidyverse/ggplot2><code>ggplot2</code></a>相吻合，有助於資料視覺化的進行。</p><p>這裡選擇以<code>quanteda</code>而非<code>tidytext</code>作為主要架構的原因在於<code>tidytext</code>的架構僅容許 <strong>bag-of-words</strong> 的架構，但<code>quanteda</code>除了 <strong>bag-of-words</strong> 之外，還保有 <strong>Positional analysis</strong> 的潛力。</p><p>由於篇幅有限，這裡不多加細談<code>quanteda</code>套件<a href=#fn3 class=footnoteRef id=fnref3><sup>3</sup></a>。關於<code>quanteda</code>的使用，可以參考 <a href=https://tutorials.quanteda.io/>quanteda tutorial</a>，內容非常詳盡。</p></div><div id=reproduce class="section level2"><h2>Reproduce</h2><p>這篇文章的原始碼在我的 <a href=https://github.com/liao961120/blog/tree/master/post_source/quanteda-chinese>GitHub</a>，歡迎下載至自己的電腦執行。</p></div><div class="section level2 unnumbered"><h2>參考資料</h2><div id=refs class=references><div id=ref-silge2017><p>Silge, Julia, and David Robinson. 2017. <em>Text Mining with R: A Tidy Approach</em>. 1st ed. O’Reilly Media, Inc.</p></div><div id=ref-watanabe2018><p>Watanabe, Kohei, and Stefan Müller. 2018. “Quanteda Tutorials.” <em>Quanteda Tutorials</em>. https://tutorials.quanteda.io/.</p></div></div></div><div class=footnotes><ol><li id=fn1><p>Mac 和 Linux 內建有 Bash，但 Windows 沒有。<a href=#fnref1>↩</a></p></li><li id=fn2><p>要能直接執行<code>wget_list</code>需先給予其執行的權限，因此需設置<code>chmod 755 &lt;path to wget_list&gt;</code>，並且將<code>wget_list</code>置於 shell 會自動搜尋程式的地方(如<code>/usr/bin/</code>)。</p><p>另一個方法是不設置權限，直接執行<code>wget_list</code>：<br><code>bash &lt;path to wget_list&gt; &lt;file1&gt; &lt;file2&gt;</code> <a href=#fnref2>↩</a></p></li><li id=fn3><p>未來可能會發一篇續作。<a href=#fnref3>↩</a></p></li></ol></div><p style=text-align:right;font-size:7px;margin-top:0;margin-bottom:0;padding-top:0;padding-bottom:1px>Last updated: 2018-11-10</p><style>div.mermaid{display:none}</style></div><br><br><div id=disqus_thread></div><script>var disqus_config=function(){this.page.url='';this.page.identifier='';};(function(){var d=document,s=d.createElement('script');s.src='https://y-f-liao-s-page.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><div class=next-prev><div><span>PREV</span>
<a href=https://yongfu.name/2018/07/23/rmd_intro/>My Notes on R Markdown</a></div><div><span>NEXT</span>
<a href=https://yongfu.name/2018/07/31/jieba-dict/>jieba 自訂詞庫斷詞</a></div></div></article><aside class="toc toc-right js-toc relative z-1 transition--300 absolute pa4 pt5 is-position-fixed"></aside></div><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.11.1/tocbot.min.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.11.1/tocbot.css><script>tocbot.init({tocSelector:'.js-toc',contentSelector:'.article_content',headingSelector:'h2, h3, h4',hasInnerContainers:true,collapseDepth:3,});</script><style>ol.toc-list{list-style-type:none}aside{position:fixed;top:15%!important;right:2%}.next-prev{margin-top:2.5em;border-top:2px solid #adadad8c;display:flex;flex-wrap:wrap;justify-content:space-between}.next-prev>div{min-width:150px;width:43%}.next-prev>div>span{display:block;width:100%;color:grey;font-weight:600;letter-spacing:1.5px;padding-bottom:.3rem;margin-top:.4rem}.next-prev>div:nth-child(2){text-align:right}.next-prev>div>a{text-decoration:none;color:#000;font-weight:600}</style><footer><div class=social><span class=icon title="Send me an email"><a href=mailto:liao961120@gmail.com target=_blank><span class="social email"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="envelope" class="svg-inline--fa fa-envelope fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="#fff" d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V4e2c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5.0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg></span></a></span><span class=icon title="Follow me on Twitter"><a href=https://twitter.com/liao_yongfu target=_blank><span class="social twitter"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="twitter" class="svg-inline--fa fa-twitter fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="#fff" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></a></span><span class=icon title="Follow me on Facebook"><a href=https://www.facebook.com/liao961120 target=_blank><span class="social facebook"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="facebook-f" class="svg-inline--fa fa-facebook-f fa-w-10" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="#fff" d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43.0 225.36.0c-73.22.0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z"/></svg></span></a></span><span class=icon title="Follow me on GitHub"><a href=https://github.com/liao961120 target=_blank><span class="social github"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" class="svg-inline--fa fa-github fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="#fff" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></span></div><p class=site_info><span class=copyright>© Yongfu&#39;s Blog 2017-2023</span></p><p class=theme_info>Powered by <a href=https://gohugo.io target=_blank>Hugo</a> &amp; <a href=https://github.com/liao961120/TeXtLite target=_blank>TeXtLite Theme</a>.</p></footer><div class=scrollBtn><span id=scrolltop onclick=window.scrollTo(0,0)>&#x25B2;</span>
<span id=scrollbottom onclick=window.scrollTo(0,document.body.scrollHeight)>&#x25BC;</span></div><style>div.scrollBtn{display:flex;flex-wrap:wrap;width:1em;position:fixed;bottom:1.1%;right:.8%}#scrolltop,#scrollbottom{line-height:1;font-size:1.4rem;color:var(--link-transitiion-light)}#scrolltop:hover,#scrollbottom:hover{cursor:pointer;color:green;font-size:1.6rem}</style><script>document.querySelectorAll('code, pre').forEach(elem=>{if(elem.className.startsWith('language'))
elem.className+=" line-numbers";if(['r','yaml','latex','markdown','bash','sh','json'].includes(elem.className)){elem.className="language-"+elem.className+" line-numbers";}})</script><link href=/js/prism.css rel=stylesheet><script src=/js/prism.js></script><script src=/js/prism-line-numbers.min.js></script><link rel=stylesheet href=/js/prism-line-numbers.min.css></body></html>